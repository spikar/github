{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1_BERT_Fine_Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS2TfQFJE4M_",
        "outputId": "6d58f647-66d8-4cc1-e18e-1cd35e401144"
      },
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torchtext.data as ttd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "We will use The 20 Newsgroups dataset \n",
        "Dataset [homepage](http://qwone.com/~jason/20Newsgroups/): \n",
        "\n",
        "Scikit-learn includes some nice helper functions for retrieving the 20 Newsgroups dataset-- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html. We'll use them below to retrieve the dataset.\n",
        "\n",
        "Also look at results fron non- neural net models here : https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeF7owBRSnZN",
        "outputId": "50436353-f79a-4960-f13f-7cb7fec639aa"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec  2 06:54:06 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    22W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apbVI5sKSmG8",
        "outputId": "e4ed1fa0-e215-4b97-fe9d-37db1b260958"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXScUokPqyPx"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "train = fetch_20newsgroups(subset='train',\n",
        "                           remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "test = fetch_20newsgroups(subset='test',\n",
        "                           remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NS-Vxi0Pkt-",
        "outputId": "30a15d35-96f0-4d63-cd84-aa87728e3b87"
      },
      "source": [
        "\n",
        "print(train.data[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV2eF-BiPrLZ",
        "outputId": "38b9665e-ce0b-414f-dfa0-12369af39ba6"
      },
      "source": [
        "print(train.target[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IqtsBCEPx-E",
        "outputId": "5cc7b8d1-0590-47f6-c2f3-ebdc3b7d41a2"
      },
      "source": [
        "train.target_names"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "0NiOeWmbRV_G",
        "outputId": "31e555c9-6ed5-4f26-e53c-a3a7a72e63db"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Plot the number of tokens of each length.\n",
        "sns.countplot(train.target);"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWDUlEQVR4nO3dfbRddX3n8fdHAj6gEpAQYxIapqKW1VURMxSrtS1pFdASRERdPkTESccBB7QzDtaujk7btdRqfaoLh4oaFBXKg0TrAxSfxjUFTRQQCEq0UJIJSXxCLUst+p0/zi+bY7hJ7jk3+96b5P1a66yz92/v3+98773n3s/Zv73PuakqJEkCeNBMFyBJmj0MBUlSx1CQJHUMBUlSx1CQJHXmzHQBU3HooYfWkiVLZroMSdqjrF279rtVNW+ibXt0KCxZsoQ1a9bMdBmStEdJcueOtjl9JEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpE6voZBkbpLLktyWZF2SpyQ5JMk1SW5v9we3fZPkXUnWJ7kpyTF91iZJeqC+jxTeCXymqp4APBFYB5wHXFtVRwLXtnWAE4Ej220lcH7PtUmSttNbKCQ5CHg6cCFAVf28qn4ILAdWtd1WAae05eXARTVwHTA3yYK+6pMkPVCf72g+AtgKfCDJE4G1wDnA/Kra1Pa5G5jflhcCdw3139DaNg21kWQlgyMJDj/88N6K157vpCv/auQ+n3rOn+/WGp592cVj9fvkaS/arXXsLT59yXdH7nPi8w/toZK9V5+hMAc4BnhVVV2f5J3cP1UEQFVVkpH+9VtVXQBcALB06VL/bZx686wrxpvB/MdTX7lb6zj5sk+M3Gf1aX+8W2vQvqPPUNgAbKiq69v6ZQxCYXOSBVW1qU0PbWnbNwKLh/ovam2aRv/7Q88cq9+fvOSzu7WOE6967sh9Pr388t1ag+73/CvWj9XvklMf2y2/58rNY41x1nPm73on7Ta9hUJV3Z3kriSPr6pvAsuAW9ttBfCmdn9V67IaODvJx4DfBu4Zmmaa9W57z/Kx+j3hrKu65S/8/bNG7v/7/+kfx3pc7Vuec/mXR+5z5XOf1kMlmu36/pTUVwEXJzkA+A5wBoOT25cmORO4Ezi97fsp4CRgPXBv21eSNI16DYWqugFYOsGmZRPsW8BZfdazI3efP/oJSYBHv3L3npTcW7zh0vGmoN5w+u6dgpI0Ot/RLEnq7NH/ZEcPdNkHThi5z2lnfKaHSiTtiTxSkCR1DAVJUsdQkCR1DAVJUscTzZI0gk1vGe+DFha8duFurqQfHilIkjqGgiSpYyhIkjqGgiSpYyhIkjpefSRpn/L1923Z9U7bedIrDuuhktnJIwVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1eg2FJHck+UaSG5KsaW2HJLkmye3t/uDWniTvSrI+yU1JjumzNknSA03HkcIfVNXRVbW0rZ8HXFtVRwLXtnWAE4Ej220lcP401CZJGjIT00fLgVVteRVwylD7RTVwHTA3yYIZqE+S9ll9h0IBVydZm2Rla5tfVZva8t3A/La8ELhrqO+G1vYrkqxMsibJmq1bt/ZVtyTtk/r+JztPq6qNSQ4Drkly2/DGqqokNcqAVXUBcAHA0qVLR+orSdq5Xo8Uqmpju98CXAkcC2zeNi3U7rf9G6SNwOKh7otamyRpmvQWCkkOTPKIbcvAM4CbgdXAirbbCuCqtrwaeGm7Cuk44J6haSZJ0jToc/poPnBlkm2P85Gq+kySrwKXJjkTuBM4ve3/KeAkYD1wL3BGj7VJkibQWyhU1XeAJ07Q/j1g2QTtBZzVVz2SpF3zHc2SpE7fVx9Ni63nf3jkPvNe+eIeKpGkPZtHCpKkjqEgSeoYCpKkjqEgSersFSeaJWlPsvkda0fuM//cJ/dQyQN5pCBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6vQeCkn2S/L1JJ9s60ckuT7J+iSXJDmgtT+4ra9v25f0XZsk6VdNx5HCOcC6ofU3A2+vqscCPwDObO1nAj9o7W9v+0mSplGvoZBkEfAs4H1tPcDxwGVtl1XAKW15eVunbV/W9pckTZO+jxTeAbwW+GVbfxTww6q6r61vABa25YXAXQBt+z1t/1+RZGWSNUnWbN26tc/aJWmf01soJHk2sKWq1u7OcavqgqpaWlVL582btzuHlqR93pwex34qcHKSk4CHAI8E3gnMTTKnHQ0sAja2/TcCi4ENSeYABwHf67E+SdJ2ejtSqKrXVdWiqloCvAD4XFW9CPg8cFrbbQVwVVte3dZp2z9XVdVXfZKkB5qJ9yn8D+A1SdYzOGdwYWu/EHhUa38NcN4M1CZJ+7Q+p486VfUF4Att+TvAsRPs81PgedNRjyRpYr6jWZLUMRQkSZ1pmT6SJO1eW/7u6pH7HHb2M3a5j0cKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqTOpEIhybWTaZMk7dl2+jEXSR4CPAw4NMnBwLb/mfxI7v83mpKkvcSuPvvoT4BzgccAa7k/FH4E/F2PdUmSZsBOQ6Gq3gm8M8mrqurd01STJGmGTOpTUqvq3Ul+B1gy3KeqLuqpLknSDJhUKCT5EPDrwA3AL1pzAYaCJO1FJvv/FJYCR1VV9VmMJGlmTfZ9CjcDj+6zEEnSzJvskcKhwK1JvgL8bFtjVZ3cS1WSpBkx2VB4Q59FSJJmh8leffTFvguRJM28yV599GMGVxsBHADsD/xbVT2yr8IkSdNvskcKj9i2nCTAcuC4voqSJM2MkT8ltQY+DjxzZ/sleUiSryS5McktSd7Y2o9Icn2S9UkuSXJAa39wW1/fti8Z4+uRJE3BZKePTh1afRCD9y38dBfdfgYcX1U/SbI/8OUknwZeA7y9qj6W5L3AmcD57f4HVfXYJC8A3gw8f7QvR5I0FZM9UvjjodszgR8zmELaoXZE8ZO2un+7FXA8cFlrXwWc0paXt3Xa9mVtqkqSNE0me07hjHEGT7Ifg09XfSzwHuDbwA+r6r62ywbu/wjuhcBd7fHuS3IP8Cjgu9uNuRJYCXD44YePU5YkaQcm+092FiW5MsmWdrs8yaJd9auqX1TV0cAi4FjgCVOsl6q6oKqWVtXSefPmTXU4SdKQyU4ffQBYzeD/KjwG+ERrm5Sq+iHweeApwNwk245QFgEb2/JGYDFA234Q8L3JPoYkaeomGwrzquoDVXVfu30Q2OnL9CTzksxtyw8F/ghYxyAcTmu7rQCuasur2zpt++f8AD5Jml6T/ZiL7yV5MfDRtv5Cdv0qfgGwqp1XeBBwaVV9MsmtwMeS/BXwdeDCtv+FwIeSrAe+D7xghK9DkrQbTDYUXg68G3g7gyuI/i/wsp11qKqbgCdN0P4dBucXtm//KfC8SdYjSerBZEPhfwErquoHAEkOAd7KICwkSXuJyZ5T+K1tgQBQVd9ngqMASdKebbKh8KAkB29baUcKkz3KkCTtISb7h/1twD8n+Ye2/jzgr/spSZI0Uyb7juaLkqxh8BEVAKdW1a39lSVJmgmTngJqIWAQSNJebOSPzpYk7b0MBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSp7dQSLI4yeeT3JrkliTntPZDklyT5PZ2f3BrT5J3JVmf5KYkx/RVmyRpYn0eKdwH/GlVHQUcB5yV5CjgPODaqjoSuLatA5wIHNluK4Hze6xNkjSB3kKhqjZV1dfa8o+BdcBCYDmwqu22CjilLS8HLqqB64C5SRb0VZ8k6YGm5ZxCkiXAk4DrgflVtaltuhuY35YXAncNddvQ2rYfa2WSNUnWbN26tbeaJWlf1HsoJHk4cDlwblX9aHhbVRVQo4xXVRdU1dKqWjpv3rzdWKkkqddQSLI/g0C4uKquaM2bt00LtfstrX0jsHio+6LWJkmaJn1efRTgQmBdVf3t0KbVwIq2vAK4aqj9pe0qpOOAe4ammSRJ02BOj2M/FXgJ8I0kN7S2PwPeBFya5EzgTuD0tu1TwEnAeuBe4Iwea5MkTaC3UKiqLwPZweZlE+xfwFl91SNJ2jXf0SxJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6vQWCknen2RLkpuH2g5Jck2S29v9wa09Sd6VZH2Sm5Ic01ddkqQd6/NI4YPACdu1nQdcW1VHAte2dYATgSPbbSVwfo91SZJ2oLdQqKovAd/frnk5sKotrwJOGWq/qAauA+YmWdBXbZKkiU33OYX5VbWpLd8NzG/LC4G7hvbb0NoeIMnKJGuSrNm6dWt/lUrSPmjGTjRXVQE1Rr8LqmppVS2dN29eD5VJ0r5rukNh87ZpoXa/pbVvBBYP7beotUmSptF0h8JqYEVbXgFcNdT+0nYV0nHAPUPTTJKkaTKnr4GTfBT4feDQJBuA/wm8Cbg0yZnAncDpbfdPAScB64F7gTP6qkuStGO9hUJVvXAHm5ZNsG8BZ/VViyRpcnxHsySpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqzKhSSnJDkm0nWJzlvpuuRpH3NrAmFJPsB7wFOBI4CXpjkqJmtSpL2LbMmFIBjgfVV9Z2q+jnwMWD5DNckSfuUVNVM1wBAktOAE6rqFW39JcBvV9XZ2+23EljZVh8PfHMnwx4KfHeKpe0tY8yGGmbLGLOhhtkyxmyoYbaMMRtqmK4xfq2q5k20Yc4UH3jaVdUFwAWT2TfJmqpaOpXH21vGmA01zJYxZkMNs2WM2VDDbBljNtQwG8aYTdNHG4HFQ+uLWpskaZrMplD4KnBkkiOSHAC8AFg9wzVJ0j5l1kwfVdV9Sc4GPgvsB7y/qm6Z4rCTmmbaR8aYDTXMljFmQw2zZYzZUMNsGWM21DDjY8yaE82SpJk3m6aPJEkzzFCQJHX22lCY6kdmJHl/ki1Jbh7z8Rcn+XySW5PckuScMcZ4SJKvJLmxjfHGcWppY+2X5OtJPjlm/zuSfCPJDUnWjNF/bpLLktyWZF2Sp4zY//HtsbfdfpTk3DHqeHX7Xt6c5KNJHjLGGOe0/rdMtoaJnk9JDklyTZLb2/3BI/Z/Xqvhl0l2efnhDsb4m/YzuSnJlUnmjjHGX7b+NyS5OsljRh1jaNufJqkkh45YwxuSbBx6fpw0Tg1JXtW+H7ckecuoYyS5ZKiGO5LcMMYYRye5btvvWpJjR+z/xCT/3H5fP5HkkTur4QGqaq+7MThR/W3gPwAHADcCR404xtOBY4Cbx6xhAXBMW34E8K0xagjw8La8P3A9cNyY9bwG+AjwyTH73wEcOoWfySrgFW35AGDuFH++dzN4A84o/RYC/wI8tK1fCrxsxDF+E7gZeBiDCzX+CXjsOM8n4C3AeW35PODNI/b/DQZv4PwCsHTMGp4BzGnLb95ZDTsZ45FDy/8VeO+oY7T2xQwuNLlzZ8+1HdTwBuC/jfBznGiMP2g/zwe39cPG+TqGtr8N+Isx6rgaOLEtnwR8YcT+XwV+ry2/HPjLUZ7je+uRwpQ/MqOqvgR8f9wCqmpTVX2tLf8YWMfgj9IoY1RV/aSt7t9uI18ZkGQR8CzgfaP23R2SHMTgyXshQFX9vKp+OIUhlwHfrqo7x+g7B3hokjkM/rD/vxH7/wZwfVXdW1X3AV8ETt1Vpx08n5YzCEva/Smj9K+qdVW1s3f0T2aMq9vXAXAdg/cHjTrGj4ZWD2QXz9Gd/G69HXjtFPpP2g7GeCXwpqr6Wdtny7h1JAlwOvDRMcYoYNur+4PYyXN0B/0fB3ypLV8DPHdnNWxvbw2FhcBdQ+sbGPEP8u6UZAnwJAav9Eftu187BN0CXFNVI48BvIPBL9svx+i7TQFXJ1mbwUeNjOIIYCvwgTaF9b4kB06hlhewi1+2iVTVRuCtwL8Cm4B7qurqEYe5GfjdJI9K8jAGr+QW76LPjsyvqk1t+W5g/pjj7C4vBz49Tsckf53kLuBFwF+M0X85sLGqbhzn8Zuz2zTW+3c2FbcTj2Pws70+yReT/Mcp1PK7wOaqun2MvucCf9O+n28FXjdi/1u4/0Xw8xjx+bm3hsKskeThwOXAudu9opqUqvpFVR3N4BXcsUl+c8THfzawparWjvrY23laVR3D4FNsz0ry9BH6zmFwiHt+VT0J+DcG0yUjy+CNjScD/zBG34MZ/LIcATwGODDJi0cZo6rWMZhmuRr4DHAD8ItRa5lg3GKMo8DdJcnrgfuAi8fpX1Wvr6rFrf/Zu9p/u8d+GPBnjBEmQ84Hfh04mkHgv22MMeYAhwDHAf8duLS94h/HCxnjhUvzSuDV7fv5atoR9gheDvyXJGsZTF3/fJTOe2sozIqPzEiyP4NAuLiqrpjKWG265fPACSN2fSpwcpI7GEyjHZ/kw2M8/sZ2vwW4ksEU3WRtADYMHeVcxiAkxnEi8LWq2jxG3z8E/qWqtlbVvwNXAL8z6iBVdWFVPbmqng78gMH5onFsTrIAoN3vdLqiL0leBjwbeFELp6m4mBGnKxj8MT8CuLE9TxcBX0vy6MkOUFWb2wuoXwJ/z2jPz202AFe0aduvMDiy3uEJ7x1pU5OnApeMUQPACgbPTRi8+Bnpa6mq26rqGVX1ZAbB9O1R+u+toTDjH5nRXmFcCKyrqr8dc4x5264GSfJQ4I+A20YZo6peV1WLqmoJg+/D56pqpFfHSQ5M8ohtywxOTk76qqyquhu4K8njW9My4NZRahgylVdg/wocl+Rh7eezjMG5npEkOazdH87gl/8jY9azmsEfANr9VWOOM7YkJzCYWjy5qu4dc4wjh1aXM/pz9BtVdVhVLWnP0w0MLtK4e4QaFgytPocRnp9DPs7gZDNJHsfggohxPq30D4HbqmrDGH1hcA7h99ry8cBIU1BDz88HAX8OvHekRx/lrPSedGMw1/stBin5+jH6f5TBYei/M3iSnjli/6cxmA64icEUww3ASSOO8VvA19sYN7OLKxkmMd7vM8bVRwyu4rqx3W4Z8/t5NLCmfS0fBw4eY4wDge8BB03he/BGBn+0bgY+RLvSZMQx/g+DULsRWDbu8wl4FHAtg1/6fwIOGbH/c9ryz4DNwGfHqGE9g/Nv256ju7pyaKIxLm/fz5uATwALRx1ju+13sPOrjyaq4UPAN1oNq4EFY3wdBwAfbl/L14Djx/k6gA8C/3kKz4unAWvb8+t64Mkj9j+Hwd++bwFvon1yxWRvfsyFJKmzt04fSZLGYChIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp8/8BhAfOHfipLI8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RX3KKlFtdUR"
      },
      "source": [
        "#BERT with 128 features and truncating at end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5PWjsT0FeKm",
        "outputId": "95d89e4a-2de7-49ae-a369-c0d7a5c84105"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hI6d8597O40",
        "outputId": "9cd344cb-79b5-4b69-a1b3-1940f420c96d"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train.data[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: tensor([  101,  1045,  2001,  6603,  2065,  3087,  2041,  2045,  2071,  4372,\n",
            "         7138,  2368,  2033,  2006,  2023,  2482,  1045,  2387,  1996,  2060,\n",
            "         2154,  1012,  2009,  2001,  1037,  1016,  1011,  2341,  2998,  2482,\n",
            "         1010,  2246,  2000,  2022,  2013,  1996,  2397, 20341,  1013,  2220,\n",
            "        17549,  1012,  2009,  2001,  2170,  1037,  5318,  4115,  1012,  1996,\n",
            "         4303,  2020,  2428,  2235,  1012,  1999,  2804,  1010,  1996,  2392,\n",
            "        21519,  2001,  3584,  2013,  1996,  2717,  1997,  1996,  2303,  1012,\n",
            "         2023,  2003,  2035,  1045,  2113,  1012,  2065,  3087,  2064,  2425,\n",
            "         4168,  1037,  2944,  2171,  1010,  3194, 28699,  2015,  1010,  2086,\n",
            "         1997,  2537,  1010,  2073,  2023,  2482,  2003,  2081,  1010,  2381,\n",
            "         1010,  2030,  3649, 18558,  2017,  2031,  2006,  2023, 24151,  2559,\n",
            "         2482,  1010,  3531,  1041,  1011,  5653,  1012,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK1TbacGPzi4",
        "outputId": "9d65a621-9aaa-4850-e5fc-ceb2ab216db4"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test.data[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "Token IDs: tensor([  101,  1045,  2572,  1037,  2210,  5457,  2006,  2035,  1997,  1996,\n",
            "         4275,  1997,  1996,  6070,  1011,  6486, 19349, 21187,  2015,  1012,\n",
            "         1045,  2031,  2657,  1997,  1996,  3393,  7367,  1048,  3366,  7020,\n",
            "         2063,  7020,  7416,  1012,  2071,  2619,  2425,  2033,  1996,  5966,\n",
            "         2024,  2521,  2004,  2838,  2030,  2836,  1012,  1045,  2572,  2036,\n",
            "         8025,  2000,  2113,  2054,  1996,  2338,  3643,  2003,  2005,  9544,\n",
            "         5243,  6321,  1996,  6486,  2944,  1012,  1998,  2129,  2172,  2625,\n",
            "         2084,  2338,  3643,  2064,  2017,  2788,  2131,  2068,  2005,  1012,\n",
            "         1999,  2060,  2616,  2129,  2172,  2024,  2027,  1999,  5157,  2023,\n",
            "         2051,  1997,  2095,  1012,  1045,  2031,  2657,  2008,  1996,  3054,\n",
            "         1011,  3500,  2220,  2621,  2003,  1996,  2190,  2051,  2000,  4965,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NAIfyBP7jMn",
        "outputId": "586c370f-765d-4f3a-e8d3-e1198e5bbef3"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} test samples'.format(len(test_dataset)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10,182 training samples\n",
            "1,132 validation samples\n",
            "7,532 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM1fTM-pENir"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(test_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4488276f-17aa-420f-c5a3-3d8ba123e072"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 20, # The number of output labels   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPi4OXjQv-6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec4ad5f-953f-44ec-9873-b568b6b6f687"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
        "device\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au9vSy4Uvugh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204a2b7e-a532-4b22-e319-5979e1c89b23"
      },
      "source": [
        "# Tell pytorch to run this model on the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64387b03-66c0-4d34-f5fa-0af458226c74"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (20, 768)\n",
            "classifier.bias                                                (20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S31Yr1JN7DGV"
      },
      "source": [
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "epochs = 2\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() \n",
        "          if not any(nd in n for nd in no_decay)], \n",
        "         'weight_decay': 0.5},\n",
        "\n",
        "        {'params': [p for n, p in model.named_parameters() \n",
        "        if any(nd in n for nd in no_decay)], \n",
        "         'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr = 5e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35c786c-fb71-4df2-ad36-b217c7c0d8d6"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model.train()\n",
        "  for batch in train_dataloader:  \n",
        "    b_input_ids = batch[0]\n",
        "    b_input_mask = batch[1]\n",
        "    b_labels = batch[2]\n",
        "    # forward pass\n",
        "\n",
        "    outputs = model(b_input_ids.to(device), \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask.to(device), \n",
        "                        labels=b_labels.to(device))\n",
        "\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "    # backward pass\n",
        "    outputs.loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    train_loss.append(outputs.loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_dataloader:\n",
        " \n",
        "      # forward pass\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "    # forward pass\n",
        "\n",
        "      outputs = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "      \n",
        "      valid_loss.append(outputs.loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 1.3324    Valid Loss: 0.9631, Duration: 0:01:58.683108\n",
            "Epoch 2/2, Train Loss: 0.6465    Valid Loss: 0.8917, Duration: 0:01:59.046046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXGS2lguch__"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "    # forward pass\n",
        "\n",
        "      outputs = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "\n",
        "      _,indices = torch.max(outputs.logits,dim=1)\n",
        "      correct+= (b_labels==indices).sum().item()\n",
        "      total += b_labels.shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jORGlh3sc6sF"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model)\n",
        "valid_acc = get_accuracy(validation_dataloader, model)\n",
        "test_acc = get_accuracy(test_dataloader, model)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MYTpwnkdX_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38234c1d-61a4-4874-83b5-255ac00c56c7"
      },
      "source": [
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.8851,\t Valid acc: 0.7500,\t Test acc: 0.7017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNhcjLa-dxx1"
      },
      "source": [
        "# Write a function to get predictions\n",
        "def get_predictions(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in data_iter:\n",
        "      \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "    # forward pass\n",
        "\n",
        "      outputs = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "      \n",
        "      _,indices = torch.max(outputs.logits,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,b_labels.cpu().numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woupMtYpeVBn"
      },
      "source": [
        "y_valid, predictions=get_predictions(validation_dataloader, model)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J80SoMYRelAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add22283-30b6-4ff4-ce8b-8ab84acddf78"
      },
      "source": [
        "predictions.max()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLNI1soZeoZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f376ef92-c3b7-408b-ddec-b985f007dc66"
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_valid,predictions)\n",
        "cm"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31,  0,  0,  0,  0,  0,  0,  3,  2,  1,  0,  1,  0,  0,  0,  3,\n",
              "         0,  2,  4,  4],\n",
              "       [ 0, 35,  5,  3,  1,  4,  1,  2,  0,  0,  0,  1,  2,  0,  1,  0,\n",
              "         0,  0,  1,  0],\n",
              "       [ 0,  4, 42,  2,  1,  4,  1,  1,  2,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 0,  0,  6, 39,  4,  1,  2,  2,  0,  0,  0,  0,  3,  0,  1,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 1,  2,  1,  2, 39,  0,  4,  3,  0,  0,  0,  0,  3,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 0,  4,  3,  2,  0, 48,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 0,  0,  0,  4,  1,  0, 52,  1,  1,  0,  0,  0,  2,  0,  0,  1,\n",
              "         0,  0,  0,  0],\n",
              "       [ 1,  0,  0,  0,  1,  0,  2, 35,  2,  0,  0,  0,  3,  0,  0,  0,\n",
              "         2,  0,  1,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  8, 48,  0,  0,  0,  1,  0,  1,  0,\n",
              "         1,  1,  1,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1,  5,  4, 45,  2,  0,  0,  0,  1,  0,\n",
              "         0,  2,  1,  0],\n",
              "       [ 2,  0,  0,  0,  0,  1,  1,  1,  0,  2, 64,  0,  0,  0,  1,  0,\n",
              "         0,  1,  0,  0],\n",
              "       [ 3,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0, 51,  1,  0,  2,  0,\n",
              "         2,  0,  2,  0],\n",
              "       [ 0,  1,  2,  2,  1,  0,  0,  4,  1,  0,  0,  1, 38,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  1,  0, 48,  1,  0,\n",
              "         0,  0,  0,  1],\n",
              "       [ 1,  0,  0,  0,  0,  0,  2,  3,  0,  1,  1,  0,  3,  2, 48,  1,\n",
              "         1,  1,  1,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0, 52,\n",
              "         0,  0,  2,  9],\n",
              "       [ 1,  0,  0,  0,  0,  0,  0,  2,  1,  1,  1,  0,  0,  0,  1,  0,\n",
              "        43,  1,  7,  1],\n",
              "       [ 2,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  1,  0,  0,  0,  0,\n",
              "         0, 39,  2,  1],\n",
              "       [ 3,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  1,  0,  2,  0,  1,\n",
              "         1,  0, 41,  3],\n",
              "       [ 6,  0,  1,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  1, 10,\n",
              "         2,  1,  2, 11]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiM8lvk2e2mh"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_pred,normalize=None):\n",
        "  cm=confusion_matrix(y_true,y_pred,normalize=normalize)\n",
        "  fig, ax = plt.subplots(figsize=(6,5))\n",
        "  if normalize == None:\n",
        "    fmt='d'\n",
        "    fig.suptitle('Confusion matrix without Normalization', fontsize=12)\n",
        "        \n",
        "  else :\n",
        "    fmt='0.2f'\n",
        "    fig.suptitle('Normalized confusion matrix', fontsize=12)\n",
        "    \n",
        "  ax=sns.heatmap(cm,cmap=plt.cm.Blues,annot=True,fmt=fmt)\n",
        "  ax.axhline(y=0, color='k',linewidth=1)\n",
        "  ax.axhline(y=cm.shape[1], color='k',linewidth=2)\n",
        "  ax.axvline(x=0, color='k',linewidth=1)\n",
        "  ax.axvline(x=cm.shape[0], color='k',linewidth=2)\n",
        " \n",
        "  ax.set_xlabel('Predicted label', fontsize=12)\n",
        "  ax.set_ylabel('True label', fontsize=12)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHqvmICSfnPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "cd05ad4d-d4f5-4e88-e0ef-10cab24a021d"
      },
      "source": [
        "plot_confusion_matrix(y_valid,predictions)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K7fwV-LKpJj"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}