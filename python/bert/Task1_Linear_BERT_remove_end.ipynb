{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task1_Linear_BERT_remove_end.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS2TfQFJE4M_",
        "outputId": "7c22f3f1-6a1a-486e-915a-b02eb512a88b"
      },
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import torchtext.data as ttd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "We will use The 20 Newsgroups dataset \n",
        "Dataset [homepage](http://qwone.com/~jason/20Newsgroups/): \n",
        "\n",
        "Scikit-learn includes some nice helper functions for retrieving the 20 Newsgroups dataset-- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html. We'll use them below to retrieve the dataset.\n",
        "\n",
        "Also look at results fron non- neural net models here : https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeF7owBRSnZN",
        "outputId": "940f7e1f-3fab-4343-9c74-71539f672be3"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec  1 23:36:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apbVI5sKSmG8",
        "outputId": "6d00e39d-ce12-41b0-dddb-7f4be79e4931"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXScUokPqyPx"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "train = fetch_20newsgroups(subset='train',\n",
        "                           remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "test = fetch_20newsgroups(subset='test',\n",
        "                           remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NS-Vxi0Pkt-",
        "outputId": "363fc1c6-3259-4bc9-dee9-347168a334a3"
      },
      "source": [
        "print(train.data[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV2eF-BiPrLZ",
        "outputId": "6cbbedf0-0084-440d-cdfc-5ece7c4c1977"
      },
      "source": [
        "print(train.target[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IqtsBCEPx-E",
        "outputId": "7752eb59-ee92-434f-dc6a-71aa8228f952"
      },
      "source": [
        "train.target_names"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3v7ZzA2QHv6",
        "outputId": "f68da7e5-e740-4c00-8599-e2af4d057ee9"
      },
      "source": [
        "len(train.target_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "0NiOeWmbRV_G",
        "outputId": "8dca36f7-cf89-4d72-89a8-bde955194aaf"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Plot the number of tokens of each length.\n",
        "sns.countplot(train.target);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWDUlEQVR4nO3dfbRddX3n8fdHAj6gEpAQYxIapqKW1VURMxSrtS1pFdASRERdPkTESccBB7QzDtaujk7btdRqfaoLh4oaFBXKg0TrAxSfxjUFTRQQCEq0UJIJSXxCLUst+p0/zi+bY7hJ7jk3+96b5P1a66yz92/v3+98773n3s/Zv73PuakqJEkCeNBMFyBJmj0MBUlSx1CQJHUMBUlSx1CQJHXmzHQBU3HooYfWkiVLZroMSdqjrF279rtVNW+ibXt0KCxZsoQ1a9bMdBmStEdJcueOtjl9JEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpE6voZBkbpLLktyWZF2SpyQ5JMk1SW5v9we3fZPkXUnWJ7kpyTF91iZJeqC+jxTeCXymqp4APBFYB5wHXFtVRwLXtnWAE4Ej220lcH7PtUmSttNbKCQ5CHg6cCFAVf28qn4ILAdWtd1WAae05eXARTVwHTA3yYK+6pMkPVCf72g+AtgKfCDJE4G1wDnA/Kra1Pa5G5jflhcCdw3139DaNg21kWQlgyMJDj/88N6K157vpCv/auQ+n3rOn+/WGp592cVj9fvkaS/arXXsLT59yXdH7nPi8w/toZK9V5+hMAc4BnhVVV2f5J3cP1UEQFVVkpH+9VtVXQBcALB06VL/bZx686wrxpvB/MdTX7lb6zj5sk+M3Gf1aX+8W2vQvqPPUNgAbKiq69v6ZQxCYXOSBVW1qU0PbWnbNwKLh/ovam2aRv/7Q88cq9+fvOSzu7WOE6967sh9Pr388t1ag+73/CvWj9XvklMf2y2/58rNY41x1nPm73on7Ta9hUJV3Z3kriSPr6pvAsuAW9ttBfCmdn9V67IaODvJx4DfBu4Zmmaa9W57z/Kx+j3hrKu65S/8/bNG7v/7/+kfx3pc7Vuec/mXR+5z5XOf1kMlmu36/pTUVwEXJzkA+A5wBoOT25cmORO4Ezi97fsp4CRgPXBv21eSNI16DYWqugFYOsGmZRPsW8BZfdazI3efP/oJSYBHv3L3npTcW7zh0vGmoN5w+u6dgpI0Ot/RLEnq7NH/ZEcPdNkHThi5z2lnfKaHSiTtiTxSkCR1DAVJUsdQkCR1DAVJUscTzZI0gk1vGe+DFha8duFurqQfHilIkjqGgiSpYyhIkjqGgiSpYyhIkjpefSRpn/L1923Z9U7bedIrDuuhktnJIwVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1eg2FJHck+UaSG5KsaW2HJLkmye3t/uDWniTvSrI+yU1JjumzNknSA03HkcIfVNXRVbW0rZ8HXFtVRwLXtnWAE4Ej220lcP401CZJGjIT00fLgVVteRVwylD7RTVwHTA3yYIZqE+S9ll9h0IBVydZm2Rla5tfVZva8t3A/La8ELhrqO+G1vYrkqxMsibJmq1bt/ZVtyTtk/r+JztPq6qNSQ4Drkly2/DGqqokNcqAVXUBcAHA0qVLR+orSdq5Xo8Uqmpju98CXAkcC2zeNi3U7rf9G6SNwOKh7otamyRpmvQWCkkOTPKIbcvAM4CbgdXAirbbCuCqtrwaeGm7Cuk44J6haSZJ0jToc/poPnBlkm2P85Gq+kySrwKXJjkTuBM4ve3/KeAkYD1wL3BGj7VJkibQWyhU1XeAJ07Q/j1g2QTtBZzVVz2SpF3zHc2SpE7fVx9Ni63nf3jkPvNe+eIeKpGkPZtHCpKkjqEgSeoYCpKkjqEgSersFSeaJWlPsvkda0fuM//cJ/dQyQN5pCBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6vQeCkn2S/L1JJ9s60ckuT7J+iSXJDmgtT+4ra9v25f0XZsk6VdNx5HCOcC6ofU3A2+vqscCPwDObO1nAj9o7W9v+0mSplGvoZBkEfAs4H1tPcDxwGVtl1XAKW15eVunbV/W9pckTZO+jxTeAbwW+GVbfxTww6q6r61vABa25YXAXQBt+z1t/1+RZGWSNUnWbN26tc/aJWmf01soJHk2sKWq1u7OcavqgqpaWlVL582btzuHlqR93pwex34qcHKSk4CHAI8E3gnMTTKnHQ0sAja2/TcCi4ENSeYABwHf67E+SdJ2ejtSqKrXVdWiqloCvAD4XFW9CPg8cFrbbQVwVVte3dZp2z9XVdVXfZKkB5qJ9yn8D+A1SdYzOGdwYWu/EHhUa38NcN4M1CZJ+7Q+p486VfUF4Att+TvAsRPs81PgedNRjyRpYr6jWZLUMRQkSZ1pmT6SJO1eW/7u6pH7HHb2M3a5j0cKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqTOpEIhybWTaZMk7dl2+jEXSR4CPAw4NMnBwLb/mfxI7v83mpKkvcSuPvvoT4BzgccAa7k/FH4E/F2PdUmSZsBOQ6Gq3gm8M8mrqurd01STJGmGTOpTUqvq3Ul+B1gy3KeqLuqpLknSDJhUKCT5EPDrwA3AL1pzAYaCJO1FJvv/FJYCR1VV9VmMJGlmTfZ9CjcDj+6zEEnSzJvskcKhwK1JvgL8bFtjVZ3cS1WSpBkx2VB4Q59FSJJmh8leffTFvguRJM28yV599GMGVxsBHADsD/xbVT2yr8IkSdNvskcKj9i2nCTAcuC4voqSJM2MkT8ltQY+DjxzZ/sleUiSryS5McktSd7Y2o9Icn2S9UkuSXJAa39wW1/fti8Z4+uRJE3BZKePTh1afRCD9y38dBfdfgYcX1U/SbI/8OUknwZeA7y9qj6W5L3AmcD57f4HVfXYJC8A3gw8f7QvR5I0FZM9UvjjodszgR8zmELaoXZE8ZO2un+7FXA8cFlrXwWc0paXt3Xa9mVtqkqSNE0me07hjHEGT7Ifg09XfSzwHuDbwA+r6r62ywbu/wjuhcBd7fHuS3IP8Cjgu9uNuRJYCXD44YePU5YkaQcm+092FiW5MsmWdrs8yaJd9auqX1TV0cAi4FjgCVOsl6q6oKqWVtXSefPmTXU4SdKQyU4ffQBYzeD/KjwG+ERrm5Sq+iHweeApwNwk245QFgEb2/JGYDFA234Q8L3JPoYkaeomGwrzquoDVXVfu30Q2OnL9CTzksxtyw8F/ghYxyAcTmu7rQCuasur2zpt++f8AD5Jml6T/ZiL7yV5MfDRtv5Cdv0qfgGwqp1XeBBwaVV9MsmtwMeS/BXwdeDCtv+FwIeSrAe+D7xghK9DkrQbTDYUXg68G3g7gyuI/i/wsp11qKqbgCdN0P4dBucXtm//KfC8SdYjSerBZEPhfwErquoHAEkOAd7KICwkSXuJyZ5T+K1tgQBQVd9ngqMASdKebbKh8KAkB29baUcKkz3KkCTtISb7h/1twD8n+Ye2/jzgr/spSZI0Uyb7juaLkqxh8BEVAKdW1a39lSVJmgmTngJqIWAQSNJebOSPzpYk7b0MBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSp7dQSLI4yeeT3JrkliTntPZDklyT5PZ2f3BrT5J3JVmf5KYkx/RVmyRpYn0eKdwH/GlVHQUcB5yV5CjgPODaqjoSuLatA5wIHNluK4Hze6xNkjSB3kKhqjZV1dfa8o+BdcBCYDmwqu22CjilLS8HLqqB64C5SRb0VZ8k6YGm5ZxCkiXAk4DrgflVtaltuhuY35YXAncNddvQ2rYfa2WSNUnWbN26tbeaJWlf1HsoJHk4cDlwblX9aHhbVRVQo4xXVRdU1dKqWjpv3rzdWKkkqddQSLI/g0C4uKquaM2bt00LtfstrX0jsHio+6LWJkmaJn1efRTgQmBdVf3t0KbVwIq2vAK4aqj9pe0qpOOAe4ammSRJ02BOj2M/FXgJ8I0kN7S2PwPeBFya5EzgTuD0tu1TwEnAeuBe4Iwea5MkTaC3UKiqLwPZweZlE+xfwFl91SNJ2jXf0SxJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6vQWCknen2RLkpuH2g5Jck2S29v9wa09Sd6VZH2Sm5Ic01ddkqQd6/NI4YPACdu1nQdcW1VHAte2dYATgSPbbSVwfo91SZJ2oLdQqKovAd/frnk5sKotrwJOGWq/qAauA+YmWdBXbZKkiU33OYX5VbWpLd8NzG/LC4G7hvbb0NoeIMnKJGuSrNm6dWt/lUrSPmjGTjRXVQE1Rr8LqmppVS2dN29eD5VJ0r5rukNh87ZpoXa/pbVvBBYP7beotUmSptF0h8JqYEVbXgFcNdT+0nYV0nHAPUPTTJKkaTKnr4GTfBT4feDQJBuA/wm8Cbg0yZnAncDpbfdPAScB64F7gTP6qkuStGO9hUJVvXAHm5ZNsG8BZ/VViyRpcnxHsySpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqzKhSSnJDkm0nWJzlvpuuRpH3NrAmFJPsB7wFOBI4CXpjkqJmtSpL2LbMmFIBjgfVV9Z2q+jnwMWD5DNckSfuUVNVM1wBAktOAE6rqFW39JcBvV9XZ2+23EljZVh8PfHMnwx4KfHeKpe0tY8yGGmbLGLOhhtkyxmyoYbaMMRtqmK4xfq2q5k20Yc4UH3jaVdUFwAWT2TfJmqpaOpXH21vGmA01zJYxZkMNs2WM2VDDbBljNtQwG8aYTdNHG4HFQ+uLWpskaZrMplD4KnBkkiOSHAC8AFg9wzVJ0j5l1kwfVdV9Sc4GPgvsB7y/qm6Z4rCTmmbaR8aYDTXMljFmQw2zZYzZUMNsGWM21DDjY8yaE82SpJk3m6aPJEkzzFCQJHX22lCY6kdmJHl/ki1Jbh7z8Rcn+XySW5PckuScMcZ4SJKvJLmxjfHGcWppY+2X5OtJPjlm/zuSfCPJDUnWjNF/bpLLktyWZF2Sp4zY//HtsbfdfpTk3DHqeHX7Xt6c5KNJHjLGGOe0/rdMtoaJnk9JDklyTZLb2/3BI/Z/Xqvhl0l2efnhDsb4m/YzuSnJlUnmjjHGX7b+NyS5OsljRh1jaNufJqkkh45YwxuSbBx6fpw0Tg1JXtW+H7ckecuoYyS5ZKiGO5LcMMYYRye5btvvWpJjR+z/xCT/3H5fP5HkkTur4QGqaq+7MThR/W3gPwAHADcCR404xtOBY4Cbx6xhAXBMW34E8K0xagjw8La8P3A9cNyY9bwG+AjwyTH73wEcOoWfySrgFW35AGDuFH++dzN4A84o/RYC/wI8tK1fCrxsxDF+E7gZeBiDCzX+CXjsOM8n4C3AeW35PODNI/b/DQZv4PwCsHTMGp4BzGnLb95ZDTsZ45FDy/8VeO+oY7T2xQwuNLlzZ8+1HdTwBuC/jfBznGiMP2g/zwe39cPG+TqGtr8N+Isx6rgaOLEtnwR8YcT+XwV+ry2/HPjLUZ7je+uRwpQ/MqOqvgR8f9wCqmpTVX2tLf8YWMfgj9IoY1RV/aSt7t9uI18ZkGQR8CzgfaP23R2SHMTgyXshQFX9vKp+OIUhlwHfrqo7x+g7B3hokjkM/rD/vxH7/wZwfVXdW1X3AV8ETt1Vpx08n5YzCEva/Smj9K+qdVW1s3f0T2aMq9vXAXAdg/cHjTrGj4ZWD2QXz9Gd/G69HXjtFPpP2g7GeCXwpqr6Wdtny7h1JAlwOvDRMcYoYNur+4PYyXN0B/0fB3ypLV8DPHdnNWxvbw2FhcBdQ+sbGPEP8u6UZAnwJAav9Eftu187BN0CXFNVI48BvIPBL9svx+i7TQFXJ1mbwUeNjOIIYCvwgTaF9b4kB06hlhewi1+2iVTVRuCtwL8Cm4B7qurqEYe5GfjdJI9K8jAGr+QW76LPjsyvqk1t+W5g/pjj7C4vBz49Tsckf53kLuBFwF+M0X85sLGqbhzn8Zuz2zTW+3c2FbcTj2Pws70+yReT/Mcp1PK7wOaqun2MvucCf9O+n28FXjdi/1u4/0Xw8xjx+bm3hsKskeThwOXAudu9opqUqvpFVR3N4BXcsUl+c8THfzawparWjvrY23laVR3D4FNsz0ry9BH6zmFwiHt+VT0J+DcG0yUjy+CNjScD/zBG34MZ/LIcATwGODDJi0cZo6rWMZhmuRr4DHAD8ItRa5lg3GKMo8DdJcnrgfuAi8fpX1Wvr6rFrf/Zu9p/u8d+GPBnjBEmQ84Hfh04mkHgv22MMeYAhwDHAf8duLS94h/HCxnjhUvzSuDV7fv5atoR9gheDvyXJGsZTF3/fJTOe2sozIqPzEiyP4NAuLiqrpjKWG265fPACSN2fSpwcpI7GEyjHZ/kw2M8/sZ2vwW4ksEU3WRtADYMHeVcxiAkxnEi8LWq2jxG3z8E/qWqtlbVvwNXAL8z6iBVdWFVPbmqng78gMH5onFsTrIAoN3vdLqiL0leBjwbeFELp6m4mBGnKxj8MT8CuLE9TxcBX0vy6MkOUFWb2wuoXwJ/z2jPz202AFe0aduvMDiy3uEJ7x1pU5OnApeMUQPACgbPTRi8+Bnpa6mq26rqGVX1ZAbB9O1R+u+toTDjH5nRXmFcCKyrqr8dc4x5264GSfJQ4I+A20YZo6peV1WLqmoJg+/D56pqpFfHSQ5M8ohtywxOTk76qqyquhu4K8njW9My4NZRahgylVdg/wocl+Rh7eezjMG5npEkOazdH87gl/8jY9azmsEfANr9VWOOM7YkJzCYWjy5qu4dc4wjh1aXM/pz9BtVdVhVLWnP0w0MLtK4e4QaFgytPocRnp9DPs7gZDNJHsfggohxPq30D4HbqmrDGH1hcA7h99ry8cBIU1BDz88HAX8OvHekRx/lrPSedGMw1/stBin5+jH6f5TBYei/M3iSnjli/6cxmA64icEUww3ASSOO8VvA19sYN7OLKxkmMd7vM8bVRwyu4rqx3W4Z8/t5NLCmfS0fBw4eY4wDge8BB03he/BGBn+0bgY+RLvSZMQx/g+DULsRWDbu8wl4FHAtg1/6fwIOGbH/c9ryz4DNwGfHqGE9g/Nv256ju7pyaKIxLm/fz5uATwALRx1ju+13sPOrjyaq4UPAN1oNq4EFY3wdBwAfbl/L14Djx/k6gA8C/3kKz4unAWvb8+t64Mkj9j+Hwd++bwFvon1yxWRvfsyFJKmzt04fSZLGYChIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp8/8BhAfOHfipLI8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RX3KKlFtdUR"
      },
      "source": [
        "#BERT with 140 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5PWjsT0FeKm",
        "outputId": "bdbaa6d0-3aa9-4356-a25d-0e10c03eadf4"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hI6d8597O40",
        "outputId": "7c4bd7fc-6dbb-4e2c-d4d4-fffc9f45fe31"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 140,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train.data[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: tensor([  101,  1045,  2001,  6603,  2065,  3087,  2041,  2045,  2071,  4372,\n",
            "         7138,  2368,  2033,  2006,  2023,  2482,  1045,  2387,  1996,  2060,\n",
            "         2154,  1012,  2009,  2001,  1037,  1016,  1011,  2341,  2998,  2482,\n",
            "         1010,  2246,  2000,  2022,  2013,  1996,  2397, 20341,  1013,  2220,\n",
            "        17549,  1012,  2009,  2001,  2170,  1037,  5318,  4115,  1012,  1996,\n",
            "         4303,  2020,  2428,  2235,  1012,  1999,  2804,  1010,  1996,  2392,\n",
            "        21519,  2001,  3584,  2013,  1996,  2717,  1997,  1996,  2303,  1012,\n",
            "         2023,  2003,  2035,  1045,  2113,  1012,  2065,  3087,  2064,  2425,\n",
            "         4168,  1037,  2944,  2171,  1010,  3194, 28699,  2015,  1010,  2086,\n",
            "         1997,  2537,  1010,  2073,  2023,  2482,  2003,  2081,  1010,  2381,\n",
            "         1010,  2030,  3649, 18558,  2017,  2031,  2006,  2023, 24151,  2559,\n",
            "         2482,  1010,  3531,  1041,  1011,  5653,  1012,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK1TbacGPzi4",
        "outputId": "fa1f3dfa-8533-4b3f-d203-5aff63fa97c9"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 140,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test.data[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "Token IDs: tensor([  101,  1045,  2572,  1037,  2210,  5457,  2006,  2035,  1997,  1996,\n",
            "         4275,  1997,  1996,  6070,  1011,  6486, 19349, 21187,  2015,  1012,\n",
            "         1045,  2031,  2657,  1997,  1996,  3393,  7367,  1048,  3366,  7020,\n",
            "         2063,  7020,  7416,  1012,  2071,  2619,  2425,  2033,  1996,  5966,\n",
            "         2024,  2521,  2004,  2838,  2030,  2836,  1012,  1045,  2572,  2036,\n",
            "         8025,  2000,  2113,  2054,  1996,  2338,  3643,  2003,  2005,  9544,\n",
            "         5243,  6321,  1996,  6486,  2944,  1012,  1998,  2129,  2172,  2625,\n",
            "         2084,  2338,  3643,  2064,  2017,  2788,  2131,  2068,  2005,  1012,\n",
            "         1999,  2060,  2616,  2129,  2172,  2024,  2027,  1999,  5157,  2023,\n",
            "         2051,  1997,  2095,  1012,  1045,  2031,  2657,  2008,  1996,  3054,\n",
            "         1011,  3500,  2220,  2621,  2003,  1996,  2190,  2051,  2000,  4965,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NAIfyBP7jMn",
        "outputId": "7a0626e3-7cdb-4d9c-cdb2-0b1be5eee2bc"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} test samples'.format(len(test_dataset)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10,182 training samples\n",
            "1,132 validation samples\n",
            "7,532 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM1fTM-pENir"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(test_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzW80b9MN4Gc"
      },
      "source": [
        "from transformers import  BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4WgTB4BN5rp",
        "outputId": "8492c807-0502-4cfd-952d-e511fa89f3c2"
      },
      "source": [
        "bert_model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gDXa2-dN6HK"
      },
      "source": [
        "# Define the model\n",
        "class linear(nn.Module):\n",
        "\n",
        "  def __init__(self, bert_model, n_outputs, dropout_rate):\n",
        "  \n",
        "    super(linear, self).__init__()\n",
        "\n",
        "    self.D = bert_model.config.to_dict()['hidden_size']\n",
        "    self.bert_model = bert_model\n",
        "    self.K = n_outputs    \n",
        "    self.dropout_rate=dropout_rate\n",
        "    \n",
        "    # embedding layer\n",
        "    #self.embed = nn.Embedding(self.V, self.D)\n",
        "    \n",
        "   \n",
        "    # dense layer\n",
        "    self.fc = nn.Linear(self.D , self.K)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout= nn.Dropout(self.dropout_rate)\n",
        "  \n",
        "  def forward(self, X):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = self.bert_model(X)[0][:,0,:]\n",
        "    \n",
        "    #embedding= self.dropout(embedding) \n",
        "\n",
        "    output = self.fc(embedding)\n",
        "    output= self.dropout(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfmumBc2OBgh"
      },
      "source": [
        "n_outputs = 20\n",
        "dropout_rate = 0.5"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0Coc3DvO9YR",
        "outputId": "bede2b29-953a-4c3f-eed0-1f437aefbb8b"
      },
      "source": [
        "#model = RNN(n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
        "model = linear(bert_model, n_outputs, dropout_rate)\n",
        "model.to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "linear(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IervsCFUPFTo",
        "outputId": "9b4ac5fe-fd2d-4538-ec2a-ab41414969f4"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear(\n",
            "  (bert_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=768, out_features=20, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y74u806ePJSj",
        "outputId": "8c154f27-7f75-4bd5-cea8-4f50993a73b1"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_model.embeddings.word_embeddings.weight torch.Size([30522, 768])\n",
            "bert_model.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "bert_model.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "bert_model.embeddings.LayerNorm.weight torch.Size([768])\n",
            "bert_model.embeddings.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.pooler.dense.weight torch.Size([768, 768])\n",
            "bert_model.pooler.dense.bias torch.Size([768])\n",
            "fc.weight torch.Size([20, 768])\n",
            "fc.bias torch.Size([20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbNhEhe4PL8t",
        "outputId": "16259e9a-02bd-404a-82e8-d35670ea0864"
      },
      "source": [
        "import random\n",
        "\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs=10\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "#model.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model.train()\n",
        "  for batch in train_dataloader:\n",
        "   \n",
        "    # forward pass\n",
        "    output= model(batch[0].to(device))\n",
        "    loss=criterion(output,batch[2].to(device))\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_dataloader:\n",
        " \n",
        "      # forward pass\n",
        "      output= model(batch[0].to(device))\n",
        "      loss=criterion(output,batch[2].to(device))\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 2.7517    Valid Loss: 2.3021, Duration: 0:00:55.957106\n",
            "Epoch 2/10, Train Loss: 2.5580    Valid Loss: 2.1465, Duration: 0:00:55.912594\n",
            "Epoch 3/10, Train Loss: 2.4920    Valid Loss: 2.0520, Duration: 0:00:55.919293\n",
            "Epoch 4/10, Train Loss: 2.4778    Valid Loss: 2.0167, Duration: 0:00:55.986673\n",
            "Epoch 5/10, Train Loss: 2.4475    Valid Loss: 1.9217, Duration: 0:00:55.934424\n",
            "Epoch 6/10, Train Loss: 2.4218    Valid Loss: 1.9241, Duration: 0:00:55.974224\n",
            "Epoch 7/10, Train Loss: 2.4202    Valid Loss: 1.8931, Duration: 0:00:55.915101\n",
            "Epoch 8/10, Train Loss: 2.4142    Valid Loss: 1.8560, Duration: 0:00:55.933802\n",
            "Epoch 9/10, Train Loss: 2.4068    Valid Loss: 1.9132, Duration: 0:00:55.909939\n",
            "Epoch 10/10, Train Loss: 2.3867    Valid Loss: 1.8397, Duration: 0:00:55.986418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEemAE_aPS1s"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      output=model(batch[0].to(device))\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct+= (batch[2].to(device)==indices).sum().item()\n",
        "      total += batch[2].shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqSxTbpgPWpM",
        "outputId": "ce353e24-a948-48d1-9f4e-d9305e220679"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model)\n",
        "valid_acc = get_accuracy(validation_dataloader, model)\n",
        "test_acc = get_accuracy(test_dataloader ,model)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.5084,\t Valid acc: 0.4735,\t Test acc: 0.4494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P8ecAVPY-4"
      },
      "source": [
        "# Write a function to get predictions\n",
        "\n",
        "def get_predictions(test_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in test_iter:\n",
        "      \n",
        "      output=model(batch[0].to(device))\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,batch[2].numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMtCseNNPcSx"
      },
      "source": [
        "y_test, predictions=get_predictions(test_dataloader, model)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiRamnIOPeY7",
        "outputId": "3519cb87-9668-4099-8192-b35866e7deeb"
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 54,  16,   0,   2,   0,   0,   1,   1,   4,   0,   1,   5,   0,\n",
              "         26,  43,  40,   4,  15,  99,   8],\n",
              "       [  1, 220,   5,  29,   8,  18,   3,   0,   1,   0,   0,  10,   3,\n",
              "         13,  44,   1,   1,   1,  31,   0],\n",
              "       [  0, 112,  53,  81,  15,  28,   0,   1,   2,   0,   0,   8,   0,\n",
              "          9,  50,   1,   1,   1,  32,   0],\n",
              "       [  0,  67,   3, 228,  27,   0,   4,   2,   3,   0,   0,   6,   1,\n",
              "         10,  34,   0,   0,   1,   6,   0],\n",
              "       [  1,  50,   6, 119,  89,   3,   5,   5,   3,   0,   0,   9,   4,\n",
              "         25,  52,   0,   0,   1,  13,   0],\n",
              "       [  0, 110,  15,  48,   6, 136,   3,   0,   3,   0,   0,  10,   0,\n",
              "          6,  32,   0,   0,   0,  26,   0],\n",
              "       [  0,  58,   0,  57,   6,   0, 178,   6,   5,   0,   0,   6,   1,\n",
              "         14,  37,   0,   1,   0,  21,   0],\n",
              "       [  0,  11,   0,  10,   6,   0,   9, 200,  17,   0,   0,   4,   3,\n",
              "         16,  73,   0,   2,   0,  45,   0],\n",
              "       [  2,  22,   0,  14,   7,   0,   5,  41, 144,   1,   0,   4,   4,\n",
              "         12,  63,   0,   8,   0,  70,   1],\n",
              "       [  1,  17,   0,   2,   2,   0,   0,   2,   2, 242,  15,   1,   0,\n",
              "          8,  48,   0,   1,   1,  54,   1],\n",
              "       [  1,   9,   1,   1,   0,   1,   1,   2,   1,  10, 261,   0,   0,\n",
              "         10,  53,   1,   0,   2,  45,   0],\n",
              "       [  1,  29,   4,  25,   3,   2,   1,   0,   0,   1,   0, 167,   3,\n",
              "         10,  55,   0,   9,   6,  80,   0],\n",
              "       [  0,  58,   1,  81,  13,   0,   4,  10,   6,   0,   0,  17,  78,\n",
              "         44,  54,   3,   0,   0,  24,   0],\n",
              "       [  3,  23,   0,   5,   0,   1,   0,   2,   3,   0,   0,   2,   4,\n",
              "        259,  58,   4,   0,   2,  29,   1],\n",
              "       [  2,  16,   0,   7,   1,   0,   1,   3,   1,   0,   0,   6,   5,\n",
              "         13, 284,   3,   1,   1,  50,   0],\n",
              "       [ 18,  10,   0,   7,   0,   0,   0,   1,   1,   0,   0,   5,   0,\n",
              "         22,  34, 235,   2,   1,  45,  17],\n",
              "       [  5,  20,   0,   1,   0,   0,   0,   5,   6,   0,   0,  15,   1,\n",
              "         31,  43,   1, 110,   3, 122,   1],\n",
              "       [  5,   4,   1,   1,   1,   0,   0,   1,   0,   1,   0,   3,   0,\n",
              "          4,  37,   2,   1, 229,  82,   4],\n",
              "       [  3,   5,   0,   1,   1,   0,   0,   1,   3,   0,   0,   4,   0,\n",
              "         19,  34,   5,  38,   5, 189,   2],\n",
              "       [ 16,   5,   0,   0,   1,   0,   1,   3,   3,   1,   0,   3,   0,\n",
              "         14,  38,  61,  14,   4,  58,  29]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y8qVpTVPgjc"
      },
      "source": [
        "# Write a function to print confusion matrix\n",
        "# plot confusion matrix\n",
        "# need to import confusion_matrix from sklearn for this function to work\n",
        "# need to import seaborn as sns\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_pred,normalize=None):\n",
        "  cm=confusion_matrix(y_true,y_pred,normalize=normalize)\n",
        "  fig, ax = plt.subplots(figsize=(6,5))\n",
        "  if normalize == None:\n",
        "    fmt='d'\n",
        "    fig.suptitle('Confusion matrix without Normalization', fontsize=12)\n",
        "        \n",
        "  else :\n",
        "    fmt='0.2f'\n",
        "    fig.suptitle('Normalized confusion matrix', fontsize=12)\n",
        "    \n",
        "  ax=sns.heatmap(cm,cmap=plt.cm.Blues,annot=True,fmt=fmt)\n",
        "  ax.axhline(y=0, color='k',linewidth=1)\n",
        "  ax.axhline(y=cm.shape[1], color='k',linewidth=2)\n",
        "  ax.axvline(x=0, color='k',linewidth=1)\n",
        "  ax.axvline(x=cm.shape[0], color='k',linewidth=2)\n",
        " \n",
        "  ax.set_xlabel('Predicted label', fontsize=12)\n",
        "  ax.set_ylabel('True label', fontsize=12)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vGCxda-6Pkmp",
        "outputId": "c275e8ed-f88f-451a-d223-d6cad99ffea8"
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMp3aD9vs9rN"
      },
      "source": [
        "#BERT with 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og4MRa_as3gN",
        "outputId": "51efdc7f-c609-4fb0-d003-884533aa6302"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llLtlYMus3gN",
        "outputId": "7703beb5-bd20-44c1-cbb8-a296ecfb2c9a"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train.data[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: tensor([  101,  1045,  2001,  6603,  2065,  3087,  2041,  2045,  2071,  4372,\n",
            "         7138,  2368,  2033,  2006,  2023,  2482,  1045,  2387,  1996,  2060,\n",
            "         2154,  1012,  2009,  2001,  1037,  1016,  1011,  2341,  2998,  2482,\n",
            "         1010,  2246,  2000,  2022,  2013,  1996,  2397, 20341,  1013,  2220,\n",
            "        17549,  1012,  2009,  2001,  2170,  1037,  5318,  4115,  1012,  1996,\n",
            "         4303,  2020,  2428,  2235,  1012,  1999,  2804,  1010,  1996,  2392,\n",
            "        21519,  2001,  3584,  2013,  1996,  2717,  1997,  1996,  2303,  1012,\n",
            "         2023,  2003,  2035,  1045,  2113,  1012,  2065,  3087,  2064,  2425,\n",
            "         4168,  1037,  2944,  2171,  1010,  3194, 28699,  2015,  1010,  2086,\n",
            "         1997,  2537,  1010,  2073,  2023,  2482,  2003,  2081,  1010,  2381,\n",
            "         1010,  2030,  3649, 18558,  2017,  2031,  2006,  2023, 24151,  2559,\n",
            "         2482,  1010,  3531,  1041,  1011,  5653,  1012,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2sJLFNDs3gO",
        "outputId": "19ba96f4-94ba-48b2-8c00-6f2a02e51532"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test.data[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "Token IDs: tensor([  101,  1045,  2572,  1037,  2210,  5457,  2006,  2035,  1997,  1996,\n",
            "         4275,  1997,  1996,  6070,  1011,  6486, 19349, 21187,  2015,  1012,\n",
            "         1045,  2031,  2657,  1997,  1996,  3393,  7367,  1048,  3366,  7020,\n",
            "         2063,  7020,  7416,  1012,  2071,  2619,  2425,  2033,  1996,  5966,\n",
            "         2024,  2521,  2004,  2838,  2030,  2836,  1012,  1045,  2572,  2036,\n",
            "         8025,  2000,  2113,  2054,  1996,  2338,  3643,  2003,  2005,  9544,\n",
            "         5243,  6321,  1996,  6486,  2944,  1012,  1998,  2129,  2172,  2625,\n",
            "         2084,  2338,  3643,  2064,  2017,  2788,  2131,  2068,  2005,  1012,\n",
            "         1999,  2060,  2616,  2129,  2172,  2024,  2027,  1999,  5157,  2023,\n",
            "         2051,  1997,  2095,  1012,  1045,  2031,  2657,  2008,  1996,  3054,\n",
            "         1011,  3500,  2220,  2621,  2003,  1996,  2190,  2051,  2000,  4965,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mngSluAWs3gO",
        "outputId": "3004dd81-e859-44eb-93fc-c7eef174c9c9"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} test samples'.format(len(test_dataset)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10,182 training samples\n",
            "1,132 validation samples\n",
            "7,532 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMZlyqpjs3gO"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(test_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjoOur4ls3gO"
      },
      "source": [
        "from transformers import  BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8t1te9os3gO",
        "outputId": "2b253829-1d5f-49d3-f655-eeb0b50230c7"
      },
      "source": [
        "bert_model"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh5ECmmLs3gO"
      },
      "source": [
        "# Define the model\n",
        "class linear(nn.Module):\n",
        "\n",
        "  def __init__(self, bert_model, n_outputs, dropout_rate):\n",
        "  \n",
        "    super(linear, self).__init__()\n",
        "\n",
        "    self.D = bert_model.config.to_dict()['hidden_size']\n",
        "    self.bert_model = bert_model\n",
        "    self.K = n_outputs    \n",
        "    self.dropout_rate=dropout_rate\n",
        "    \n",
        "    # embedding layer\n",
        "    #self.embed = nn.Embedding(self.V, self.D)\n",
        "    \n",
        "   \n",
        "    # dense layer\n",
        "    self.fc = nn.Linear(self.D , self.K)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout= nn.Dropout(self.dropout_rate)\n",
        "  \n",
        "  def forward(self, X):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = self.bert_model(X)[0][:,0,:]\n",
        "    \n",
        "    #embedding= self.dropout(embedding) \n",
        "\n",
        "    output = self.fc(embedding)\n",
        "    output= self.dropout(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaWwMHehs3gO"
      },
      "source": [
        "n_outputs = 20\n",
        "dropout_rate = 0.5"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw8HGuyYs3gO",
        "outputId": "650a3733-2fb9-41a1-9f72-1312eb64b00a"
      },
      "source": [
        "#model = RNN(n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
        "model = linear(bert_model, n_outputs, dropout_rate)\n",
        "model.to(device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "linear(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ueislYs3gO",
        "outputId": "6a57ddb5-d125-453a-d96f-a29fabbf8b4a"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear(\n",
            "  (bert_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=768, out_features=20, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2G1iryHs3gO",
        "outputId": "5c8991fb-2a5e-496b-db23-41eddc437ce4"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_model.embeddings.word_embeddings.weight torch.Size([30522, 768])\n",
            "bert_model.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "bert_model.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "bert_model.embeddings.LayerNorm.weight torch.Size([768])\n",
            "bert_model.embeddings.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.pooler.dense.weight torch.Size([768, 768])\n",
            "bert_model.pooler.dense.bias torch.Size([768])\n",
            "fc.weight torch.Size([20, 768])\n",
            "fc.bias torch.Size([20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwpXN3MVs3gO",
        "outputId": "f714b0e9-83a9-4542-c50b-6564134b29bf"
      },
      "source": [
        "import random\n",
        "\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs=10\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "#model.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model.train()\n",
        "  for batch in train_dataloader:\n",
        "   \n",
        "    # forward pass\n",
        "    output= model(batch[0].to(device))\n",
        "    loss=criterion(output,batch[2].to(device))\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_dataloader:\n",
        " \n",
        "      # forward pass\n",
        "      output= model(batch[0].to(device))\n",
        "      loss=criterion(output,batch[2].to(device))\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 2.7181    Valid Loss: 2.1756, Duration: 0:00:52.097921\n",
            "Epoch 2/10, Train Loss: 2.5172    Valid Loss: 2.0393, Duration: 0:00:51.956894\n",
            "Epoch 3/10, Train Loss: 2.4376    Valid Loss: 1.9340, Duration: 0:00:51.921139\n",
            "Epoch 4/10, Train Loss: 2.4005    Valid Loss: 1.8955, Duration: 0:00:51.917111\n",
            "Epoch 5/10, Train Loss: 2.3927    Valid Loss: 1.8542, Duration: 0:00:51.926076\n",
            "Epoch 6/10, Train Loss: 2.3700    Valid Loss: 1.7962, Duration: 0:00:51.939493\n",
            "Epoch 7/10, Train Loss: 2.3622    Valid Loss: 1.7845, Duration: 0:00:51.973877\n",
            "Epoch 8/10, Train Loss: 2.3467    Valid Loss: 1.7723, Duration: 0:00:51.916696\n",
            "Epoch 9/10, Train Loss: 2.3558    Valid Loss: 1.7830, Duration: 0:00:51.929136\n",
            "Epoch 10/10, Train Loss: 2.3251    Valid Loss: 1.7442, Duration: 0:00:51.955068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlFtGphLs3gO"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      output=model(batch[0].to(device))\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct+= (batch[2].to(device)==indices).sum().item()\n",
        "      total += batch[2].shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EdzGc-Vs3gO",
        "outputId": "5c5d959b-41ce-49fb-b652-6fe9cfa13669"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model)\n",
        "valid_acc = get_accuracy(validation_dataloader, model)\n",
        "test_acc = get_accuracy(test_dataloader ,model)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.5166,\t Valid acc: 0.4806,\t Test acc: 0.4522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLRlFoGcs3gO"
      },
      "source": [
        "# Write a function to get predictions\n",
        "\n",
        "def get_predictions(test_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in test_iter:\n",
        "      \n",
        "      output=model(batch[0].to(device))\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,batch[2].numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1LzDm4fs3gO"
      },
      "source": [
        "y_test, predictions=get_predictions(test_dataloader, model)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYxKhmyFs3gO",
        "outputId": "fe3f3331-b214-472d-8976-829047eb7168"
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 58,  35,   0,   0,   0,   0,  22,  18,   1,  15,   0,   7,   0,\n",
              "         57,   1,  70,  12,  15,   8,   0],\n",
              "       [  0, 281,   8,   4,   5,   6,  36,   5,   0,  13,   0,   2,   2,\n",
              "         23,   2,   1,   0,   0,   1,   0],\n",
              "       [  1, 168, 114,  16,   3,  11,  23,   9,   1,   8,   0,   8,   0,\n",
              "         30,   0,   0,   2,   0,   0,   0],\n",
              "       [  0, 129,  28, 125,  14,   2,  41,  13,   0,   5,   0,   3,   6,\n",
              "         25,   1,   0,   0,   0,   0,   0],\n",
              "       [  0, 124,  19,  42,  65,   1,  48,  17,   2,   9,   0,   5,   5,\n",
              "         46,   0,   0,   2,   0,   0,   0],\n",
              "       [  0, 181,  23,  10,   4, 107,  37,   4,   0,   5,   0,   6,   0,\n",
              "         15,   1,   0,   1,   1,   0,   0],\n",
              "       [  0,  43,   3,   3,   1,   0, 303,   6,   1,   9,   0,   2,   1,\n",
              "         18,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,  24,   0,   0,   2,   0,  33, 268,   2,  11,   0,   0,   1,\n",
              "         44,   1,   1,   5,   0,   3,   0],\n",
              "       [  0,  44,   3,   1,   1,   0,  45, 118,  86,  29,   0,   3,   6,\n",
              "         47,   0,   2,  11,   0,   2,   0],\n",
              "       [  3,  22,   1,   0,   1,   0,  19,   8,   0, 302,   3,   1,   0,\n",
              "         29,   0,   1,   4,   0,   3,   0],\n",
              "       [  3,  20,   1,   0,   0,   0,  19,  14,   1,  87, 222,   0,   0,\n",
              "         24,   1,   2,   3,   1,   1,   0],\n",
              "       [  0,  58,   8,   3,   3,   2,  32,  13,   0,  12,   0, 182,   5,\n",
              "         41,   0,   4,  25,   2,   6,   0],\n",
              "       [  0, 103,   8,  25,   4,   0,  43,  23,   2,   9,   0,  12,  87,\n",
              "         73,   1,   2,   1,   0,   0,   0],\n",
              "       [  4,  16,   0,   0,   0,   0,  15,  13,   1,  11,   0,   1,   1,\n",
              "        321,   0,   8,   2,   0,   3,   0],\n",
              "       [  5,  80,   1,   1,   0,   0,  22,  18,   1,  13,   0,   4,   6,\n",
              "         67, 148,   9,   6,   0,  13,   0],\n",
              "       [  7,  32,   0,   0,   0,   0,  19,   7,   0,   5,   0,   0,   1,\n",
              "         56,   0, 263,   6,   1,   0,   1],\n",
              "       [  7,  31,   0,   0,   1,   0,  21,  24,   1,  12,   0,  16,   2,\n",
              "         55,   0,   8, 155,  14,  17,   0],\n",
              "       [ 10,  25,   1,   1,   1,   0,   4,  14,   1,  14,   0,   4,   0,\n",
              "         23,   0,  10,  14, 244,  10,   0],\n",
              "       [  7,  16,   1,   0,   0,   0,   3,  19,   0,  15,   0,   7,   1,\n",
              "         73,   2,  14,  67,  12,  73,   0],\n",
              "       [ 14,  30,   1,   0,   0,   0,  19,  16,   0,  11,   0,   2,   0,\n",
              "         35,   2,  90,  21,   3,   5,   2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8W7NLdLs3gO"
      },
      "source": [
        "# Write a function to print confusion matrix\n",
        "# plot confusion matrix\n",
        "# need to import confusion_matrix from sklearn for this function to work\n",
        "# need to import seaborn as sns\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_pred,normalize=None):\n",
        "  cm=confusion_matrix(y_true,y_pred,normalize=normalize)\n",
        "  fig, ax = plt.subplots(figsize=(6,5))\n",
        "  if normalize == None:\n",
        "    fmt='d'\n",
        "    fig.suptitle('Confusion matrix without Normalization', fontsize=12)\n",
        "        \n",
        "  else :\n",
        "    fmt='0.2f'\n",
        "    fig.suptitle('Normalized confusion matrix', fontsize=12)\n",
        "    \n",
        "  ax=sns.heatmap(cm,cmap=plt.cm.Blues,annot=True,fmt=fmt)\n",
        "  ax.axhline(y=0, color='k',linewidth=1)\n",
        "  ax.axhline(y=cm.shape[1], color='k',linewidth=2)\n",
        "  ax.axvline(x=0, color='k',linewidth=1)\n",
        "  ax.axvline(x=cm.shape[0], color='k',linewidth=2)\n",
        " \n",
        "  ax.set_xlabel('Predicted label', fontsize=12)\n",
        "  ax.set_ylabel('True label', fontsize=12)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "gGpKvnUHs3gO",
        "outputId": "f5ba2047-38b4-44cf-da2c-dfe3ca1daf27"
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFkCAYAAAAwtcDIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd1gVx/eH3wFEUURpdmNPbF9NbDEau8beu0YTY4kt9i5RrLGkqokt9lixaywxIqjYsdeosXdFBKRf5vfHXq4X5LalGPjt+zz7cO/unD1nZ5ZzZ2d3PiuklGhoaGhopH/s3nUAGhoaGhopg5bQNTQ0NDIIWkLX0NDQyCBoCV1DQ0Mjg6AldA0NDY0MgpbQNTQ0NDIIWkJPRwghnIQQO4QQr4QQPsnYT1chxF8pGdu7QghRQwhxLZV9hAkhiprZflsIUT81Y0ivCCGWCyGm6j+nSltlpPM5uWgJPRUQQnQRQpzSJ4JHQojdQohPU2DX7YDcgLuUsr3anUgpV0spP0uBeFIVIYQUQhQ3V0ZKeUhK+UFqxiGldJZS/quPyZCgUhshxJdCiMMWyvgJISKFEAWN1tUXQtxO9QBtJCXaSghRWH9eOBjtN12cz2mBltBTGCHEMOBnYDpK8n0P+A1omQK7LwT8I6WMTYF9pXuM/6n/n/Ma+DYldiSEsE+J/Wi8I6SU2pJCC5ADCAPamymTGSXhP9QvPwOZ9dtqA/eB4cBT4BHQQ79tEhANxOh99AS8gT+M9l0YkICD/vuXwL9AKHAL6Gq0/rCRXTXgJPBK/7ea0TY/YAoQoN/PX4CHiWOLj3+UUfytgCbAP0AQMM6ofBXgKBCsLzsPcNRvO6g/ltf64+1otP/RwGNgVfw6vU0xvY8K+u/5gGdA7SRi7QHsMPp+HfAx+n4P+FD/WQLFgT76+o/Wx7RDv/02MAI4r6/D9UAWo331Bm7oY9sO5EuqvYzquxdQCogEdHpfwSbq3A+YqG+bYvp19YHbRmVK6csFA5eAFkbblgPzgV36uq6vP56R+uN5DSxB6Zzs1vv5G3A12oePvj1e6dutTKL9TzU+P/SfO+qPK36JAvz025oCZ4AQfTt4G+3vrr7O4u0+IZXO5/S4vPMAMtICNAJijf9BkygzGTgG5AI8gSPAFP222nr7yUAmlEQYHv/Pw9sJPPF3Q4IAsun/IT7Qb8sb/49m/A8AuAEvgW56u8767+767X7ATeB9wEn/fYaJY4uPf4I+/t4oCXUNkB0oA0QARfTlKwJV9X4LA1eAIUb7k0DxJPY/E+WH0QmjJKEv0xu4DGQF9gLfm4i1KEqCs0NJ/Hd4k2yK6uvALnEcGCUoo33dBk7o9+OmP46++m11gedABX3Mc4GDidvLaF9+QK/E7WTmfPJD+QH4Mf5cwCih69vhBjAOcNTHE2p0XixHSXzV9XWRRX88x1CSeH6UH+fTwEf67b7ARKMYvtK3b3xn5azRNkN9JW4rozIu+jr72qjc//TxlAOeAK3M1JmhnkjB8zk9LtqQS8riDjyX5odEugKTpZRPpZTPUHre3Yy2x+i3x0gpd6H0QtSOO8YBZYUQTlLKR1LKS0mUaQpcl1KuklLGSinXAleB5kZllkkp/5FSRgAbgA/N+IwBpkkpY4B1gAfwi5QyVO//MlAeQEoZKKU8pvd7G1gI1LLimCZKKaP08SRASrkYJYEdR/kRG5/UTqQyJh6qP5aaKMn/oRCipD6GQ1LKOAuxGDNHSvlQShkE7OBNHXUFlkopT0spo4CxwCdCiMI27NsavgOaCyHKJFpfFXBGSVrRUkpfYCdKootnm5QyQEoZJ6WM1K+bK6V8IqV8ABwCjkspz+i3b0FJ7gBIKZfq2zcKpZNRXgiRw5qghRB2KD/4flLKhfr9+UkpL+jjOQ+sxfJ5EU9Kn8/pCi2hpywvAA8LY7vxvcF47ujXGfaR6AchHOUf0iaklK9RLmv7Ao+EEH/qk5WleOJjym/0/bEN8byQUur0n+MT7hOj7RHx9kKI94UQO4UQj4UQISj3HTzM7BvgmVHSMcVioCxKUooyU84fpTdYU//ZDyVx1NJ/twVTdZSgfqWUYSjniXH9Jht952AeytWdMfmAe4l+nBK3770kdpm4zUy1ob0QYoYQ4qa+DW/ry1hqx3imofTuB8WvEEJ8LIQ4IIR4JoR4hXIOW7u/lD6f0xVaQk9ZjqKMBbYyU+Yhys3NeN7Tr1PDa5ShhXjyGG+UUu6VUjZA6aleRUl0luKJj+mByphsYT5KXCWklC4owwLCgo1ZeVAhhDPKZf8SwFsI4WameHxCr6H/7I/lhG6rPGmC+hVCZEO5knuA0n5gug1t9TUbqIMylGXsv6C+JxxP4vZNjuRqF5Qb/vVR7iEV1q+31I4IITqhXCm001/RxbMG5V5DQSllDmCB0f4sxfouz+d3jpbQUxAp5SuU8eNfhRCthBBZhRCZhBCNhRCz9MXWAl5CCE8hhIe+/B8qXZ4Fagoh3tNf4o6N3yCEyC2EaKlPIFEoQzdJDSHsAt7XP2rpIIToCJRGuSxPbbKjjPOH6a8e+iXa/gRlPNsWfgFOSSl7AX+iJANT+KMkQCcp5X2UoYVGKAn3jAkbW2NaC/QQQnwohMiMchVyXEp5W9+rfgB8ru/pfoVyY9fYVwEhhKM1jqSUwcAPKDel4zmO0gsdpT8Xa6MMP6yz4RjMkR3l/HqB8sM03RojIcRHKPcTWunrIfE+g6SUkUKIKig/GvE8QzmPTbXBuzyf3zlaQk9hpJQ/AMMAL5ST7x4wENiqLzIVOIXyBMEFlJtNqp5rllLuQ3mi4jwQSMKT1k4fx0OUpytq8XbCREr5AmiG8mTNC5Rk0ExK+VxNTDYyAuWfNRTl6mF9ou3ewAohRLAQooOlnQkhWqIk5PjjHAZUEEJ0Taq8lPIflB+6Q/rvIShPBQUYDRslZglQWh/TVhNljH38jfJI4SaUJ3mKAZ2MivRGeaLkBcpN4yNG23xRnkp5LISwtj1+QXkyJt5/NEoCb4xyc/Y3oLuU8qqV+7PESpQhjQco90eOWWnXEnAFDuvna4QJIXbrt/UHJgshQlE6PBvijaSU4SjDNAH6NqhqvNN3fD6/c4SU2gsuNDQ0NDICWg9dQ0NDI4OgJXQNDQ2NDIKW0DU0NDQyCFpC19DQ0MggaAldQ0NDI4OgJXQNDQ2NDIKW0DU0NDQyCFpC19DQ0MggaAldQ0NDI4OgJXQNDQ2NDIKW0DU0NDQyCFpC19DQ0MggaAldQ0NDI4OgJXQNDQ2NDIKW0DU0NDQyCFpC19DQ0MggaAldQ0NDI4OgJXQNDQ2NDIKW0DU0NDQyCFpC19DQ0MggaAldQ0NDI4OgJXQNDQ2NDIKW0DU0NDQyCFpC19DQ0MggaAldQ0NDI4Pg8K4DsAYhhHzXMWhoaKQPpJQiuftw+migzTkn4sy8ZPtNLukioQNcuB9qU/kcTpls9uHpktlmm/RAaESszTZ2Kq/dsmW2/ZSKiNap8uXkaG+zTazO9r6Bg726/9ObT17bbFMsdzZVvi7fD1Hhy9lmmziprm+lpg4z2dt+Ejpleuc59Z2SbhI6QN/OzXDKmhU7O3vs7e2ZteAPbt24xsKfphMTHY29vT29B4+hRKmyBpvoqCiG9utBTEw0Op2OmnXq80XvAcya4sX5M6fI5pwdgJFeU/CsVD5JvwGHDjJzxjTidHG0btuenr37WBWvGrvUtHny+BFTJ47lZdALEIIWrdvToXM3fv3lewIO+pEpUybyFSjIuIlTyZHDBYBp3l4EHPLH1c2N1T7bAPjn2hVmT5tMdHQU9vYOjBjrRemy5UzGN8FrLAf9/XBzc2fztp0my031Hk/AQcXXmo3bAVi8YB7bN28kp6srAP0GDqFajVrJrgtjbt/6l7Gjhhm+P7h/j779B9Gl2xdm7az19XXnpjhlzYadnR329vbMXrCa7yeP5uG9OwC8Dgslm3N2fly8Lkl7a+vv4b3bzJk+zvD96eOHtOvWh5r1m/LL9HE8f/IIj9x5GTz+O5yzuxjKTZk4nsMH/XB1c2Pdph0AzPlxNocOHiBTpkzkL1CQCZOmk93ljU1KtNXqVcvZtnkjIChe4n0mTplO5syWO1Vq/x9tQqTT0Wgp5X9+AeSF+6Gyeo1aMuDSXXnhfqhhad+5m1yxaY+8cD9ULt+4W7Zu31leuB8q776IlHdfRMo7zyPktXtB8u6LSPnvk1DZolUbucf/uBw4ZIT8w2e7odzdF5EyIka+tYRFxsq69erJ6//elSGvo2SzZs3lxSvXkyybXLvUsnkaEiOfhsTIy/8+lIdOnJNPQ2Lk7UfBsm79BvL42Sty519+8mFQhHwaEiO9p86Q3lNnyOdhMfJ5WIzc539UBpw8Jxs2bmJY17X7l3LHXl/5PCxGbt+zX3bs3NWwLakYDx89IU+fuygbN2ma5Pag17Ey6HWs3H/wmDxy6rxs1LiJYd3MH36Wc+cvMnw3XtTURWhknNkl+HWM/OSTavKff+8Z1qmt94v3w+TF+2Gyeo1a8sile4bviZfh4yfLCdN/lBfvh6mqv4gYKQNvvUqwnLwRJCt/XFXuOXZVDhs/RU6Y8YsMvPVKTpjxixw+fqoMvPVKBofrZHC4TvoeOiaPBSr1Hr9uz98H5fOQKBkcrpNTps+UU6bPlMHhOtVtFRKpS7DcuPNQ1q5dRz4Nfi1DInWy/8BBcvX6jQnKqKl3JaUlP+dkqTBI2rq86zwppUybm6JCiJJCiNFCiDn6ZbQQolQK7ZyIcOXSNvx1GK7uHol945Q1KwCxsbHExsYihPWXZRcvnKdgwUIUKFiQTI6ONGrSFL8D+1PFLrVtPDw8+aBkaQCyZstG4cJFef70KVWqVsfBQblYK/O/8jx7+sRg81HFSrjkyJFgPwJ4HRYGQFhYKB6enmZjrFip8lv7SIqkfNmC2rYy5sTxoxQoWJC8+fKnui9QOlRH/Pbxad1GJstYW38J4jt7ktx5C+CZOy+BR/2pWb8ZADXrN+PUUb8EZStUrIyLS84E66pWe3NOlC1XnqdPniTYnty2AtDpdERFRRIbG0tkZASenrks2qRUvVtE2Nm+/AdI9SiEEKOBdSh54IR+EcBaIcQYG/fF5JEDGPl1V/7auRmArwaMYOXCn+nTsQkrF/xM117fvGWn0+n4unt72jWpTcUqn1CqjDI8sHThXHp/3pbffp5FdHR0kj6fPnlCnrx5DN9z5c7Nk0Qnd0rZpZUNwKOHD/jn2pW3hkr+3L6ZqtVqmLUdMmIMv/7yPa0a12PeT9/Td+BQi/6Sg8+6NXTt0Iqp3uMJCXllspzaujDmrz27aNi4qcVytvgSQjBp5ABGfN2Fv3ZuSrDt8vnT5HR1I1+B92yK0xJH/P6iWu2GALx6GWTo6OR0c+fVyyCb9rVj62aqfWr+nIjH2rbKlTs3n3/Rg2af1aNRvZo4O2enarXqFvefEm1sFULYvvwHSIuflZ5AZSnlDCnlH/plBlBFv81qpv6yhO8XrcFrxlz2bN3ApXOn2bvdhy/7D2fR+l18OWAYv30/+S07e3t7Fq70Yd22fVy9fJFbN6/Ts99glq3bzq9L1xIa8or1q5amzNGmA8LDXzN+1BAGDx9DNuc3N8ZWLFmIvb0DnzVuZtZ+88b1DBo+mq279zN4+Gi+m/xtqsXapn0nNu3Yy6p1m3H38GTOj7NSzVdMTDT+fr7U/8x0b1kN035Zyg+L1uA1Yx67t27g0rlAw7bDvnvN9s7VEBsTQ+Cxg3xcs95b24QQNl2hLl28AHt7exo1aW6xrC1tFRLyCv8DvmzfvY89f/sTERHBrp3brY4r1dF66CaJA/IlsT6vfluSCCH6CCFOCSFOxa9z11+S5XB14+NP63Dj6kX8/tpJ1Rp1AahWqwE3rl4yGYhzdhc+rFCZk8cCcPfwRAiBo6MjDZu14urli0na5Mqdm8ePHhu+P33yhNy5c5s7XtV2aWETGxuD16ghfNaoKbXqNjCs37VjC0cO+zNx6kyL//C7d26jtt62boOGXL50wWz55ODu7oG9vT12dna0bNOeyxdN+1LbVvEEHD5EyVKlcU80bJdcX/HnbU79eXtdf47qdLEcO+xL9TqfWR2jNZw9eYQixUuS09UdUP5fXr54DsDLF89xyelq1X52btvC4UN+TJk+26ofAVva6sSxo+QrkB9XNzccMmWiTr36nD97xqKP5Lax1Wg9dJMMAfYLIXYLIRbplz3AfmCwKSMp5SIpZSUpZSWAyIgIw1h5ZEQE504d470ixXF19zT0eC6cOUne/AUT7Cf4ZRBhocojXVGRkQSePMp7hYrw4vmzeD8c8felcLHiScZRpuz/uHv3Nvfv3yMmOpo9u/6kVp26Fg9ajV1q20gp+W7yBAoVKUqnz780rD925BBrVi5lxo/zyJLFyeKxeXjk4kzgSQACTxynYMFCFm3U8vzZM8Nnf9+/KVqshMmyatsqnr27/6SRFcMttvhK+rwtBsC5wOPkL1gYD8+UTUhH/PZSrfabH4mKVWty8G/l6ZiDf++k4iemnzyJ52jAIVatWMIPP/9GFifL5wTY1lZ58uTl4vlzREZEIKXk5PFjFC5azKKP5Lax1aTTHnqqP7YopdwjhHgfZYgl/k7TA+CklNLqB5CDX75g1oQRgDImXqNeIz6qUo0sTk4snfc9Op0OR0dH+g73SmAX9OI5Myd7ERenQ8o4atVtSNVPazFiYE+CX74EJMVKlGTIqKSHDRwcHBg7fgL9+vQiLk5Hq9ZtKV7c9ImaHLvUtjl/7jR7d22nWPH3+bJLGwC+7j+En7+fTkxMDEMH9AKgTNnyjPaaCMCEsSM4E3iS4OBgWjaqS6++AxjzrTc/z56BTheLY+bMjPbyNhvj6BHDOHXyBMHBL2lQtyb9BnxDm7bt3yr37ZgRnA48QXBwMM0b1qF334GcDjzB9WtXQQjy5s3PGDO+1LYVQER4OMePBjDu20lWlbfWV/DLF8ycMByAOP15W6GKMlYccOAvalgx3GJt/QFERkZw4fQJeg1+8/hii45f8Mu0sfjt2Y5HrjwMHv9dAhuvMcMJPKXUe7PPatO730BWLF1MdHQ0A/sqo6Jly5VnrFHdJ7etypYrT736DenasS329vZ8UKoUbdp1sFgXyWljm/iP9LhtRUiVEwXSEiGE1CYWqUebWPQGbWKRsa+MObEoRWaKVhtn+0zRI9Pf+a9AuppYpKGhoZEmpNMeupbQNTQ0NBLzHxkTt5V0k9CL23h56Nr+d5t9PF33lc02APZp+Guu5oI3Isb2IQ0PZ0cVntSRlp0hezvbnakdlfR0sb0O1foqXcDFciEN60mnPfT0+TOkoaGhkZqkwlMuQogsQogTQohzQohLQohJ+vVFhBDHhRA3hBDrhRCO+vWZ9d9v6LcXtuRDS+gaGhoaiUmdxxajgLpSyvLAh0AjIURVYCbwk5SyOPCSNxMuewIv9et/0pczS7oZckmMJcW1PZObkCunE1LC0n1X+XXnJcoVdmNu30/J7GhPrC6OIYuOcOr6M97Pn4NF39TE2VEQpZMkHqFQqwqn0+no2qkduXLlYs6vC606riYN65Itazbs7BVFyTXrN1m0CQ0JYbK3FzevXwchmDh5GuU//OitctFRUQwzUp6soVeelFKybOFcDvruw87OjuZtOtD7qx4pFh9Yp5A3ZeIbBb+1m5RZgwt+ncMhP1+EELi6uTNh8nQ8c5nW/FCjxPf40SO8xo0i6IWiQtm2XQe6WlBatNbmyeNHTJs4jqCgFwghaNG6He07d+P3+XM55O+LnZ0drq5ujPOehocJLRM18YH1Ko2JSSuV0LSMz2ZUDM1ZQiqPFIbpv2bSLxKoC3TRr18BeAPzgZb6zwAbgXlCCCHNPZr4rtXBrFVbtFXpruqwzTJLq8XSo9Ny+c+DYPnhQB+578w92WLybpml1WLZcvJu6X/hoczSarEs+MUqWX3EFhkZEycjYmxXhXsdFZfksmDREjlo8FDZs1dvk2USL7Vq15b3H78wuT0siWXYiJFy1Zr1MiwqTr4Mi5SPngUn2H7nRaS88yJS3n4eIa/eC5J3XkTKm3rlyd3+x+XCFetk/0HD5K1n4fLOi0h59voD1fGpUch7GR4rX4bHSt9Dx+RRvepf/Lp7T4MNnxf8vkyOHudl+K5GATE8+u3lzoMnMvDsRRkeLeWzl6GyfoPP5IUr15Msa4vNk5BoeenfB/LgibPySUi0vPXopaxbv4E8dvaK/PdhkHwSEi2fhETLXxctlSPHjJdPQqJV+1Kr0viuVEJTKz5SSm2xzlRp62JlLrMHzuoT+0zAA7hhtL0gcFH/+SJQwGjbTcDjnastpjTWKK6d/fcFAGGRMVy9H0w+92xICS5Oyo2qHFkdeRSkPCf87FUkgTeem/SnRhXuyePHHD7kT2sTE0BSitDQUE4HnqJVm3YAZMrkmEC32hhTypM7N2/g86/6Yqd/+NzVzT1FY7RWIe+jipVwcUmo4OdspDUTERFhdgq6WiU+T89clCpdBoBs2ZwpWrToW+qCam2SVrh8kkBDJyIiwuxNODXxgUqVxjRSCU3L+NIKY7kS/fLWpYOUUiel/BAogDLZsmRKxvBOh1yEED2klMtstUtKce3C+fNJln3P05kPi7hz8p+njFx6jB0TGvHdl1WwE4I6Y3dY9GWsCpc5S2aqflLdKlW42bOmM3joCMLDbZtcIoSg/9c9EUDb9h1p276j2fIPH9zH1dUNb6+x/PPPNUqVLsPI0eMMiTsxOp2O/j068fD+XVq07USpMuV4+OAefvv3EODvS86crvQfNgaPUknPvrM1PrCtvZJi/tyf2bVzO87Ozvy2eHmq+QF48OA+V69c4X/lkn7ZSXJsEitcLvr1F/bu2k62bNn5ZaF14nBq4rMFNXWYEvWemvGpQsVTLlLKRcAiK8sGCyEOAJ8AOYUQDlLKWJRE/0Bf7AFKj/2+EMIByAG8MLffd91DNznPOilxLlvJlsWBtaPrM3LpMUIjYujTsBSjlh6jRO91jFp6jPkDLEuCqlGFO+h/ADc3d0qXKWu2XFIsW7GGtRs2M2/+YtavW0PgqZNmy+t0sVy9cpl2HTuz1mcLTk5OLFuy2GT5eOXJtdv2cU2vPBkTE42jY2Z+W7aOxi3b8sO0CSkWX0rQ75sh7NjrS8MmzfBZtzrV/ISHv2bE0EGMHD0uwZVBStiEh4fjNWoog4aPNvTO+wwYzKY/99OgcVM2b1iTKvFpqCR1nnLxFELk1H92AhoAV4ADQDt9sS+AbfrP2/Xf0W/3NTt+TtrooZ83sVwATKoSJRbnMsYaxTUHe8HaUfVZf/AG247dBqBrnRJs1X/edOQWlUqYfzEDqFOFO3vmNP4HfGnSsC5jRg7n5InjjB8z0qKv+GMDcHN3p269+ly6aL73kSt3HnLlzm3osdVr0JCrVy5b9OOc3YXyFSpz6lgAnp65+bS2IrX6aa16/HvjeorFF2+TEgp5jZo048D+faniJyYmhuFDBtGkaXPqNbBO/dBam3iFywaJFC7j+axxM/z3/53i8akhrVRC0zI+VaSO2mJe4IAQ4jxwEtgnpdwJjAaGCSFuAO7AEn35JYC7fv0wwOL7I9Kih54b6A40T2Ixe/lgCmsU1xYMqMm1+8HM2f5GFvfRy3BqlMkLQO3/5ePGI8v6F2pU4QYNGc7e/f7s2uvLjNk/ULnKx0ybMduir4jwcF6/DjN8PnokgGLF3zdr4+HhSe48ebl9619AeeNOkWJJx5dYefL0yaMULFSEarXqck6vnnj+zCkKvJe0eqKa+CB5Cnl379w2fD7o50uhIkVT3I+UkkkTxlOkaFG6fZH00z1qbaSUzJg8gcJFitLp8zdPpty7e8fw+ZCfL+8VLpKi8aklrVRC0zI+VaRCD11KeV5K+ZGUspyUsqyUcrJ+/b9SyipSyuJSyvZSyij9+kj99+L67f9a8pEWY+g7AWcp5dnEG4QQfmp2aElxTaD0xi/cDuLYj60BmPjHSQb8dojZPT/BwU4QFaNj4G+HAMid04mA2a1QtJ4EjvbwOlq5slGrCqeGFy9eMGzIQEAZ627cpBnVrXhTzOixXowfM5KYmBgKFCiI95TpSZYLevGcWUbKkzX1ypNly3/Ed95j2bRuFU5ZszJsrHeKxmetQp7XmBGcNqj+1aFPv4EEHD7I3du3sLOzI0/efIwePzHZfhJz9kwgO3dso0SJ9+nQtiUA3wweRo2apmVmrbW5cO4Me3ftoGjxEvTo0haAPv0H8+e2zdy9cxthJ8iTNx8jxpoe5lITH9im0hhPWqmEpmV8qkinM0XTjdpiRIxtcWpT/9/wIizp1+uZQ+3UfzsVz+9GqpAmAMiSyXa1xbQ83UMjY2y2yZ7FdpVQSLf5J8VJMbXFRj/arra4Z9g7b4V0O7FIQ0NDI9VIp7+QWkLX0NDQSIymtvjf4vPOVW222XHpoSpfjUvmtdkmcyZ1J4xOxQsasqjwpYtTNzahZshFjQKiWmLjTL7G1iRqXrQA6l6mkZYdQzXDT+m042o76fRAM2xC19DQ0FBNOu2hp8+oUYR9atf4hDYtm721zcEOfmhREu+GCV/8XLe4G5MblWBSw+K0Lac8u2ovoEeV/GQ9vpI5/duzZGxvQ/lLx/z5bcRXTOpSn4c3r73l59XzJ0z/simrVyqz/KZ6j6dx3U/p0q5FgnIb1v5Bx9ZN6dy2OXN//t7kMUVFRfF5p/Z0aNOSti2bMX/eHJNlJ08Yz2e1q9OxTXPDur//2kOH1s2o8mFpLl+6+JbNk8ePGPR1Dz5v34JuHVris3YVAL/Pn8sXnVrTo0tbhg3ozfNnT036Xbt6JR3aNKdD62as+WOFyXLGmGsrc6xetZwOrZvRoXVzxo0aTlRUlEWbgEMHadG0Ic0aNWDJYqsm7aWqr+ioKPr16EzPrm35slMrli36FYBHD+/T76sudG3bhEnjRxATY/4GqprjUmPz+NEjevXoRpsWTWjTsimrV1nXxmkVX3LsbCKdviT6vxGFClq2asP8hUk/yaKLg18O3k6w7gPPbJTP78Lkv24wce8N/rqmaLdULJgDB/lUKoAAACAASURBVDvBw9wV6ThqOpnt7cimf1dlroKF6TBsEoVKlkvSz95V8ynxYRXD96bNW/PTrwlPsMCTxzno58uq9VtYu2kHXbubfo7Y0dGRRUuXs2HzNtZt3MKRgMOcP/fW054ANGvZijnzE/oqVrwEs36ay0cV35qLBYC9gwMDho7kD5/tLFy2hs0+67j17006d+vBinVbWLZmE9Vq1GL54vlJ2t+4/g9bNvmwcvUG1vhs5fBBvwTPU5vCXFuZ4umTJ6xf/Qcr125kw5YdxMXF8deeXWZtdDod06dN5rcFv7Nl+5/s2bWTmzduvFNfmRwd+fHXJSxZvYnf//DhxLEALl84x8J5P9G+UzdWb9pF9uwu7Nq+OUWPS21d2DvYM3zkGDZv38WqNetZv24NN2+mvC+18am1s5nUmViU6qTbhG5O2EcCrxO9eLh2cTf2XHlGrH5sODRKZyic2cEOtyJlcM6eAwnE6JRxVs/8hfDIVzBJH1dPHiZnrrx4FihsWPdRxUpvxbTZZx3de/TC0VF5DNDNjPCVEIKsWZWXBBuLZyVFhYqVcXHJmWBdkaLFKGxmgkpyhaJu3/qXsv8rRxYnJxwcHKhQsTK+ZmZuxqNGhAlsF0VLjnBTavlKLIimi40FIThz6oRh1mjDpi047O+boseVlkJlaRlfmolzaT100wghSgoh6gkhnBOtb5QW/gFyOztSwjMbY+sVZUTtIhR2dQIg8P4romLj+L55ST77wJOo2DiiLdzMio6MIGDHOmq37W7R7907tzl3JpCvunWkX8/uXL50wWx5nU5Hx7atqFezOlU/qZZqIkxJCUW1bVqPfbv/pGffgUnaFCtegrOnAwkOfklkRAQBhw/y5PHjJMsmF2NRtEb1auLsnN2iKFpSwk1PrFAlTG1fOp2OXp+3o3WjWlSsUpX8BQrinD079g7KLSzPXHnMDnOpOS61dWGMtUJgaRlfShyXVWg99KQRQgxCEZv5BrgohGhptDnpKY2pgJ2dIJujPd/t/5eN5x/z9SdKz7uwW1akhJE7rrLvn2dkdngz5GIKv40rqNq4HY5ZnCz61el0vHr1iiUr1zFw6AjGjxqGuclc9vb2rN+0lb37/bh44Tw3rv9j24FagVqhqCJFi9G9Ry8G9u3FN/178/4HJbFX+QSIJdSIov1Xfdnb2/P7Hxvx2fE3Vy9d5O7tWym279Ti/70QmNZDN0lvoKKUshVQG/hWCDFYv83kz1pKqC0a8zI8htP3FR2T20ERxAHOme35uFAOLj4OQychWheHLk7intX8LMkHN66wb80ifv6mC8d2b2LFkkUmVQBz5c5DnXoNEEJQpmw57OzsCH750mK82V1cqFTlY44cPmTzsZojuUJRrdq04491m1i87A9cXHLwXqHCKRpfPGpE0dQKN6WVL+fsLnxYsTKXLpwjLDRUGX4Bnj19bPJtRWp9paVQWVrGl87FuVKdtEjodlLKMAAp5W2UpN5YCPEjZhK6ObVFNZx9GMIHuZTx6dzOjjjYCcKidASFx1BSv95OCOztBCFRsWb31cP7F4bMXcOQuWuo2rgtX/TsQ/tOXZMsW7N2XQJPngCU4ZeYmBhyuromWTYoKIjQEOVHJzIykuNHj1DYjBiVraSEUFTQC0VP7fGjh/ju30ejxrY9uWItakTR1Ao3paavxIJogSeOUahIUT6qWBl/X+X+w94/t1O9Zp0UPa60FCpLy/jSUggsPZLqWi5CCF9gmLE4l16sfSnQVUppUZAjKS0XY2EfN3f3BMI+mewgNCoG58wOhEbGsv3SU47eCebLyvkpmDMLsXGSjecec/XpazI72PFl5fwsmTWBc6dPEfzyJVlzuFK73Rc4Obuwe/lcwkNekSVrNvIULs7nYxO+p9Vv4wrKvZeLrt2/4tsxIzgdqIhLubm507vvQBo3a85Uby+uX7uKQ6ZMDBo6kkpVqiY5seifa9eYMH4McTodcVLSoGEjvu43IEGZ+Mkq40cPJ1AvZOXu5k6ffgNxyZGD72dM4+XLILJnd+H9D0oyd8HvBq2U82dPM6BXd4oWL2F4O5Epoaj38udLsi16ffk5r14F4+DgwNARo6ny8ScJtmdyePu4zLUVvLkJnZiFv87lr727DaJo33pPNdxchqQn/Bw66M+sGdMNwk29v+6XYLsaX6YmFlnyFRQWzc3r15ihF0SLi5PUrvcZX/Tqx8MH95jiNYqQkFeUeL8k4ybNwNHRETcTGjqWfKmxSepf/8zpU/To3pUSJd5H6M8RYyEwUx3R1IhPjV1KablkbbvU5sQYvumrd95NT4uEXgCIlVK+dfdMCFFdShlgxT5sFuf6ZvPbz2Fbok7xnJYLJUFazhRVM/tQjfiVkwrhK0g6oVvCVJK16EvF+L0aX2pnigapEEUzldBTg4w4UzSlEnq2dstsrp3XG3u889pJ9ZmiUsr7ZrZZTOYaGhoaac47T83q0Kb+a2hoaCTC3MvI/8tk2IT+YX7bH7V6GRFLm7JJjx2bw+e8yYsQk7QvV8BmG1CnAa5GD91RxdAJgBo177TUk1cjBKZWqCwtRcfUkE5zVpqgJfQMgJpkrqGhkfHQErqGhoZGBkFL6GlMwKGDzJwxjThdHK3btqdn7z6GbRO8xvLX3/txcsnJ51MUAavDGxZz6+wx7BwykcMzLw16DidzVmd0sTH4rviFp7ev86eTIwOHjyF/gYJM9x7Hy6AXCATNWrejXafPuf7PVX6cMYXoqCjs7e0ZOtqL7Zs34Od3gKwuOfly+mIA/Nct4ubZY9jbZyJnrrw07DWCLNmcefXsMcvH9sI1bwG2Z8lE2f+VJyY2hoCD/ri6ubFmY8LZiatXLmPuT7PZ4xtg8tn1x48e4TVulPJ8uBC0bdeBrt2+SLIsKDNXB/XsjLtnLibPnsf2jWvZsmE1jx7cY/2ffuTImdDPlInjDfGt3aTEt+DXORzy80UIgaubOxMmT8czl3ntE3PtZYomDeuSLWs27Oztsbe3Z836TRZt1PiJioqi5xefEx0djU6no36Dz+g3cJBFu9CQECZ7e3Hz+nUQgomTp1H+w48SlHny+BHTvccRpD+XmrduR/vO3Vi66Fd2bt1ETn199x4wmE+q10zSzwSvsRz098PNzZ3N23ZajCseNXWh1i6tbJJjZxPpM5+nz4Qer7i2cPEycufOTZeO7ahdpy7FiityuS1btcGpXF3++n22waZg6QpUa/sVdvb2BPj8zqk/11G9fS8u+u8GoOuUhdTJl5nRQ/ox7fu59B88gvdLlib89Wv6dO9IpSqfsHDuj3zZqy8fV6vBsYCDLJj7I1/1GYB7pQbsXjTL4KtQmQrUaN8TO3t7Dq7/nRM711GzYy8AcuTKS/cpCwxj6GcCT9GuY1cmfzsmwTE+efyIE8eOkCeP+Uci49XxSpUuw+vXYXTu0Jaq1apTrFjxJMtv9VlNwcJFCX8dBkDpch9SpXpNRg3slWT5Zi1a075TVyZ5vYnv8y++ou8AJeGtX7OKJYt+Y4yXt8kYLbWXORYtXYmriR+zlPITr3KZNWs2YmJi+Kp7V6rXqEm58h+atZs9cxrVqtdg9o9ziImJJjIi8q0y9g4O9B8ykg/051Kv7h2o/HE1ANp37kbnbpYn77Rs1YbOXT5n/NjRFsvGo7Yu1NillU1y7GwlvfbQ00qcq4oQorL+c2khxDAhRBO1+7OkuFaxUmWyZMuewKZQ2YrY2Ss3FPMULUXYS0U+N+jhXQqUUv5xXd3ccXZ24fmzp7xvpEpYqEgRnj97gkDw+vVrAF6HheHh4Un5CpXe8lX4f5UMvvIWK0noy2cmjyUphUaAn7+fycDBwy3eubJFHe/Z0yecPHKIRs1bG9YVf78UefLmNx+fS8L4nBOpM1o6+dNKIU+tH1tULuMJDQ3ldOApWrVpB0CmTI5kd3F5q1xihctChYvy7JltYlJq1CrTUs0wI6otCiFsXv4LpIU410RgDjBfCPEdMA/IBowRQoxXs8/kKq5dOryXQv+rDIBnwaLcOnuMOJ2ORw/uc+3qZZ4+eTMH6tHDB1y/dpVSZcoxcNhoFsz5gfbN6jN/zg/0HjDEoq+Lh/ZSRO8L4NWzx6z8th/9enbn7OmkZWoOHtiPZ65clPigpNXHBJbV8Rb+Moue/YciUkBIaP7cn2nesC57d+2kT79vzJZV215CCPp/3ZMuHdqwyWe9xfLJOS9sVbl8+OA+rq5ueHuNpXP71kye6EVEeLhZG+VcukLpMorC5RaftXzZuTUzJnsRGvLKqjitJS3VDDOi2qKW0E3TDqgO1AQGAK2klFOAhkDHNPCfgJM71mBnZ88HVRX9h9I1GuLs6sG6yQOZ99NMypYrb5gWHx4ezsQxQxk4TFEl3LZpPQOGjsJn598MGDKSWVMnmPV1bLviq1S1egBky+lGn59W033KfAYPH82EcaN4HRaWwCYyIoLlSxdZTJKJsaSOdzzAn5yubpTQ9xaTS79vhrBjry8NmzQzKUyWXJatWMPaDZuZN38x69etIfDUyVTxA7arXOp0sVy9cpl2HTuz1mcLTk5OLFuy2GT58PBwvh09lG/051Krth1Zu2U3S1dvwt3Dk19/nm3SViPt0RK6aWKllDopZThwU0oZAiCljABMzsM2p7aoVnHt8uG/uHX+BA37jDY0gJ29PTU796XLpPlM+34uYaGhFHyvMLGxMUwcPZT6DZtSs059QBFRiv9cu35Drl42LS9w8dBf/Hv2OE36jjH4csjkiJOzcllesnQZ8hcoyN07txPY3b9/j0cPHvB5x9a0alKfZ0+f8EWXtrx4bnrYxhp1vEvnz3LssB/d2zZmxsTRnAs8ycxJYy3WmSUaNWnGAQsvuUiOsh6Am7s7devV59LF86nixxhrVS5z5c5Drty5DT35eg0acvXK5STLxsbG8O3ohAqXbu4e2NvbY2dnR7NW7biSxCsDk0NaqhlmTLVFFct/gLRI6NFCiKz6zxXjVwohcmAmoZtTW1SjuHb7wkkCd/vQ7BtvMmXOYlgfExVJTJRyM+vU8SPY29tTqEhRZk2ZyHtFitKh65snRtw9PQ3DJKdPHqdAwfeS9HXr/ElO7tpAqyGTEvgKDwkmLk7RVXlw/x73794hX4GEE4yKl3if3b6H2brrb7bu+hvPXLlZsUbpxZmoJ6vU8b7qN5g/tu5j5abdjJk0k/IVKzN64nfmqswkxj9CB/18KWRBEVJNe0WEh/Naf+M2Ijyco0cCKFb8/RT3A+pULj08PMmdJy+3b/0LwInjRylS7G2FRiklM6dMoFDhonQ0OpeeG/1AH/LbTxETN7HVkpZqhhlRbTG99tDTQpwrs5TyrTfuCiE8gLxSSvOv8CFpcS5zimujRwzj4JGjRIa9wsnFlaotu3Fq1zp0MTFk0feQ8xQrSd3ugwl5/pitP4xH2AmKFMjHKK/JPH3ymEF9vqBo8RKG8ebe/QeRNZsz836cgS5Wh2PmzAwZNZ71q1dw/PhxIsJekdXFlWqtu3Fi53piY6MNvfG8xUrR4MvB/HPyEEc2r8TOwR7XrJnp3Xcgf+3+8y2Fxhat2xqOpVWT+ixf7WN4bDHxTFFL6ngAj18lfPri3OmTbFq7gsmz57HVZzUbVy8nKOgFOXO6UfmTTxk61hvXbMqcT68xIzh96k18ffoNJODwQe7evoWdnR158uZj9PiJht60qZms5torLomZmPfv3WPYEOXNSTqdjsZNmtGrT98EZeySmIlpScEvLonz3ZLKpal/kWtXrzB5ohcxMTEUKFAQ7ynTE9y8DIuM5fzZ0wzsrVe4jD+XBgxm/95dXP/nGkJAnrz5GTFuIh4enuTI+vZcW0tqlaZIDTXDd21jyS6lxLk8e6y3OTE+W9bxnWf1VE/oKYEatcUlx2/b7EftTNEdVx7ZbJOWU/8TJ3RriE/otqImvqQSujUkldAt+lJxvqv9FwmLNK+rnxRJJXQN60mphJ7rqw02t/rTpR3eeUL/b7w3SUNDQ0Mj2aTLiUUaGhoaqco772urI8MmdEcH21tE7YsM6hez/S773efmn1k2xQf5slsulAg1L3WIU/fOCVXDE2rVDNUMuaDmpQ62mwAQ+h8fcsmIL7hIKf4rNzltJcMmdA0NDQ21aAk9jbFGnCurS056fKdM9vBbu4h/9eJcOXPlpZFeMCuekOdPqf9pS77qM4Dbt24ScEgRpPpjwzYArv9zldnTJxMRHk7efPmYOHUW2ZKYwKPT6RjUqzMenrmYNGseMyeN5frVSzg4OPB+qbIMGvUtDg4Je2Gvw0JZ8OMU7t2+iUDQb8QEzp46yv5dW3HJoTzd0vmr/lT4+NMk68IW8SadTsewPl1x88jFxJlzOBd4nKW//YyUcWRxysqQsZPIV+DN45hTvcdzRF8Xq30UcS6v0cO4e+cWoEyBz549OyvXbTHp01YBsXjWrl7Jlk0+ICWt2rany+eWbdQKN6kRArPFRqfTMaR3F9w9cuE9ay5SSlYunsfhA/uws7enaav2tGjXJUWPS42N2rbKaOJcqZHQhRAFgZVAbpRrxUVSyl+EEN5AbyD+WdZxUspdepuxQE9ABwySUu415yNdJnRrxLlcPqrHroVvBLMKl61AzQ6KYJb/+t85vnMdtTq+EaQ6sHYBVavVAKBJ81a07dCFKRPfTLyZMWUCA4eM5KOKldm5bTOrVy6lT/+3Ffm2+azmvUJFCQ9XnqGu81kTRk2YDsBM7zHs2bGFZq07JLBZ9tv3fFipGsMnzCI2JoaoqEjOnjpK07ZdaNG+m8X6sEW8acfGNRQoVIRwvSbNbz9Mx2v6TxQsXJQ/t2xg/crfGTpusqF80+atad+xK5MnvBHnmjrzR8PnOT/OJJuz+WEgWwXEAG5c/4ctm3xYuXqD8nLt/r2pUbM2Bd8rZNImucJNtgiB2Wqz3WcNBY3q/e9d23j+9AkLV2/Fzs6O4JdBJm3TUvxKTVtp4lxWEwsMl1KeFkJkBwKFEPGz8n6SUn6fKIbSQCegDJAP+FsI8b6U0uRLgtPlUy5qxLmMBbPyFStJWNCbiR3XAwPI4ZHHMLnjwwpvC2bdu3OHDysoc5wqf/wJ/r5vz4589vQJJ44eoqGR+FWVT2oYJh58ULosz58m1J0Ifx3GlQtnqNu4JQAOmTJZTJCJsVa86fnTJ5w8epjPmr6JTwhBePhrfSyhb01gMiUeBsqkmf379vJZI/M6a7YIiMVz+9a/lP1fObI4OeHg4ECFipXxtTAjNa2Em2xFqfdDNGzWxrBu1zYfOn/ZxyAzkdPVzaR9WopfqWmrjCjOlRozRaWUj6SUp/WfQ4ErgGllPGgJrJNSRkkpbwE3gCrmfLyThC6EWJkc++QK9Fw4uJci5RTBrOjICE7s3EC11uZ7wkWKFeeQny8AB/7eyxMjAa94Fs6ZRc9+Qw0TSIyJjY1h/96dVKpaPeGxPHqAS46c/DZ7EqP6dmHBD1OIjIgAYO+2DYzo04nfvp9EWGiI1cdnisVzZ9Oj32BDEgH4ZtQEJo36hi/bNuTA3j9p19WynGs8Z08H4ubmTsH3ClttY0lALJ5ixUtw9nQgwcEviYyIIODwQZ48frvOjUnOeWGrEJgtNovmzKZH/yEIo5u4jx7c56DvXgb36sKEEQN4cO+OSfu0FL8yxtq20sS5bJ8pKoQoDHwEHNevGiiEOC+EWCqEiL/kyw/cMzK7j/kfgDRRW9yeaNkBtIn/ntr+E3Ns+xrs7N8IZh3ZsoqKjdrgmMXJrN24CVPY7LOOr7q2Jzw8nEyZEo6DHw/wJ2dO0+JXv/4wnbLlK1K2fIUE63U6HbeuX+Oz5u2YtWANmbM4sXX9cj5r3o65K7Yya8EaXN08WLnwp2QcNZw4cpAcrm4U/yBhfNs2rGbirLks37SX+k1a8vu8H6ze5769f9LAQu/cGEsCYsYUKVqM7j16MbBvL77p35v3PyiJvcqnkKxBjRCYNTYnAg6Sw9WVEonqPSYmGkfHzPzy+xoaNm/DLzO8U+pQUgRb2iojoiahG+tP6ZckB/eFEM7AJmCIXttqPlAM+BB4BFj/T5iItBhDLwBcBn5HuREggEpYCFpfGUlWiFqBnouH/uLmmeN0GDPT8Iv66OZV/jl5iIPrfycuMhxhJ3DM7Ej1GrUT2BYqUpSff1NusN69c5sjh/0TbL984SzHAvw4eewwMdFRhL9+zazJYxk14TtWL13Aq+CXeE379q2Y3D1z4e6ZixKlygJQtWY9tq5bTk5Xd0OZek1aM/Nby1K95rhy4SwnAvwJPHaY6Ohowl+/ZtKob7h/9zYflP4fAJ/W/QzvEQMs7EkhNjYWP9+/Wb7ax6ry1giIJaZVm3YGvfFf5/xkkBcwRXKEm5ISAqtYqXKybS5fOMvxAH9O6es94vVrZk8eh4dnbqrVVDoV1WrW5efvJqbocSWnLmxtq4wozqVmDF1KuQhYZGG/mVCS+Wop5Wa93ROj7YuB+CcbHgAFjcwL6NeZJC2GXCoBgcB44JWU0g+IkFL6Syn9TRmltDjXrfMnOfHnBloPTSiY1dnrR/r8uIo+P66iQ5dudO/Rh3Ydu75l/zLoBQBxcXGsWLKQVm0TKv/26DuYP7bsY8XG3YzxVsSvRk34jj07NhN44gijvWckGOqIJ6ebB+6euXl47zYAF86coEChorx88dxQ5kTAAQoWflv4yRa++HoQyzftZcmGXYyaOINyFSrjNf0nXr8OM1zunz15jAKFili1v5PHj1KocBFy5c5jsay1AmKJCXqh1PnjRw/x3b+PRo2bmS2vVrhJjRCYtTZf9h3Eys1/scxnN6O9lXofOWE6VWvU4fwZpUd/4ewp8psQelN7XGrrQk1bZURxrtQYQxfKr8QS4IqU8kej9cavJWsNxEtvbgc6CSEyCyGKACWAE+Z8pHoPXUoZB/wkhPDR/32SXL8ODg6MHT+Bfn16GQR6ihcvYdg+esQwDh05SkTYKxYM7kL1Nt04vmM9uthofGYpT2vkK1aKBj0GJ7n/ieNGcObUSYKDg2nVuC49vx5ARHg4m33WAlCrTn2atmidpG1i5n4/lVy58zLs6+4AVKtVl649EopMfTVgJHO++5bY2Bhy5c1P/xETWfbrbG7f/AchBJ6589JniOl3gRiLNzWoW9Nq8SZ7Bwe+Gfkt33mNQNgJnLO7MHiMd4IyE8aOMIiHtWhUh159B9KiVVv+/mu31cMtZ88EsnPHNkqUeJ8ObZWbv4kFxJJi1PDBvHoVjIODA6PHfZvkG4GMsXRemOLFixdvCYFV/7RGitsY075rD2ZPHsfWDX/g5JSVQaNN99DVHJfaulDTVmkZn1o7W0mlp1yqA92AC0KIs/p144DOQogPUUYwbgNfA0gpLwkhNqCMcMQCA8w94QLvQJxLCNEUqC6lHGeDjc3iXKsCTd9kMkXrMmbvN5gkJML2GYGhETGqfKmZKXr3he2zUj2cM9tsA+DkaLs4V6yKmawAmRxsv8BUKwSmhofBtouiFXAzfy8nJcmIM0VTSpyr0KAdNtfOnTnN33ntpPlz6FLKP4E/09qvhoaGhrVoM0U1NDQ0MghaQv+P8fdV0zPvzNnMbVPWZjvP7I422+TJoW5IY+cl27XXKxcwPWnFFKGRsaqOS83/gb0akS2VqBlwURufu7Pt9ZeWpNOclTak07rJsAldDWqSeUZFTTLX0MgopNceerqc+q+hoaGh8TbptoduTnHNwQ4WdShLSGQsI7ZfBaCQqxO9PylIJnuBLg6WHL/Hzefh5HPJTL/qhSji7kRkjCQiJo4njx8xbeI4goJeIISgRet2tO/cjd/nz+WQvy92dna4uroxznsaHp65DH4nTRjP4YN+uLq5sWHzDgBevQpm7KhhPHr4gLz58jNj9k+4uJjXXdHpdHTt1I5cuXIx59eFAHh/O46DB/3IlM2FwT8sByA8LIR1P00i+NljcnrmofNQb5ycs3No+zrOHlJ0T+LidDx/cJcNu/zJkjkLw/v3ICYmGp1OR4069eneawDD+n1BeLjyJEzwyyA+KFWW336bb1N8yWkvU6hRQFSrxBcaEsJkby9uXr8OQjBx8jTKf/hRivia6j2egIOKYuWajcrk6MUL5rF980bDu2L7DRxCtRpJPxpoi5qmmviS6yst40uOnS1oPfQ0JF5x7bcFv7Nl+5/s2bWTmzduvNkeB9/9fTOBTddK+dh47jGjd1xjw9lHdK2ovD80LFrH8hP32XHpqaGsvYMDA4aO5A+f7SxctobNPuu49e9NOnfrwYp1W1i2ZhPVatRi+eKESa95y1bMnZ9wotjypYupUuUTtuzYS5Uqn7B8yWKLx7fmj5UUSfTW+eYtW/Pr/IS2B7euodj/KjBszmqK/a8C/lvXAFCjRSe+mb2Eb2Yv4bPOffjfhxVxcclBJkdHZs39nQUrNzJ/xQZOHgvgysVz/Dh/BQtW+LBghQ+ly5bj09r1bI7PHJbayxyLlq5k/catViXz5PiZPXMa1arXYPOO3azftJWiRc1P5LLFV9Pmrfnp17cnEHb6vDur1m9h1fotJpM5KGqa8xf+btVxqIkvub7SMr7ktLEtCGH78l8gzRO6EOJTIcQwIYR187+TwJLimgTCohI9fy/BKZNyuFkd7XkZrjwHHhIZy80X4QnemuPh4ckHek2WrNmyUbhwUZ4/fZJA/zwiIuKtVqxQsTIuLjkTrPM/4EuzFsoEjWYtWlpUhnvy+DGHD/nTOtHEoIqVKpMjkerhlZMBfFSrEQAf1WrElZOH39rf+YD91GnQGFB6HU5ZswLK1H1dbGyCY3j9OoyzgSeoVtP0zDtT8ZkjrRTy1PoJDQ3ldOApg8xApkyOFicx2eLLnGKlNVirpqk2vuT6Ssv40upcSm1xrtQiLcS5Thh97g3MA7IDE4UQY0wamkGN4tqKk/f5vGJ+fm1Xhm6V8rH29EOr1gRxhgAAIABJREFUfD16+IB/rl2hdNlyACz69RfaNq3Hvt1/0rPvQIv2QUEvDMMy7h6eBOklBEwxe9Z0Bg8dYdXr1cJeBeGi13zJntONsFcJn+yJjork+tkTfFqngWGdTqej7xft6dC0NhUqf0KpMuUM244c9OXDih+TLZtpMSZb4otHrUKerQqIav08fHAfV1c3vL3G0rl9ayZP9CIi3PxkrJRQ/fNZt4auHVox1Xs8ISGvbLK1RFqpEqrlv6+2qPXQTWEsS9gHaCClnAR8BrwtmpJKNPjAgxUn7zNg4yVWnHhA32qmX5QQT3h4OF6jhjJo+GhD77zPgMFs+nM/DRo3ZfOGNTbFIIRAmHke6qD/Adzc3CldxvanbUQSZ9XVwCO890HZBGP29vb2LFjhw5qt+7h25SK3bl43bDuwb7ehN5/S8alBjQKiGnS6WK5euUy7jp1Z67MFJycnllkxNJYc2rTvxKYde1m1bjPuHp7M+XGWZSONNEProZvxIYRwFUK4o0gNPAOQUr5G0SdIEmMpysTb1Ciu1Srmzom7Si/o2J1ginlkNVs+NjYGr1FDaNCoKbXqNnhr+2eNm+G//2+z+wBwc3Pn+TNlfP75s6e4upl+JvzsmdP4H/ClScO6jBk5nJMnjjN+zEiT5Z1zuBHyUunxh7x8gbNLwjfnnA/wpfynSY+HO2d3oXyFypw6HgDAq+CXXLt8kY+r1Uyx+OJJjrIeJFQzTB0/eciVO7dB97teg4ZcvXI5VXzF4+7ugb29PXZ2drRs057LFy9YbWsNaaVKqJb/vtqi1kM3RQ4UtcVTgFu8spheE9hkNaS02uLL8BhK51Z62WXzOPM4NMpkWSklMyZPoHCRonQyeo/lvbtv9GEO+fnyXmHLyoS1atdl53blvaQ7t28zG+egIcPZu9+fXXt9mTH7BypX+ZhpM2abLF+yUjXO+O8B4Iz/HkpVfvPyjMjwMG5fPkepSm/WBb8MMrwoIyoqktMnj1JQr6546MA+Pq5eE8fMpic82RpfPGraS40CololPg8PT3LnycvtW/8CcOL4UYoUM39TNLmqf8+fvXljlr/v3xQtlrICU2mmSqiS/7raop2dsHn5L5AWaouFTWyKQ5GKtBlLimuZ7GBKk/fJnsWB39qVwefsIxYevcuXVQpgLwTRujgWHbkLQI4sDnzX7AOcMtmTJZMdWR3tOBBwgr27dlC0eAl6dGkLQJ/+g/lz22bu3rmNsBPkyZuPEWMnJIhr3OjhBJ5SlAmbNKhNn34D+eKrXowdOYxtWzeSN28+vput7kUVY0YNI/DkSYJeBjGzbzvqdehBrVZdWPvTJAJ9d5HTMzedhnobyl8+cYji5SsleHFH0IvnzJ7iRVycjri4OGrVa0jV6srTFX5/76Fjt69UxWYJNQp5atQMk6PEN3qsF+PHjCQmJoYCBQriPWV6ivn6dswbxcrmDevQu+9ATgee4Pq1qyAEefPmZ4yXt+nYVKhpqq0LNb7SMr60U1tM8V2mCWmutqgGNWqLX6w+Y7MftTNFnTLZrjCodjr5rivmX8OWFGqm/qudKaqmp6JWAVGNL50KX2rbKiLarNJpkqhRq9R4Q0qpLZb12mfziXJxaoN3/jOQbicWaWhoaKQW6bWHriV0DQ0NjUT8V55asZUMm9CnNylps41zlrSrDjuVJ0yzMnktF0qEa73JNts83/f2+09TCzXDIKBuyEVtvashLh0MZ2okjZbQNTQ0NDII6TSfawldQ0NDIzHptYeeLsW5QFFca9G0Ic0aNWDJ4reFj4zR6XQM7NGRiaO+AeDn77wZ8EUH+n/RnmleI8xO846KiuLzTu3p0KYlbVs2Y/68OVbFp8ZugtdYatf4hDYtzb/dPjGW6uLQgp4cX9KHwOV98eqhPKZYKE9ODs7vycXVA1k1sa3h/Zy9WlTk5LKvyeIAWRzenigQGhLCyGGDaNO8MW1aNOHcWctPE6k9rrWrV9KhTXM6tG7Gmj9WWGVjy3kRz+NHj+jVoxttWjShTcumrF5lnS9rj2uatxdN6tWga/uWhnX/XLtC7+6d+aJTG77q2oHLFiZNqTkuNTZp6Sst47OV9DqxCCnlf34BZESMNCxhkbGybr168vq/d2XI6yjZrFlzefHK9QRlbjwNNyyz5iyUvfsPkl2/7ClvPA2X5289NWwb9e1kOf2HefLG03D5f+ydd3wUxfvH35NLQgKhJIQAAhJCU0AE6SBI70jvAkoTpAtK74IUCwIqglIEpCPtS29JCC303kR6C5BAernM74+9hJRru0mO4O8+vPbFZXeefWae3ZubnZ15T3hMfKotLFovg0JCZXhMvAwJj5Zt2raTRwJPGU2rxi5pXhO2Q0eOy1NnL8gmTZsZPW5ssyYWuRtNly61Jku3OlPl8Yv3ZK1+v8v1+y/IbpPWS5dak+XCTYFy0PfbpEutyTJP42+lS63JMiw6XkbGxMtYfbwMi361fTniK7n8rzUyLDpeBodFyYdBIcmOaynXy0h9qu3UucuycZOm8snzMPk8NFp+0q27vHj1ZrI0WmIREZN6u33/sTx55oKMiJEyKDhU1m/QUJ6/fD3xuKnYWyrX07BY+TQsVu7xPSIDAs/KRk2aJu7r2v1TuXXXfvk0LFZu2blPduzcVT4Ni9V8jdPDxpa+Mip/SpWW9jrngyn7pdrtddeTUkqbwLmqCCFyGD67CiEmCyG2CiFmCiE0IejUENeePnlM4BF/GrVok7gvqwE+JaUkJjra7OOVEIKsWbMBCqEwLi7OqscxLXYZRa0Lj1TIkk6ODjg6OiAlfFS+CBt9lentK3edo8WHykvk0IiYJIVI7ksLlVBruW79e5My75XFxdUVR0dHPqhQif379pi10Uriy5PHi3dLlQYgWzY3fHx8eGIF8MnachmjLQogPEyZCRsWFopnnjwm7bWUy5Y0w8yePy16U1votuhyWQwk9Gn8hIICmGnYt0TLCdUQ136bO5ue/YemGt3ww/QJdP24Hvdu/0uLdp3M+tPr9XRs24p6tWpQtVr1ROaHJWm1UyNrYuHgIDj6e1/ubBrB/hM3ufngOS/CotDrlVEY95+85C3P7InpP29VEVcncNZBTBLajhYqoVYVLVacM6dOEhISTFRkJAGH/Hj8yPykqvQg8d2/f48rly9nyLVKqqEjRvHzT9/Rqkk95v/4Hf0GDjOZVku5bEkzzOz5+/8km8C5pJQJ1UJFKeVQKeUhA3HR5CoJ5uBc1upYgB+5crlT3MA2T6ovx0xh+aY9FCpcBL99u8yeR6fTsWbDJnbtO8iF8+e4cf2aVf612qW34uMlVXsvpFj7H6n4bgFKvu1pNv1vm04QGQsxekg6CdaWVMIiPkXp/llvBvbrzaAv+lCi5DvodBl7u0ZEhDNi2GC+GjkGNzfTCOH00Mb1axg8fCSbduxjyPCRfDvFdsNE7bIsO23RtC4IIT4zfD4rhKgIIIQoAcSaMjIH57KWuHbp/BmOBvjyabsmzJw0inMnA5k9ZUzicZ1OR636jQnwte6RLXuOHFSsXIXDh/ytSp9WO2ukhj73Iiwa39O3qFK6IDndXNDplJuwgFcOHjwNTZVeH68s5/fKl3oqYVrUqk07VqzewKIlK8iRIydvF/Y2mz4tJL7Y2FiGDx1M02YtqNdA89orVmvHts3UNlA86zZoxKWLpmmLWsplS5phZs+fFtm7XEyrN/CREOIfoBRwRAhxE1hkOKZa1hLXPus3mOV/72bp+h2MnDSDshUqMWL8NB7cU8BcUkqOHfKl0NumqYnPnz8n9KVCKIyKiuLYkcN4W7H8mlY7tbImFjndFIKii7Mj9Sr6cOX2U/zO3KLNR8qTS9dGZdkWcBWAogVecV90ApLO+dFCJUyLnj9T0MCPHj5g/749NG5ifjSJVhKflJLJE8ZSxMeHbj0+s5g+PeTp6cXpkwrf/eTxYxQqZJrPr6VctqQZZvb8adGb2kK3BW3xBfCp4cVoEYPPe1JKzR1faSGuSSn5ftp4IsLDQUqKFCvBwBFjTaZ/GhTEhLGjiNfriZeSBo0aU6t2HYt+tNhlBLVOADvndEfn4ICDEGw4eIkdR65z+VYQyye2ZWKvOpy98Yil/1OGH/ZvU4k6FYqQMGk25Up+aqmEWssF8PXwIbx4EYKjoyMjx4y3+AJW631x5vRJtm3dTPHiJejQVhlaOGjIl9SsZXqdTzXlmjB6BKdPBhISEkLLxnXp3W8Ao8ZPYs7sGej1cThnycJIM7RFLeWyJc0ws+dPizJJ/axa/1na4v3gSNV+8udyUW2jVbacgm7Lqf9ayISxcfGafDk5qn/A1HK7a71U4dEm128xqWxZ7HP90qL0oi1Wm+mn+k45MrLWa/8ZsN89dtlll10p9Ka20O0Vul122WVXCmWWPnG1+s9W6G4aHl1t2Q2itadLSxavbxqp2qZgT3ULYCfowRL1637bstPPlt/TkHCTg7hMypZdLloWFtG61JoW8qQtv48p9YbW5//dCt0uu+yyS6ve1Bb6GwvnshaM9PjRQ4b0+4xuHT6me4eWrFu1PNnx1SuWUqtSGUJCgk2ew1YQIa2QKGv9xERH80XPLvT5pB09O7dm6aKfAZg9bSJ9PmlH765tmTT6S2KjI9kyph5HZjbn8IxmfN6oZOI5+jQowbFZyv7JncoD4KgT/PJ5NQK+bUYWx+Rj19WUa8qEsTSsXYOObVok7tu7eycdWjencrlSXLp4Id1ikR52aqBjer2egT1fAeIStGDOTNo0rJZuftLDrmmjurRv3YKO7VrRpWNbq2y0xE8r+M42cC77sEWbqmWrNnTu8gljR5vvTtA5OvLF0K8o+U4pIsLD6d29A5WqVMfbpyiPHz0k8Nhh8uYzvWiEXq9n+rQp/LZoCXnz5qVLx3bUrlOXosWKmfWrxU7nqGP4V6N4t1RpwsPD6NyhLVWr16BoUdM2avw4OTvz/fzfcc2albi4WIb07UHlah/yxdCvyGbg2/wyZzY7tm5izW0vzt0Kxs3FkQNTm3Dw/EPy5HSlaYWC1ByznZi4eDxzKOPbW1UuTBZHB2qM/h8PlnQli6MyKSnhIdvacjVv2YoOnbswceyoxH1FixVn1o/z+HbqRLPx1hrztNhZew8CbF73F4UKF1GGyxp07cpFQkNfWrRV4yc97AAWLv4Td3d3q9JqjZ+zszMLFy8la9ZsxMbG0rN7V2rUrEXZ98uluy+1yiT1s2rZAs41WAhRKL3Pay0YydMzDyUNU/+zZstGYW8fgoKUIfDzf5xF/0Ffmv11tSVESAskSo0fIQSuWbMCSYBhiMTKXIGVRREeEcm5W8oTS1hUHNcevCC/R1Z61i/OnK2XiDEMM3z6MlqxQ5I1i2OyIYtJe0ytLdcHFSqRI0euZPuK+BTF29v0xC+tsUgPO2vvwURAXPNXgDi9Xs/iX36kV/+h6eYnvezUSmv8tADsbAfnSv8WuhCikBDigBDikhDiohBiiGG/hxBijxDiuuF/d8N+IYSYK4S4IYQ4J4T4wJIPW3S5TAWOCSH8hRBfCCFMY+UyWA8f3Of61cuUKl0Wf9/9eObxolgJ80vVvS6IkLWQKLV+9Ho9fbu1p22T2lSoXI13y5QFYNbU8bRrWoc7t2/RukPnxPSFPLNRtrAHJ/95SrF82alWMg97JjVi29j6lPdRZpVuPn6HiOg4rsxvg4sjxJlZ7D4j4VeZFfj029zZ9PxiaLIXils3rqZKjY/w8HxtXweTEkLwxee96NKhDRvWrbGYPi3xUwuwsxWcK4Om/scBw6WUpYCqwAAhRClgFLBPSlkc2Gf4G6AJUNyw9QV+teTAFhX6TaAgSsVeAbgkhNgphOghhMhu3jT9FBERwfiRwxj05Uh0jjpWLFlEr34DbeVelTISEqXT6Vi4fB1rtuzhyqUL/PvPdQC+Hj+Vtdv2Udi7CAf3KrCybFkc+XNITUavOEloZByODg64u2WhwaRdTFh1miUDawJQwccTfbzk3UEbiYoDR13qhTEyulyZVccC/Mjl7k7xkq8Acc+ePuHQgT183LazGcvXpyXL/mLV2o3M/3URa1b/xckTgRnmK7MA7FIqI1roUsqHUspThs+hwGWgANASSHixtAxoZfjcEvhTKjoK5BJCmF1U2BYVupRSxkspd0spewFvAb8AjVEqe6NKD9piguLiYhk/cigNGjfjo7oNuH/vLg8f3Kdnl7Z0+LghQU8e0/uT9jwNCkpla2uIkFpIlFY/btlzUK5CJQKPBiTu0+l01GnQGL8De3HUCZYNqcm6w7fYduIuAPeDI9gaqHw+dfMZ8VKSO3sW2lX3Zt+5h8QZcLzxElKObrMF/CozAp8SAXHtDYC4U4H079aWh/fv0qtzCz5t34ToqCh6dWph+WQ2kpeh7B65c1O3Xn0uWlhNKT3iZy3ALjPDuZLWWYatr+nzC2+gPHAMyCulfGg49AhIKFAB4G4Ss3uGfSZliwo92VdbShkrpdwipewMmCQSmaMtqpGUkplTJ1DY24eOXXsAULRYCbbs9mPtlt2s3bKbPF55+X3FOqOLDNgSIqQFEqXGT0jwc8IML+Gio6I4efwIBd/25v7dV7Cyw/4HebuwN/N6V+Xag5f8suNKov32E/eoWUq514rmy46zowPPQqO59yycmqVffakcUkC9bAW/yozAp8/6DWb5xt0sXWcAxH1QibU7/Fm5eR9L1+1g6bodZHFx4Y/VW9PFX1oVGRFBeHhY4ucjhwMoWqyEWRut8dMCsLMVnMtBCNVb0jrLsBkdgiOEcAM2AEOllMneikuFxaJ5aoYtRrl0NHVASql5dQRrwUjnz55m1/at+BQrTs8uyhCsPgOGUK1GLav82BIipAUSpcbPs6dPmTV1HHq9Hinj+aheI6rWqMXQzz8lIiIMKSVFi5Vk1PhJvO2Vk4t3gvGb1gSAqWvPssL3H+b3rcrhb5sRo4+n/29HAPh9zzVl/4xmqUa4qCnX2JHDOXniOCEhITRrUJu+/QeSI2dOvpsxjeDg5wwb2I8SJd9h3oLf0y3mabHTCh1TK61+tNg9e/aML4cqXZF6vZ4mTZtT48OaZm20xk8LwM5WcK6MkhDCCaUyXyml3GjY/VgIkV9K+dDQpfLEsP8+kHRASUHDPtPn/6/CuV5EqJ+llzOrk2obrbLlTNGnodGqbd4btF69I7TNFI3Va4NzOWuAc9lS95+rB8QV8HDNgJwY139xpmh6wbka/nxUdYZ3D6hq1q9QOtqXAc+llEOT7J8NPJNSzhBCjAI8pJRfCyGaAQOBpkAVYK6UsrI5H2/sOHS77LLLroxSBk0UqgF0A84LIc4Y9o0BZgBrhRC9gNtAB8Ox7SiV+Q2UJTst9lfaK3S77LLLrhTS+CBiVlLKQxgfAAZQz0h6CQxQ48NkhS6EWI4VnfNSyu5qHNpKYVHqWdTZXbX9vml5NLTlTLToWPVdGnOGWveOIaUC/32u2qaYl7YhjB5uzqpttDz6a+0e09CjoVla8hinIYPOGms6YbIey5zKLFP51cpcDXbDZrmwyy677MpEekPrc9MVupRysi0zYpdddtmVWfSmPVEkyOo+BiFEA6AT4CWlbCGEqAjkkFLuz7DcmVGAvx8zZ0wjXh9P67bt6dXH5Bh+9Ho9Q/p0IbenF5NnzUvcv2DOTHZv38TG3UdM2kZHR9OrxyfExMSg1+up36Ah/QcOtpi/CeNG4+d7EA+P3GzcvM2qMmmxgbTF4odp4zl/9mQiz2XYmClsWb+KgEO+ZM2Ri74zlSGCl4/54r/hT54+uMNnU+aT30chMOrj4tj++/c8+vc68fHx1KrflKbte7Bn0yr8d29FCEEB76J8NmQsjk7ObFr+GycC9uPg4EDtJm2o93GHxLw9efyIbyeNIfj5MxCC5q3a0a7TJ9y4dpUfZ04hMjKCfPkLMHbyDLKZmGmqJhYJ0nqNQ1++ZMqkcfxz/ToIwcQp03i/XHmTcR/WV4n7xJnz+HrgZ0RGKKCuF8HBlHi3NOOmzzHpS225Hj18yLgxXysLbQtB23Yd6Nqth9G0UyaM5ZDfQdw9PFizURkPv3f3Thb+Op9b/95k6cq1lCpdxqw/LXFXk8e0+lKrjOhDt4WsqtCFEIOAIcDvQDvD7khgLlA9Y7JmWmqJa2kh3WkhwoE20p0Wm/SIRa/+w/iwToPEv+s3+ZhC1RuzZcHMxH15CnrTdugkdiz+Mdn5rhzzJS42lj4zfyc2OorFo3pT8r0K7Nu6jim//IVzFhcWzBjLcb+9gOT508dM/XU1Dg4OvAxJ3t+u0+noP2QEJQxkzM97dKRi5Wp8N30i/QYPp9wHldi+5W/WrFhCz37JMbRaYpEgrdd49sxpVK9Rk9k/zCU2NoaoyCiTabesTx73WfOXJB6bPm44VT6sbdI2o8mdr4tymdF00bToTe1Dt3Yg71CgvpRyBpDwhu0KUNK0iSIhhLMQorsQor7h7y5CiPlCiAGGQfaqpYa4llbSnRYiHGgj3WmxSWssjOm9chVwcUuO2fEsUJjcbxmBZgpBbHQU8Xo9sTHR6BydcHF1JT5e+VuvjyMmOopcHp4c3L6RFp164uCg3HY5cnkkO1VuzzyUSELGfNu7CE+DHnPvzm3eL69MGK5YpRp+B/amORbJi6D+GoeGhnLq5AlatVHaN05OzmTPkcNo2oS4N2yWOu4R4WGcPXWcajVNT6jJaHLn66JcZjRdNC3KIDhXhsvaCj07r5gCCa/GnYAYK2yXAM2AIYaRM+1R+AWVUFr8qqWGuJYepDu1RDhbKq2xAFi2aD5f9GjPwrmziY2x5pK+0juVa+GUxYWfBnTg5yFdadS6CwUKF6Vh6y6M7NmaEd1b4JrNjdIfVCHo0X0C/ffxzbDP+GniMB4/uGvyvI8e3OfGtSu8W7os3j5FCfBTevYO7tvFkyePjNrYkvr34P493N09mDRuNJ3bt2bKxHFERhif+Lxw3mx69h+KMPIcf8T/AO9XqELWbKZH+tiK3KlV6UFAzCi6qFZpmfqfGWRthe7HK6RjggYDB6ywfU9K2RFoDTQE2kkpl6MMkjfe4ZhOSi/SXWYlwqmRsVgAfPr5YBau3MRPi1YSGvqCdSuXmDiDcT345woODg4Mnr+GL35czu5Nq7jzz1XOHPPn2983MHvZVmKiojh6YCdxsbE4OTsz7scl1GzUkqU/TTN6zsiICCaMGsaAYSPJ5ubG1+OmsHn9Gvp270BkRAROjuk/o1ftNdbr47hy+RLtOnZm1bq/cXV1Zckfi1KlO35YiXuxFHFPkN++nXxUr3G6lMGY3gTCZWbM45vaQrf2peggYKsQog+QXQhxFQgFrFnbykEI4QxkA7ICOYHnQBaUVr5RGUhlRt92WEtcSyDdBR49RGxMDBHh4fTv1hYnZ2d6dVbodgmkO2vgSEmJcMWKmwcW2UppicXsKWP4asJ0QFnNqEHTlmxY9acq/xcP78enbCV0jo5ky+lOsXff48j+HXjmzU/2nMqKN+Wrf8Q/l8/jnjsP5avVVvZV+4ilP32T6nxxcbFMGDWM+o2bUatOfQDe9vZh9jyFc3T3zi2OBvilKRbmZO019sqbD6+8eRNblPUaNGKpkQr90vkzHAvw5cTRQ8TExBAZHs53U8cwYvx0XoQEc+3yBcZ+84PZPNmK3KlVaYm7reiiavWf7kM3oB0roUxJ7QL0ACpLKY0/+ybXHyj97WeAscA6IcQiIBBYbcanSdqitcS19CDdaSHC2VJpicVXE6bz/KmCDJZScsT/AN4+6l4u5fT04vYlZRZzTFQkN69epHCxd7h55SLRUVFIKbly9gT5CnlTrupHXD1/EoBrF07j9dbbyc4lpWTWNxMp7O1Dhy6vRjsEP38GQHx8PMsXL6RF6w4Yky2pf56eecibLz+3/lUI0MePHaFI0aKp0n36+WCWbdjN4rU7+HqiEvcR45Uf0QDfvVSqVhPnLFnM+rIVuVOrtMY9o+miadF/vYUOSuWf0KLWYXoKazJJKX8UQqwxfH4ghPgTqA8sklIeV5PZBNmSuKaFCAfaSHdabNIai1lTx/AiJBikxKdYSQaOGMfMSaM4cfI4kaEvmDewEzXb9cA1W3Z2L5tPROgL1sweS97CRek8aiYVGrRk22+zWfh1L6SU1GnUgqp1GvP4wV2+GdoDB50jb/uUoFbjlsRGR/P795PYu3k1WVyy0mPw6GR5uXD2NHt2KGTM3p8oLxt79x/Mvbt32Lxe+e2vWaceTVq0SlWOtMRC8zUePY6xo74iNjaWggULMWnqdIs2SeW3byftu/a0mC6jyZ2vi3KZ0XTRtCiz9ImrlVW0RSFEWWATSjfJfRSMYxTQWkp5NkNziDbaohbSXX53F9U2kPkvvpZYHLrzVJOvIjmyqbb5r079fxBsehijKRXKrY22qCWPWiiXWgmXWvKn5WuVXrTFTstOq87x6h7lX3tFYO3VWQz8DBQ04BsLAPMN++2yyy67/lPKiCXobCFrK/QSwBwD/SuBAvYTyuKldtlll112ZQJZ24e+HfgY+DvJvhbA/9I9Ryak9lE5h6v6oW2ZvetEq7Qs3NHmPbNLF5qUk079I7l7g6mafD3bPU61jaZrrPG2yJZFp81Qg7QUy9GG89ulhlXVXidP5T839T8FPlcHrBZCnESZYFQIqABszvAc2mWXXXbZWJmlC0Wt1OBzLyT5fAnYlf7ZsV7WApUeP3rINxNHJwKfPm7dng6du/HzT98R4HcQJycn3ipYiDETvyG7q4cRT7aBZtnCz/TJ4wjw98Xdw4MVa5Xf4uvXrjB7+hQiIyLI/9ZbTPxmlknwFcDK5UvZvHE9IChWvAQTp04ni4Vhd5by6P9LT5ydHXHUOfC372W+WepL4Xy5WD6hDR45XDl97SE9p28iNi6ewe2r8GnT8sTp48migxj9q1aHLUFqlsqUoPQAjllONYq2AAAgAElEQVTrK73Kpdfr6dqpHV5eXsz9+TerbGwJRbMFnOsNrc+VsaCZfQNkeEx8si0sWi+DQkJleEy8DAmPlm3atpNHAk8lHn/yMlY+eRkrL918IP2Pn5VPXsbKWw9DZN36DeSxM5fltt0H5YPnkfLJy1g56ZsZctI3M2RkrDS6HTpyXJ46e0E2adrMZJqUW1hUnKxbr568fvOOfBkeLZs3byEvXL5u1iaj/ASFxsqg0Fi5x/eIPHT8rGzUpGnivo9btZa7Dx6WQaGxcsmKNXLazO9lUGisfBmlT7XduP1A1q5dRz4JCZcvo/Tyi4GD5co165Ol0ZLH3I2/lS61p0i3et/I45fuyVr9/5DrD1yU3SZvkC61p8iFm0/IQT/8T7rUniIbDl0m3RtNly61p8jouHgZq7f+ngiPibdp3O8HR8tz1+/JA0dOy/vB0fL6veeybr0GMuDkJdmiZWv5v32H5P3gaLlo2Wo59dvv5P3g6HS7l6wpV3h0vNFtwcI/5OAhw2Sv3n1SHdOav5TfX2uulxZfGF7xpXXrtvKsVLu97npSSmn1S9EEyNZ7Qog6Qoi6CVuG/dJYzo9VQCVPzzyUTAJ88vb24emTJ1SuWgNHR+UBpfR77xP0xDQPIqOhWbbyU+6DiqnOf/f2bcp9oMzdqlSlGr7795j1p9friY6OIi4ujqioSPLk8UpzHsOjlAW9nRwdcNQ5IJF8VN6bjb6XAFi56ywtPlQ4cH5nbhMZraxGpY9P3r1tS5CatXFPK3BMja/0KNfjR4845O9LawvzH9Ijf1qul63gXA5C/ZYZZFWFLoT4EGXxUl9gD7AepcvFKriWEMJHCDFCCPGTEOIHIUQ/IYRxNJ0KqQUqPXxwn2tXL1OqTNlk+/+3ZSNVq9dMa3aSyVYQobT6KVK0GP4HFfDVgb27ePzY9ORfr7x5+aTHZzRvWI/G9Wrh5padqtVrpDmPDg6Co4v6cOfv4ew/+S837wfzIiwKvWGJtPtBobzlmT3VeR0dQJ/iXZutQGpa4q4FOKbVl1bNnjWdIcNGpAK4mZMtoWi2isV/fdjij8AsKaUHEGr4fyrwiyVDIcRgYAHggoIPyILyUvWoEKK2lkwnSA1QKSIinLFfD2XI8FHJ+iqX/fEbOp0jDZtYg6X572nMhKlsXLeanl3bExERgZOT6RExL1++wPfAfrbs2MPOvb5ERkayfduWNOchPl5Stc8iirWfQ8V33qLk254WbTrVfw8HAXEp5sZkVpDa6wCOqZWf7wE8PHJbXMwiPZVZr5fQsGUGWTtssQTKuPOkmgH8C3xnwbYPUE5KqRdC/ABsl1LWFkL8hjJKxihx0RycK6UsAZXi4mIZ9/VQGjZuxkd1Xy3ksH3r3xw+5MtPv/6R7r+wtoIIpdVP4SI+zPlFgUrduX2Lw4d8TaY9fvQIbxUsgLuH8vK4Tr36nDtzmqbNP06XPL4Ij8b3zC2qlC5ITjcXdA4CfbykQJ7sPHgampiuzgdFGPnJh0TrTfvMaJCamrinBTim1ldadOb0KXwP7OeQvy8x0TGEh4cxdtRXTJsx26ydbaFotonFmzqE2doW+gsgoYvkoRCiFOAOWDtnO+GHI0uCjZTyDmZoi+bgXGA9UElKybdTJlC4iA+dPvk0cf/Rw/789ediZvwwHxcXbdOtzclWEKG0+kkKvlr2x2+0atvRZNp8+fJz4dxZoiIjkVISeOwo3j6pgVRq85gzmzJKxsXZkXoVfLhy+yl+p2/R5iOl77lro/fZFnAVgPeL5WP+l01pN3ZNKj+2BKlZG/e0AsfU+EqrBg8dzq59vmzftZ8Zs7+nUuUqFivztORPy/Wyw7nMy9oW+kagKfAXynT/A0AsSl+6Jf0OBAohjgE1gZkAQog8KBhdTbIWqHTu7Cl2bd9C0WIl+LSLsmLM518MZc5304mNjWXYgN4AlC7zPlOmGp/gYitoVkb7mThmBKdPBBISEkKrJnXp9fkAIiMi2LhuFQAf1alPs49bm/RVpuz71KvfiK4d26LT6Sj57ru0aWe6IrImjwLY+WN3dA4CBwfBhoOX2HH0OpdvB7F8fBsm9qrN2euPWLpdITpO71ePbK7OrJzUFhdHiJfK0EWwLUjN2rinFTimxld6lEuLbAlFsxWcK7P0iauVVXCuVEZC1ERpae+SUlok/AghSgPvAheklFc0+JPhMepAQuFRZp7HTSi7qxr45JujsKg41TZZnLRBmP6TM0U16nmYutWfQBtwTKvi49V/99W8LE3mS0M9o+VapRec6/P1F1Vn+Ld2pV/7r4CmGkxK6a8y/UXgohZfdtlll1221pvah25u6r8/WAYwSClrpWuO7LLLLrtes97Q+txsC13TAs6ZRVouSFhUHG4u/81uF7WKSznA20o5aeBR7VgwQJOvGtOtWdI2uY6Mtd1cOJ0t4VdaLpcNK603rcX7pvahm6y9pJTLbJmRzCB7ZW6XXXaB9cP/MpvsNZhddtllVwr951romV1qaItTJ7yiLbZs3Z4OXbrx8kUI40eP4NGD++R7qwBTZ3yPm0tuo75sRVvMaBsttMVvJo0lwE+x+Wt98lmhK/9cwrwfZ7NzfwC53N1N5k9N/PZuXsWh3VsRQlCgcFF6DBnLnAlDiIqMACD0RTAVqtRg+vRpbPiiClJKNpx6wKpj9xjaoCi1SngSq5fcex7JxM2XCYuOo4qPO4PrFcVJ54CzTpldmnKAR0bF/fGjh0yfNIbnz58hELRo3Y72nbslHl+9Yim//PQdW/b4kyuX8Rhquf8ePXzIuDFf8/yZct+3bdeBrt16WLTTQkDU+v2w5ffq/4ve1CcLnJ2dWbh4KWs3bmb1+r85HHCIc2fPpEqn0zkyaNjXrFy/lYVLV7Fx3Sr+vXmD5Ut/p2KlKqzZtIOKlaqwYqnpVwYtW7Xh19/UvVLQ6/VMnzaFXxb8zt9b/sfO7dv450ZKIrFtbZq2aMUP85LjUGdMnUD/QcNYvnYTterUZ+WfyVcVbNaiNT/+vDDVuR4/esjxo4fJly+/2fyB9fELfvaE/VvXMeaHxUycv5L4eD2B/nv5asYCxv/0J+N/+hOfkmV4t3wV/nkSQdtfjtH9j5N0rFQQH8+sHP0nmPa/HKfjguPcfh5Bz5qFAQiJiGXoqnN0WHCcWD2kHJGZkXHXOTryxdCvWL52CwuW/MXf61dz6+Y/iTEMPHaYvBZiqOX+0znqGP7VKDZu2c7yv9awZvVf/POP+TKB9d+rtOZPq52Wa6VF/2k4V2aU1bTFPHko+a4y4zBbtmwULuJD0JMn+PseoElzZTJHk+at8DMAqozJVrTFjLbRQlssXyG1DcCc72YycMhwq94+q4lffLye2Jho9Po4YqKjyOXxiusSGRHO1XMnKV62MmGGef8RMXr+DQonT44sHL35HL3h7eD5ey/Im12ZgXr1URhBhjHhxt4dZmTcU9I+C3v7EBSkwKTm/ziL/oO+tPh4r+X+y5PHi3dLlQYgWzY3fHx8eGIFxEoLAVFL/rTa2WmL5mUtbTGLEGKaEOKmEOKFYV9DIcTAjM2eeWmhLV6/cpnSZcoS/OwZnnnyAJDb05PgZ8/SNW9aqHC2skkqNbTFBPkd2EceLy+Kl3zHaj/WyD23Fw1adWF0r9Z83aMFrtncKFW+SuLxM0d9eef9irgaKhyA/DldKJk/OxfuvUx2rpbl3iLgRupr6iBSd7fYKu4PH9zn+tXLlCpdFn/f/Xjm8aJYifSNoTHdv3+PK5cvW02etBWxUoveZNqiEGKxEOKJEOJCkn2ThBD3hRBnDFvTJMdGCyFuCCGuCiEaWZNvNbTFMkBXXjVyLgL9rbTPEKmmLX41lMEjRqVaGSYz4S9tLTW0RYCoyEiWLl5I3/6D0j0v4WEvOXvMn2mLNjBr6Vaio6I4emBn4vFAvz1UqvUKrubqpOO7DmX4bud1wmNezQzuVbMw+njJ9vPJv+g+ebLh6JCa0GgLRUREMH7kMAZ9ORKdo44VSxbRq1/Gt4ciIsIZMWwwX40cg5uZFZGSKrMSEG2pDGqhLwUaG9n/o5SynGHbDmDgZXUCShtsfhFCWBwUbG2F3hroIqU8AsQDSCnvAxZXEhZC5BRCzBBCXBFCPBdCPBNCXDbsy2XGrq8Q4oQQ4oQlH0lJbcYUFxvL2K+G0rBJM2obaIvuuXPzNCgIUJgSuTyMLz+nVVqocLaySaoE2uLileuo36gpBQoWMpv+3r27PLx/n086tqZV0/oEPXlMjy5tefY0yGqfpnTlTCCeefOTPac7OkdHylf7iJtXzgMQ9jKEW9cv8V7F6oAyhPq7DmXYcf4x+6+88t3i/XzUKu7J2I3JJyZ7Zc/CDx3fI1afutslo+MeFxfL+JFDaWCgfd6/d5eHD+7Ts0tbOnzckKAnj+n9SXuePX1qKUSqFBsby/Chg2narAX1GjRUbW/pe/U6ZCvaYkbAuaSUfljPr2oJrJZSRksp/0VZErSyJSNrK/QYUoyIMcC1rOmnWAsEA7WllB5SytxAHcO+taaM0pW2ODU1bfHDWnXYsW0TADu2baLmR5YhTmqkhQpnK5ukUkNbBChWvAQ79h9i0/a9bNq+lzxeeVn21wZye+ax2qcpeeTJx82rF4mJjkJKyZWzJ8hXyBuAkwH7ea9iDZyclX7xkvmy8e/TCFYcvZtoX72oB5/WKMzQ1eeIStIMd8viyLwuZZm79x+jfegZGXcpJTOnTqCwtw8duyqjTIoWK8GW3X6s3bKbtVt2k8crL7+vWEduT8sceGslpWTyhLEU8fGhW4/PrLazJbFSi2xFW3QQQvWWBg0UQpwzdMkkDHUqANxNkuYeVjSgrR22uA5YJoQYBiCEyA/MAVZbYestpZyZdIeU8hEwUwjR00r/qWQ1bfHMKXb+T6Et9uhsoC0OGEq3T3szftSXbNu8kXz532LqjO9N+rIVbTGjbbTQFsePGsGpk8cJCQmhRaM69Ok3kI9btzWbp5SyNn5FSpbmgxp1+GZoD3Q6Rwr5lKBmo5YAnPDfS6O2ynC/nK6O5MuZhUpF3Fn9eSUA5u+7yVdNiuOsc+DXbuUAOH/vJdP+d5VOlQtSyCMrfT/yxtnw0JqkhyZD437+7Gl2bVdoiz27KHHrM2AI1WpYT8zQcv+dOX2SbVs3U7x4CTq0VWI4aMiX1Kz1kVk7LQRErVRHW32vtEjLaBEjazgslFKmHiKWXL+iLBYkDf9/D2iuF62iLQohnFGwt32ArEAEsAgYKaU0i5QTQuwG9gLLpJSPDfvyAp8CDaSU9a3wr5q2GGFu9QMT+q/OFNVCW9Q6bd3VWf3c/6P/aKMoD1ttfjidMdly6v+LiFjVNjmzalu5SMvUf2kZ1ZRKmX0Kf3rRFsfuuKY6ONOalLDoVwjhDWyTUqZaFirpMSHEaAAp5beGY7uASYZub5Oy6odIShkjpRwmpXQD8gLZDX9bwwftCOQGfA196M+Bg4AHkP5wZrvsssuuNMpWXS6G3o4EtQYSRsBsAToZRhgWAYoDxy2dz6omqRAiZSda9oRRIVLKm+ZspZTBwEjDlvK8nwFLrMmDXXbZZZetlBEPIkKIVUBtwFMIcQ+YCNQWQpRD6XK5BXwOCnJcCLEWuATEAQOklBa7Haztcok3OExaTGlwrIGvl3jeO1LKt61IJyNj1T0B3Xgcpjo/hT2zqrYB21L1hAZE3jMNCy24uWi7rC4acIvRsdrGEWpZhKPbilOqbZZ1MbrsrUU9fhmt2iZ/LhdNvrQsVhGqoSsuh6u2LiEtC1xo+V6lV5fLpN3XVWd4UsPir70/yqoWupQy2TdHCJEP5dfF4ngmIcQ5U4dQum/ssssuuzKVMvu7AlPSumLRIyHEUOAayjqj5pQXaIQyTDGpBHBYi39QB+jp17k5rlmz4uCgQ6fTMWvBCv69cZXffpxObEwMOp2OPkNGUbim8WGeK5cvZfPG9YCgWPESTJw6nSxZspjNnxbIkRYbNRCmmOhohvb/lFjD+WvVbcCnfQYwfcJIrl65hKOjI++UKsOwURMApaU9deIrONeqDQqca8HPc/E/uB8hBO4euZkwZTp5vLzM5tOa6zV14lgO+R3E3cOD1Ru2AjD3h9n4+x3AycmJAgULMWHydLLnyJHK1ho/jg7we8f3eBEVx/DNlwHw9nClT7W3cdYJ9PGS34/e5cbTCD70cadVmXwIAVkclVExKRuZTRvVJVvWbDjolPvqrzUbTOZLr9czuFdncufxYsrs+WxZv4q/167k4f27rPnfQXKaAHOpiZ8pv107tcPLy4u5P/9mNI0pgNjihT+zbdOGRGhYnwFDaFS/Xip7rSAwgNCXL5kyaRz/XL8OQjBxyjTeL2f+icgWcK43tD5PE22xJMqIF0vaBrhJKVMNSRBCHNTiOAHQ89uiJeTNm5cuHdtRu05dihYrZtJm8g+/kSPnqy/N8t9+okP3vnxQpQYnjx5i+cK51K+5IpXdk8ePWbNyBWs3bcPFxYVRI4axe+d2WrQ0vZgyvIIcZc2ajdjYWHp270qNmrUo+365dLVJgDC9W6o04eFhdO7QlqrVa1C0aOpYODk78/38P3DNmpW4uFiG9O1B5WofUq9xM0ZPngHAtAkj2b55I126dgGg+cetad+pK5PHjUo8zyc9etJvgPJDs+av5fyx8BdGjZtkMo/WXq9mH7eifacuTEriq3LV6nwxeBiOjo7Mm/MdSxcvZNDQEZr86ONh2p4bDKzp/aosFQqw7sxDztx/SfkCOfikYgEm7bzOk9AYJu68RniMnuVdy+Osg2gjPRQLF/+JuxnSZII2rVtJIW8fIsKVrsBSZctRuUYtvh7Y26Ktlvs9QX+t+JMiRXwIDzfdBZkAECv5TikiwsPp3b0DlaooE7jad+5G527mx7GruQdTavbMaVSvUZPZP8wlNjaGqMgos+nTEgs1yixsFrWyluXiL4TwS7KdAI4BP1iylVL2klIeMnGsi7rsKkoXQI8QREaEAxARHoZ7btOTOvR6PdHRUcTFxREVFUmePOZbo8rp1UOOtNiogTAJIXDNmjX5+RFUqV4rEX/wTqkyBD15ZV++QkVy5EgOUEo6hTwyMtJiHq29Xh9UqESOHMknD1etXgNHR6XdUabs+2YBU5b8SCAsJvl7JQlkNfT7Z3XWEWwYangtKDwRJxAv09ZiC3rymMDD/jRu8aoRUKzEu+TLb3GeiFXlMqXHjx5xyN+X1hbGdpsDiFkjrSCw0NBQTp08Qas27QBwcnI2+/QFtoNzCQ3/MoOsbaGnZFyGA2ellNfTOT9WyRig5/w5U131SkU25asBCCFo0KItDZu3oeeAEUwdOYBlC+Yg4+OZNs/4YBuvvHn5pMdnNG9YjywuWaharQZVq9ewKp96vZ4uHdpy984dOnbuYhXkSItNgqyBMOn1evp/2pH79+7Qsm0n3i1TNvFYXFwse3ZsY8CXqQYkpdKv8+awfdsW3Nzc+GXRUrNp1V4vU9q6aSMNGjVJVz9Lj99jXINidKtUAAdg7PbU3BJHB4g38t5WCMEXn/dCAG3bd6Rte+OzbH/7aRa9vhhGhKEBoVZa4zd71nSGDBuhym9SgNj5s6f5e90qdm3fwjvvlmbA0K/I4Wp+NqsaENiD+/dwd/dg0rjRXLt2lXdLlearkWMSGx3GlF73kiX9Z1voBiBMXRSuwDLDtv51VeZa9M1Pf/Ddwr8YN2MeOzet5eLZU+zaso5PvxjOwjXb+XTAl/zy3RSjti9fvsD3wH627NjDzr2+REZGsn3bFqNpU0oL5EgrGMlaCJNOp2Ph8vWs2bKXK5cu8O8/ry7jT7OmUbZ8BcqWq2DRX/9BQ9m6az+NmjZn3eqVVuUxLVq8aAE6nY7GTVuk63kblvRkaeA9+q+7oPxfI/mgq9L53HDUJZ9ZmqAly/5i1dqNzP91EWtW/8XJE4Gp0hwL8CWXuwfFDS1gW8nP9wAeHrkpVTrV/BWTSgoQy+bmRqu2HVn19w4Wr1TQDj/PmW3BXh0ITK+P48rlS7Tr2JlV6/7G1dWVJX8ssjq/dqWWxQrdMPaxIQYoV3pKCLHDzDGTcC61gJ7chi6SnO4eVPmwDjeuXODg7m1UranMGqz+UQNuXLlo1Pb40SO8VbAA7h4eODo5Uadefc6dOW1lCRVpgRypsdECYXLLnoNyFSoReDQAgD9//5WQkOf0H/KV1XkEaNy0OQf27TGbJq1ApW2b/+aQ/0GmTp9ttntHi5/axXJz7HYIAEduhVDM8xWa9213V/pVL0y0iQmfXoZze+TOTd169bl4IXVL8eK5Mxw9dJDubZswY+JIzp4MZObk0WbzlB7lOnP6FL4H9tO0UV1GfTWcwOPHGDvK9LVNCRBTyuWJTqfDwcGB5q3acfniBZP2Wu5Br7z58MqbN7E1X69BI65cvmTBxjZwrv80Dx0FnztZCKF6EKoQ4gMTWwXA5Ns+c3AuNYCeqMjIxL7yqMhIzp44yttFiuGeOw8Xz54E4PzpQPIXME4ZzJcvPxfOnSUqMhIpJYHHjuLtU9RiubVAjrTYqIEwhQQ/JyxUOX90VBQnjx+lUOEi/G/zBgKPBTBuyiwcHCzfEndu30r87HdwP4Ut5DEtQKUjAf4sX/YH38/5BRdX13T38zwillL5lNZkmfzZeWQYO+6ZzYmv6hRhnv8toxPkIyMiEl80RkZEcORwAEWLlUiVrmf/IazYtIc/N+xg1OSZvF+hEiMnfmtFydNWrsFDh7Nrny/bd+1nxuzvqVS5CtNmGG9hGwOIATxNQtD0P7iPIiZecmoFgXl65iFvvvzc+leZm3j82BGKFDX/3bIVnCsjeOi2kNk+dCFEZynlKmAQkA/4UggRRBICqRUTgwIBXzD61sAkPtec1AB6QoKfMWuCMipCr9dTs15jyleujourK4vnf4der8fZ2Zl+w8cZtS9T9n3q1W9E145t0el0lHz3Xdq062Axj1ogR1ps1ECYnj0NYtbUcej1eqSUfFSvIdU+/IgGNcqRN19+BvX5BIAPa9fjiwEKq3vcqBGcOqHAuZo3rEPf/gMJOOTHnVv/4uDgQL78bzFy7ESzebT2eo0bNZyTib5q06f/QJYtXkRMTAwD+/UClOsx2sSIGkt+nBxgWtOSZHdxZEH7Mqw985DfDt/ms8qFcHCAWL3ktyO3AWj3fn7csjjSp1ohXByVGz7pKJdnz57x5VAlRnq9niZNm1Pjw5pm45BUm9atZP3KpTx//oz+3dtTqdqHDButrVxplSmA2L5d27l+7SpCQL78BRgxxvh11goCAxg5ehxjR31FbGwsBQsWYtLU6WbT2wzOlTnqZ9UyO1NUCPFSSplDCGHyykgpfc06UFbnaG2sz10IcVdKaR7AjX2maFLZZ4q+kn2m6CvZZ4oqSq+Zoj/43VSd4S9r+bz2nwFLo1wEWK60LWgSprt20n/ZG7vsssuuNOq/OlNUJ4Sog/HuEgCklKZXV1aOrzdz2PKMDLvssssuG+tN7XKxVKFnAf7AdIUugbQsZzIZO23RLrvsymR6QxvoFiv0cCllmtafel1wrhvPbNeHHhqpvi8yu8bFNISGpVSi49Qv9uEcp+2OzuKovg/dlq2h3zuaxiiY0vF/U2KIrFM2DYt9aO1D1zLKQutiGlqke8NqSIdMMvNTrWyxRE+GwLnssssuuzJKb9jvT6KseimaRqU7nAvME9cmjBvN3n37ccvpzpc/LAUgIvQlK3+cRHDQI9zz5KPrl5PJ6padi4GH2L36D4RwYGm2LAz/ejTlPkg+U9Ia2qIaYp2l9SStIeRZGwtj5x7Suwu583gxedY85nw7ietXLiGRFChUmC/HTEk29frxo4dMm2golxB8bCjX77/Ow993Pw4ODri7ezBm0jQ8TTButNL4Vq38k783rAMpadW2PV0+sWxjbSy0kh33bl7Fod1bEUJQoHBRegwZy5wJQ4iKjAAg9EUw3sVL8cVYZRndB3dvM//bMYn2Tx49oF23voS+fMGpI34IB0GOXB58PnwC7rmNL7Q9Ydxo/HwP4uGRm42bt1mMAWiPuRZfoI2AqJWaaAva4pvah27VAhevWymHLer1ej5u1igZcW3G7B8SiWsnTwRy5lEka+ZPT6zQty//FVe3HNRp3ZUDf68kMjyUpp/0IzoyAmcXV4QQvC2CGTViGBu2bE/09eTxY3r36JqMtlijZq1ktMWIaD1Pnwbx7GlQMmLd9Nlz2b93J66uWVMR68x1uSxftoRLFy8QHh6WqkJ3SHGnWYoFwP3gyMTPG1cv5/qVi0REhDN51jwiwsPImk2ZWLNw3nfkyuVBh249E/OXsly9unVg+ndz8fLKSzbD9O71q1dw6+Y/jBgzkewuqR/jg4Ke8DQoKBmN78e5PyfS+OL0qYct3rh+jTEjh/PnyrU4Ojkx+Is+jB43iUJvF05M4+SYvP/JmlgkDJE8dTKQrFmzMmncqMQK/ejhACpWrpJIdgQYNHQEp+8oM0mDnz1h9sh+TPr5L5yzuLBw5ljKVKxO9XrNEs+/4NvRvF+lJtXqNk3V5RKv1zPok2ZMnrOErG7ZE+O+a9Ma7t+5Sc/Bo3mvUHIQGij3c9asWRk7eqTJSjbl19hSzMF4K9QaXyllTdzTw8Yau/Qatrjw6G3VFWPfqoVf+8+AlsWtX7ssEdcqVKyEq1v2ZDYXAwOoULuxcrx2Yy4eVwCQWVyzJvY/RkZGGO2LtIa2mFZiXYKsJeQlSA197umTxwQe8adRizaJ+xIqFSklMdHRqcqfslze3j48ffI4sTIHhbho7hlVC43v1r83KfNeWVxcXXF0dOSDCpXYbwExoCYWWsmO8fF6YmOi0evjiImOIpfHK1hVZEQ4V8+dpFxV49M2Lp4JxCt/QTzz5k+MO0B0lHliZYWKlciRM3VFb05aCYhafGkhIGqlJtqMtijUb5lBb+Qy91qIa4uZ49AAACAASURBVGEvgsnhnhuA7Lk8CHvxqkv/wjE/dv61iOiwF8z5+ddkdlpoi5aIddlzmP7CqCXkqYnFb3Nn07P/0EQUQoJ+mD6BE0cO8ba3D70Hfmm2XNeuXqaUgdC48Oef2LV9C9myZeen3xZblV9raXxFixXnl3lzCAkJxiWLCwGH/Hi3lHnQVHqS+IyRHd1ze9GgVRdG92qNk3MWSpWvTKnyVRKPnznqyzvvV8Q1a7aUpwPgiO8eqtV+xTlZu/QXDu3dTtZsboyZ+atRm/SQGgKiFmmJu9ZrZTvaYiapoVXqjWyhp1UKe+HV32Wq1GLET8v5bs48FsyfmyytWtpiWoh1Wgh51upYgB+5crkbpf59OWYKyzftoVDhIvjt22XUPiIignFfD2Pw8JGJrfO+A4aw4X/7aNCkGRvXWlq4Sh2Nr4hPUbp/1puB/Xoz6Is+lCj5DjqdbW5XU2TH8LCXnD3mz7RFG5i1dCvRUVEcPbAz8Xig3x4q1Wpg9JxxsbGcOupHlZqvVvzp8OkXzF2xjep1GrNn67oMKYtaAqJdit7UFnqGf0OEEDmEEN8KIZYLIbqkOPaLGbt0oy0CuOV052XwMwBeBj8jW47Uc5o+qFiJ+/fuERL8qvWuhraYVmKdWkIeWB+LS+fPcDTAl0/bNWHmpFGcOxnI7CmvXtbpdDpq1W9MgG/qx9e4uFjGfZ28XEnVsElzfPftNZtPLTS+Vm3asWL1BhYtWUGOHDl5u7C32fTpQeIzR3a8ciYQz7z5yZ7THZ2jI+WrfcTNK+cBCHsZwq3rl3ivYnWj5z174jDexd4hp+EpMamq121M4CGz8/M0SUvMtUhL3LVeK5vRFjVsmUG2yMcSlNEyG4BOQogNQoiEISJVTRmlF20xQaUq1uDkQaU1dfLgTkpXUrpNnj68R8KL4SuXLhITG0POXK/6Vq2lLaaVWAfqCHlqY/FZv8Es/3s3S9fvYOSkGZStUIkR46fx4N6dxPwfO+RLobeLpCrXjCkT8C7iQ6cko0zu3rmdpFz7eds7uV3Kc2ih8T1/pvwAP3r4gP379tC4SXOz6dNK4rNEdvTIk4+bVy8SEx2FlJIrZ0+Qr5A3ACcD9vNexRo4ORtfa/bIwd3Julse3b+T+PnUEV/yG86TXtIacy3SEnet18pOWzQvW/ShF5VStjV83iSEGAvsF0J8rPWElohrI0d8ScCRI4SHvmDa5+1o0OEzarfuwsofJhG4/3/KsMVhkwCl//yk7y50Okc8c2bj21k/JLs41tIW00qsy6hYmJOUku+njSciPBykpEixEgwcMdZkuT4zlKvvF0P43+aN3Ll9C+EgyJf/LUaMnmDSj1Ya39fDh/DiRQiOjo6MHDPe4vJkamKhhexYpGRpPqhRh2+G9kCnc6SQTwlqNlLKc8J/L43adjPqKyoqkgunjtFz8CsO+prFP/Pw3m2EcMAzbz4+GzTKqC0o9/OJwOOEhATToG4t+g8YRBsLL821xlyLLy33oNb71la0xcxRPatXhg9bFEJcBkpLKeOT7PsU+AplfHphU7ZJ0qumLe689MhyohSqV9LyWqHGFBGtfiam1pmiKYctWqOkwxatldb8GRu2aEnGhi1ao5TDFq2RFrJjwrBFtdIyU9TYsEVrpOVrnEkalemq9Bq2+OeJu6oj2r1iodceUVt0uWxFWcIuUVLKpcBwQD3X1S677LIrg+UghOotMyjDu1yklF+b2L9TCGGeZm+XXXbZ9RqUOapn9XqtM0WFEHesWPEIIYQMj1b3qBwdp/7R2lXDI/KboEhjKxxbkNYGh5YFLmI0XCsAZw1dLraUe6WBqm2CA+dr8hWrodvK0YrlBlNK632hZYELLa3e9Opy+evUPdUZ7vJBwdf+O5DhLfTXRVu0yy677NKqzDJqRa3stEW77LLLrhTK3M9+pmWLfCfQFm+n2G4BB9NyYr1eT6f2rRk84HOTab6ZNJYmdT+kS7vkoyTXrlpBx9bN6Ny2RSKIyZQC/P34uFkjmjduwB+LFlqdPy12GWljLBaLFsynRcPadOvYmm4dW3PYP/lqg1MnjqVxnQ/p3PaVzYKf59K1fSs+6dCaQf16E/Tkidn8TRg3mto1q9Gmpflx5FMmjKVh7Rp0bPNqhube3Tvp0Lo5lcuV4pKZSVkJ0hI/a/Onxs5ZB8fWjOLk+rGM69cUgCXTenD27/GcWDeGBRO74mjoMirhnZeDy4YTcuxHdCYahlrKtXL5Ujq0bk6H1i0Y8/VwoqMtr3H66OFDen/WjTYfN6VNy2asXL7MKl9a8hcdHc0nndrToU1L2rZszq8pZmmnpy+1elPHoSOlzPQbIMOj41NtCxb+IQcPGSZ79e6T6tjz8Dj5PDxO7vM7Kg+fOCcbN2mauG/PwQDZ5ZPu8lFwhHweHidv3H0sn4fHychYmWoLi4qTdevVk9dv3pEvw6Nl8+Yt5IXL142mTatdRtmYi8XM7+fIeb8uTPw7YQuOULb9/kflkZOKTcK+u09CEj8v+H2JHDlmXOLfxvJ46MhxeersBdmkaTOjx19E6uWLSL08cOioPHZK8ZWw78zFa/Ls5RuyU5eu8siJs4n7X0Tq0+1aWcqfVjuXcgOkW8VB8vi5f2WtbrNly4E/S5dyA6RLuQFyzY5AOWjaKulSboAsVGekrNFlppyxaKeMidN2jV9G6ZNtN24/kLVr15FPQsLlyyi9/GLgYLlyzfpkaSJiZKrt9v3H8uSZCzIiRsqg4FBZv0FDef7y9cTjWu/B8Jj4VFtYtF4GhYTK8Jh4GRIeLdu0bSePBJ5KPK7Fl1Klpb3OWXv6vlS7ve56Ukr5xj5ZWE0lLF+hYip63MZ1q+n+WW+cnZ0B8PBIPR07QbakwmW0jbFYWFL5ChXJkQIm5paCtGipdWItwc8YAbGIT1G8zcxCTSqt10oLYdBaOydHHY6OOqSU7Dp0KXH/iQu3KeCl4CeCgsM4eekOsSZWltJaLmsooSmlhdKoNX9CCLIaQGZxcXHExcVZvJdsR1t8M1vob2yFnkAl1DLR5s7tW5w9fZKe3TrSv1d3Ll08bzKtMbrbYyswpFrsbGWTUutW/0XXDq34ZtJYXr58YZXNr/Pm0KJRXXZt30bf/oNU+csopUcs0lNHV4/izr4Z7D96hcALr1AJjo4OdG5WmT2HL5mxfiUt5UpKCW1crxZubtktUkJTylpKY1rirtfr6di2FfVq1aBqteoZ6kuN7CwXExJC5BNC/CqE+FkIkVsIMUkIcV4IsVYIkd+MnUk4V1qphHq9nhcvXvDHn6sZOGwEY7/+MpHn8v9Nbdp3YsPWXSxfvZHcnnmY+8Msq+z6DxrK1l37adS0OetWr8zgXL6ZqtppBsUajaNimcKUKvrqVv9pdEcCTt0g4PQ/GeZbLSU0pWxFadTpdKzZsIld+w5y4fw5bly/lmG+1CgjWuhCiMVCiCdCiAtJ9nkIIfYIIa4b/nc37BdCiLlCiBtCiHNCiA+sybctfliWApeAu8ABIBJoCvgDC0wZmYNzaaESJpVX3nzUqdcAIQSly5TFwcEhGWExeVrbUeFsSa1LUO4kNMiWbdpz6YLppxVjaty0OQcsLDxhK9mKxKdGL8Ii8T1xjYbVFWzxmL5NyOPuxtffb7T6HFrKpYYSmlJqKY3pEffsOXJQsXIVDh/yz3Bf1kho2KzQUqBxin2jgH1SyuLAPsPfAE2A4oatL2AVMN8WFXpeKeU8KeUMIJeUcqaU8q6Uch5gkeNiTFqohElVq3ZdTgYeB5Tul9jYWHK5p8bpgm2pcLak1iXoadArGqTv/r34FLUMOrpz+1biZ7+D+ylcxMdqfxkpW5H41MglixP1qrzD1VuP+bR1NRpUf5fuo5eqeiLUUi5rKaEppYXSqDXuz58/J/TlSwCioqI4duQw3hbuJdvRFtOfhy6l9AOep9jdEkgYSrQMaJVk/59S0VEgl7kejQTZYhx60h+NP1Mcy/CpmeNHjeDUSYWq16JRHfr0G0iLVm34ZtI4urT7GEcnJyZMmW7ykcmWVLiMtjEWi1Mnj3P96hUQgvz5CzAqCV0QYNyoEZxKpBLWoW//gQQc8uPOrX9xcHAgX/63GDnWPEHSWoLf2JGvCIjNGtSmb/+B5MiZk+9mTCM4+DnDBvajRMl3mLfg93SLn5r8WWsnACcdHF8zGgcHwYY9p9jhf4HQwJ+48/A5B5cNB2Dz/jN8u3AneXNnJ2Dl12TP5oKjg/KlTMp701IuaymhKaWF0qg17k+DgpgwdhTxej3xUtKgUWNq1a5j1sZWtEUH203+zyulfGj4/IhXky0LoPRqJOieYd9DzMgWtMUpwCwpZViK/cWAGVLKdlacwz71Pw2yT/1/PbJP/X+lN23q/7YLj1VnuMV7+T5H6R5J0EIpZbKB8kIIb2CblLKM4e8QKWWuJMeDpZTuQohtKPXjIcP+fcBIKWWqd4pJZQs4l1FQtpTyhhDifxnt3y677LJLrYSGFrqh8lY70+mxECK/lPKhoUslYZbefaBQknQFDfvM6nU3cSa/Zv922WWXXalkwzVFtwAJS4H1ADYn2d/dMNqlKvAiSdeMSf1n4VxXH4SqtinnnctyojdQcXoNj7s2/KnX8jiu2Ve8el9ac3d407eqbabu0TZsb1Qd00sbmpKWuOs01lxautW0dN9lZgkhVgG1AU8hxD1gIjADWCuE6AXcBhJedGxHGQ14A4gArHpDbYdz2WWXXXalUEa8FJVSdjZxqJ6RtBIYoNaHLSr0BDjXmZQHhBAH03Lipo3qki1rNhx0OnQ6HX+t2WA03c6/V+G7ezNCCAoWLkrvYeN58fwZv8wcR1joC7yLvcPnwyeZ9DNh3Gj8fA/i4ZGbjZu3WZU3LTaggIdmzphGvD6e1m3b06tP33SzefzoId9MHE3w82cgBB+3bk+Hzt34+afvCPA7iJOTE28VLMSYid+QM6eyfue0SeMI8PfF3cODleuUp8FrVy8ze9oUYmKi0ekcGTF6HKXKlE1zLKZOHEuAn+Jr1QZlEsyCn+fif3A/QgjcPXIzYcp08niZnsKuJX4J0uv1dO3UDi8vL+b+/JvF9KEvXzJl0jj+uX4dxP+1d97xUVTdH35uCi3UFIqAEJqCvnYRkN67FLEgSFVBkCYdRJpIUeR9rYiCBalSRAEp0nvvXXogEEgC6WVzfn/MJqRsmZ0kC+E3D5/5sDtzz5w7Z2ZPZu7c+72Kj8d/wtPPPJuhXFRkBDOnT+DqxX9BKXp9OIZVy+Zz/Yo2ejQqKgIfnwIEVnyMndu3kDt/IRoP/zrNPs5sXMaRP2bTauJccucvREJMFHvmfk50WAiSZKHKnV60btMujc38335h2ZLFIEKb9h3omGqS76w4rtTojfv9Psd6eUBG8rtMtj9Yi0iP5De1NrZ1zOz+v5/9Cwt/X243mYfeusm6PxcybsZPTPpmPklJSezevI6Fc76iSZs3mPbDEnzyF2DzWvuj6F5p045vZ9ruKpeVNhaLhUmfjOeb735g2YqV/L3qL/49dy7LbDy9vOg7cChzF//J93Pms3TxfC6cP8eLL1Xnl4XL+XnBMko/WoZf58xKsWneqg1ffJU2uX393+l0f+99fl6wlJ69+/L1f6c7rKPeWLRs3ZYZ36R9p9SpS3d+W7ycuYuWUbN2HX78/hu79kbil5p5c38h0IU+9dOmfEKNl2ux9M/VLFyynHJ2+nn//M1nPPNiDabPXsLU7+ZT8tFABoz6lCnfzWPKd/N4qWZ9qtasR51Graj53tgM9tFhIdw4dZB8RQJS1p3btpICxR6l0dAvqdP3U2Z8PpWEhHszOp47e4ZlSxbzy2+LmLd4Odu2bOLK5UsZ9p2Z40rGlbjf73OsFze2oWcp9/ulqFtIsliIj4/DYkkkPi6Wwr7+nDyyjxdragMSajZowYFdm+3aGxFvMmKT3eJc/v4BPPa4NmIxn48PZcuW49bNm1St9jJeXtrD2hP/eZqQm/e0MWwJeikgKlLrhRoZGYF/QACO0BuLzAqBZUa4Sa/YWzIREREc2L+PNu20Xrfe3rkoULBghnLRUZGcPHqQek21Pt1e3t745C+Qsl1E2Ll5PTXqNaHyU8+RK1+BDPs4vPwH/tO6G6nHIyoUiXHRiAiJcTEULFQIT897D9wXL5znyf88RZ68efHy8uK5519kg44RvXqPKzUuC8Tdp3PsCsrAvwcBdzS5ZBtKKd5/rwcKaN/hddp3eD1DGV//ojRr9xaDur5Crly5efK5lyhb4XHy+RRI+QEU8S9K2O2QDLbuxpbw0NEj9t4pG7cBuH4tiDOnT2ZoKlm5YikNGjVzaDtg8HAG9n2Xr2Z8RlJSEjPnZK+Wy7dfzmDVXyvInz8/38z6yW45o7GAe2Jv0dFRuspfC7pKkSK+jB09gjNnTlO5yhMMGTaSvPnypa1TcBAFCxfm28/Gcfn8GQIrVqZL78HkyZsXgFNHD1K4iC8lStqeifHa0V3kLeRH4ZJpFSfL12rBjh8msvLjLiTExvD551/gkepNdvkKFfnmyxmEh4eRJ3cetm/bQuUqzrWP9B5XmmPMRNyTccc5dgUDmn8PBPflDl0p5VzHUwdzfp7H/EVL+erbWSxcMI/9+/ZmKBMVcZcDu7bw2exlzPh1JXGxMRzZvzMr3OdYoqOjGDV0AP0/HI5Pqrujn3+ciaenF42bOZ7oYenvC+n34TCWr/6H/h8O49PxH2VrfbNbCMyI2JvFksipkyd49fU3mb94GXnz5mXOj7NslLNw4expGrV8lcnfziN3nrz8sfCnlO3bN62hRr0mNn0kxsdyct1inmj2VoZtN04dpFDJQFqM+5lGQ/7L1E8nEhl5b+xeYLnyvN2tJ3179eSD99+h0mOP4+np/Oeu97iymgdN7C2n3qG7Q23RN93iB+xRShVRSvk6sLOrtphMUasoj6+fH/UbNOT4sYx/qY8f2ktAsUcoWKgIXl5ePF+jHmdPHiE6KgKLJRGAsFs3KeLnuNnAHbhDnCsxMYHRQwfQuGkL6tRvlLJ+1Z/L2LFtMx9PnOJUOW71X39Q12pbv1ETh/LDWYkzITCjwk1GxN6KFitO0WLFUuReGzRqwqmTGeVw/fyL4htQlIqVtT8WL9VqwMVzpwAtee7dtpHqdRplsAOIuhVMdOgN1k3tx6pxPYi5c4v1nw0g9m4YF/esp+RTNVBKkT/gER4pWYqLF86nsW/T7lXmLljCrDlzKViwEI+WKes0FnqPK61N1glmZdc5dhWzDd0+t4D9qZZ9aJoEB6yfbeJIbREgJjqaqKjIlM87d2ynfIVKGcr5BRTj3OljxMXGIiKcOLyXkqUDqfyf59m7bQMA2/5ZyXMv1c7cUWYB2S3OJSJ8On4MZQLL8Uanrinrd+3YyrxfZjN5+lfkyZPXaT39/YtycL/2NLR/z25KlzaksaYLV4TAjAo3GRF78/cPoFjxEilJdM/unQSWz/jysLCvP34Bxbh2RTuOYwf3UPJR7RiOHtjDI6XL4hdgOyEVeqQsrSbOpfnHP9L84x/JW8ifhoNnkKdgEfIVDuDmmcMAxEaEceniBUqVKp3GPvT2bQCCr19jwz/raOrkycuV40pNZgWz3HGOXSWn3qG7ow19CNAIGCIiRwGUUhdERN80NHa4ffs2gwZoWhkWi4VmzVvycs1aGcqVf/xJXny5Ph/3fxsPT0/KlKtE3WZtePrFl/lm6miW/DqTMuUqUbtJ6wy2yRgRbzJik93iXEcOH2DNqhWUr1CJrh21Lm7vvT+AGZ9NIiEhgYF9egLwxJNPM2y0Jrg1ZsRgDu7fS3h4OK80rU/PXn0Y/tFYZkybjMWSSK7cuRmWTtDLaCwyKwTmLuGmlOMaMZpRw4eQkJBAqVKlGTthks1y3foM4avJH5GYmEDR4iXpNVg7hh2b1lKj3j152v9NGsmBA3uJi7zLyo+7UqVZRwKr2ZavrdzkdfbOm8HaKX1BhMEDPsygGDr0w/7cuROOl5cXw0Z+5PTlpqvHlYwrcc8p5zintqFnuzgXgFKqFPAFmnrYx8BhEdHdP8yIONeRy/pm3knNwzpSNCIm0WUboyNFfXK7fo8Qm+C6eBgYG0nozpGiZ65HOi+Ujt9POB3dbRMjI0WNzPblaTDTGTnHRs5vVolzbT0T5vJpr1WpyH3/M+CWXi4ichXooJRqDawD7L8yNzExMbnPPCht4q7i1l4uIrICqAc0BFBK6VPQNzExMXEj2TRjUbbjliYXu86Vuiwitjvgpi0nEbGuNbmERycYqpN/gVyG7B5kImNdb3IxKozk5en6pW2kGQSMNRm4k/M39fVpT025oj6GfJXqucBlm0vfZxy34QyjTS7uIquaXHaeC3f5oqxeofB9D85Dq7ZohIcxmZuYmLjOfc/MBjHVFk1MTEzSk0Mzeo5VW7x44Twjhg5K+R509Qq93u9Hx85pFeXi4+IY0LsrCfHxWCwWatdvRNd3+jBpzDBOnzqBl5cXj1d5koHDxwC279CNqrtlp3KiEZtJ4+4pJ85dpCknnj1zimmTxhMTHU2JRx7h44lT04weTY3emGfVcelV08ysH6N2elUk332jBXnz+eDh4YGnpyefzdRGQq5cuoDVyxfh4eHB89Vq0qXXAEP18/aA7Z80Q4BfNv3L91ZN9Z4NK9KjQUUsScK6w9cYt+gwzwb6Mr3biwDk8YIEC6SXy3dVbdGdyqJGfbnKg9Kv3GVE5IFfAImITbK7hEclSPXqNeTM+Ssp666ExsmV0Di5fDtWzlwNkyuhcXLhZqS0btNe1mzZI7//tU4u346Vy7dj5b0+/eXrWb9ITIJkWCJjE6V+gwZy9vxluRsVJy1btpJjJ8/aLJtZu+yyCYlIkJCIBFm3eads23NYmjRrnrKudZu2snbTDgmJSJA5cxfKJ1M+l5CIBIfxthfziNgkQ3WMikuyudSpW1euBt+2u/1+nquYBJFtO/fIgcPHpFnzFja3Hw+KlONBkfJyrTqy88SVlO/HgyJlwV8b5dU3OsmhC6FyPChSth+7LMeDIg3VLzZBxK/LfCnz3mI5d/2OVB+xUl759B/ZdOy6lOixUPy6zJfH+i4Vvy7zpdQ7i6RotwXi12W+RMUlSVJSkkTGpV0GDR4iv85bKJFxSRIWGSvXQ8JTthmJgztjjlVKPLPLrnPh4upyv/OkiDwcaot7du+kVOnSlHikZIZtSqkUYaHExEQSExNRKF6qURulFEopHq/yZBqFwdQYVXfLbuVEIzbPPJdROfHKpUs885w2GPfFl6qzeYNzRT5wHPOsOC4juPNcgTFFzWT+/uN32nXshncu7amwcBG7KhhO65d8gx0Zm8iZa3cpUSQvXetX4L8rT6bMFHQrIg7QJgy3OHgJbURt0V3KokZ9GcEc+n8fWfv3Kpo0a2F3u8Vi4d3Or9K+WR2er1qNyqkUBhMTE1i3+i9erP6yTVtb6m43bthO/pm1c5dNagLLV2DrJk0CYeP6Ndy4EezEQsNZzLOijslqmh1fa8eSxQuzzU9mY+gMpRTjhvThw3c7svZPrdno2tVLnDhygKG932ZU/56cPXU80/Ur7e/Df8oUYf+/tylfvADVKwWw5qNGrBhen2cD7/3BeK6cL9s+aUZeb4hL1wEqtdrimx3aMv7j0cRER2cyAsaP6X6RU7st5viEnpAQz+ZNG2jYuKndMp6ennz/6+8sXLGeUyeOceHfsynb/jv1E5569nmeeuZ5d1T3gWPkmAksXbyA7m91IDo6Gm9vb6c2emKeFehR08wJTPrfbD7/fh4fTfmK1csXcfzwfiwWC5ERd5nyzc906TWAz8YNS25eNIRPbi9+6vsyo+YdJDI2ES8PReH8uWgyYR0fLzzED+/XSCl74HwoNUetJiYB0vdOvV9qiw8cOTSju0NtsWmqz4WUUj8qpY4opeYppex2W9SjtgiwfdtWHq9cBT8/f6d1yV+gIM88/yJ7d20H4JcfviU8PJTe/e0r6xlVd3OHcmJm6pdMmcByzPhmFrN/W0zDJs0pmU7gyRauxDwzddSjpplVfrJTwc8vQFOLLlzEl5dq1ePsqeP4BxSlWq36KKWoVPlJlIcHd++EG67fnL4v8/vOS6zcfxWAa2ExrNynfT54IZQkAb8CudPYJP/5SN213IjaohHcpZpolJwqzuWOO/TUyj6fA9eBVsBewO7Ejc7UFpNZs3olTR08+oeHhRIZcReAuNhY9u/ZRekygaz8Ywl7d29n9PipaSYGSI9RdbfsVk7MbP2SCQvVFPmSkpL4+ceZtGnvfLCJs5hnRR31qmlm1k9m7PQQGxNDjHXSjNiYGA7t28WjgeWpWrMeRw9q9ypBVy6RmJBAwUK2tYSc1c/bA85cv8u3a06nrFt94Co1K2t/SMoXK0AuTw9uR8TxqL9PyuAghdb2m7pJ3YjaohHcpZpolJzahu7uGYteEJFnrJ+/UErpm7XWDjHR0ezeuZ2RH42zW+b2rRCmThiNxWJBRKjToDHVa9ah0cvPUKx4CT54pxMANes2YNCA/hnsjaq7ZbdyohGbj0cO5uA+TTmxTbP69HivDzHR0SxdPB+AOvUa0qJ1W4f+9MQ8K45Lr5pmZv1kxk6PimR42G2mfPRhynHUatiU56q+TEJCAl9NHUu/bh3w9vam3/BxdnXoHdVPAZ4eUKtyMTaO1ybK+OT3I/y25QL/61GVrRObkpCYRN8fdgHwUqUA+reoTIIlidxeEG9jELGraovuUhY16ssID0h+dplsH/qvlLoKTEeLUR+gvFidKqWOiIj96eLv7cMtQ/8f1pGi5tD/+4M59N/9ZNXQ/wOX7rp8UT5XpuB9D4477tBnAckz3/4M+AMhSqniQIbBRiYmJib3mwelTdxVsj2hi4jNZ3MRCVZKbcxu/yYmJiau8qC0ibuKu9vQ0zMOmJMdO86pJyQ7MNKgEZW+5oAsawAAIABJREFUg7JOCuVz3u0xPQnpx57rJLeBx/+YePdMtADubYe9MPM1l23GrDnjss3oBq5PpAFgpGU3X25jcc8Kcmr6MNUWTUxMTNKTQzN6jlVbdEWcq3+ve+Jcdeo3ouu7fVi2eB5LFszl2tUrLFuzhUKFi6R3kYK7BJ+yW+ToRvB1Jo4ZoXVVVIrWbTvwWsfObFi3htnff82lC+eZ9csCHq/yZBqbSWNHEhp6G4WiVdtX6fBm55TtC+b+xDf//YwV67ZS2E4M9R7XhI9HsW3LJor4+rJgyZ8A/G/6NLZu2Yi3tzclS5VmzLhJDoei643FxLGj2L5FEyqb9/uKlPWL5s9lyaL5eHh4UKNWHT4YMNimffD164weOVSbiFkp2r/6Gm/ZESl7J5041+czf2P+T9+xbuUyChbSYtapZ19eqFYz08eVmt9+/Yk/lv4OKCpUrMTHEyaRO7fWFz2Pl2Js4/JExln4bPNFABpX8qPao4WItD7FrDp1i1M3oyiS14th9QK5GRlPgTweWCzCyFEjbcYP4Ldf5vDlF9P4e8P2DPOcThw7ih1WgbjfFmt2o4cN4vKlC4AmPVCgQAF+WbAsS2PhKjm1Dd0dwlo/AjXtbJuXXeJcV8Pi5GpYnFwJjZWzQWFyNSxOLoZESuu27WXtlj2ycdch2Xf8vNSqU1eOXwiWq2Fx912cK7tEjm5GJMjNiAQ5cf6abN1zWG5GJMjF4HCp37CR7D58UvYcOSX7jp6R1958S7bsPig3IxIk+E68BN+Jl2P/Bsnm3Yck+E68nL8WJvUbNpJdB09K8J14OXz6krz1dlepVbuOnLp0Q4LvxBs6rvBoi4RHW2TD1l2ya/8Radqsecq6v9dvkVt34yQ82iITJk2RCZOmpGwzEovQqEQJjUqUf7bskh37NF/J69Zt2i4dO70twWHREhqVKOeu3JDQqESJjpcMy6WgG7L/0DGJjhcJCYuQho0ay9GTZ9OUOREUKSes4ly7TlxJ+X4iKFI++uQzmTT9mzTrThgU54pJELkba0mznLt0TerWrSc3w6PkbqxF3u/bT35b+HvK9qg4i3y++YJcuxMrg1ackkErTsnfp0JkxbEbKd+TlwnrzqWUcxS/0KhEOfnvFencpZvUrl1Hzl8NSVl/O1Jb1m/eJTv2anbJ61IvH4//RKZO/5/cjkw0FAuySJzryJUIcXW538JcbhHnEpEeIrLNzraOWeHDZXEupaj4WGWKZ6OwlBG77BY58g8I4LHKVQDI5+ND2cBy3Lp5k7KB5Xm0bKBtG/8AHnv8nk2ZsuUICdE0N776Yiq9Pxhkt/+0q8f13PMvUrBg2sE11Wq8jJeX9iD55FNPc9OB3ocrsXj2+YxCZUsXL+Dtbj3JZRXM8vX1s+srIKAolas8AYCPT37KlSvnsG6Zweg1aLFYiIuLJTExkdjYGAKsI1ZBk8yNNvA+IRlb8QOY8dkU+vb/0O5LLHt2oN1c/rNuDY2bNrfr111Cbzl05H/O13IBfeJc73R6lXZN6/BCOnEuZzyogk+Z9XP9WhBnTp2kiguxuH4tiLOnT1LliafYunkD/gFFqVDpcUP1NsKfy5dSw8HgoszG/PKlixw+uJ/unV+nd4+3OXH8qC67oKCrnDp5MmW4fHqUUowd0odB73ZkzZ/3NN1XLltI/x6v8eWUsSmjmW1h5LiKFitGpy7daNm4AU0b1CZ//gJUq2FbgC41LwcW4cM6ZXn96eLk9b6XHnzzeTOodhny5/bAy07W2LLxHwKKFqXiY8auiUMH9uPr60fpR8vaLeM2Ua8cmtHvS0JXStm/9XERveJcs+b+zqI/13PqeFpxrv+PREdHMWrIAPoPHm53MouMNtF8NGwgHwwahqeXJ3PnzKJHr77ZXNN7zJ71HZ6enjRt3irbfFgsFu7cucOPvyyg78DBjBo6yKlgVnR0FIMH9mPIsJHktxPLT/83m+nfz2NMKnGuZq078N1vK/hi1gKK+Pkz55vpWXosd+/eYfPGDaxYvY6/128mJiaGVX+tcGiz42I4k/45z/TNF7kbl0jrKtod/d04CxPX/8v0LZeIiU/CJ1fGtBEbE8NPs7/n3d4fGK7zujUraeTg7tydmFoudlBKTVZK+Vs/v6CUOg/sVkpdUkrVcWCXbeJce3Zu113/B1XwyaifxIQERg8ZQONmLahTv5EuH4mJCXw0bACNmmo2QVevcP1aEN07tue11o0JuXmDnp06cPvWrUwfjy3++mMZ27ZuYsKkaQ6bdzIb86LFilOvQSOUUjzx5FN4eHgQHpb+Xf49EhIS+HBAP5q3aEWDRo3tlrMlzlXY1w9PT088PDxo1LKdQ/lcI8e1Z9dOHilVkiK+vnh5e1OvQUOOHDro0CYy3oKgdXPddSmc0oXzAGBJEqITtJHaFtEWz3SZ4+rVK1wPCqLT621p07whITdv0KVje27fCnHoM5nExEQ2bVhPw8bNHJZ70EW97jfuuENvISLJv/RpwOsiUgFohCbWZZPsFOey115siwdR8MmoHxHh0wljKBNYjjc6ddW1fxFhyoQxlClbjtff0npxlK9QiRVrt7BoxVoWrVhLQNFi/DB3MX7++tQXXWHn9q38+vOPfD7jG/LkzeuwbGZjXrtuffbv3QNozS8JCQkZemkkIyKMGzOKwHLl6Nylm9192hPnCr19L9Ht3rqBRwPtC2AZOa7ixUtw7MhhYmNiEBH27t5F2XKORbYKpOr3/Z8SBQi2Torhk8sz5f7TQ4GngqR0ShwVKlZi9YZtLF+1nuWr1hNQtBg/z1uCn3+AQ5/J7N29kzJlAylarLjDcu76XZniXA58KKW8RCQRyCsiewFE5IxSKrcTW4foFeeaMn40SUkWkpKEulZxrqULf2PBr7MJDb1Nz7fa81KNWnz66acZK+9GwafsFjk6cugAa1auoHyFSnR9sx0A7/UZQHx8PDOmTSI8LJQh/d+nYqXH+OzL7wE4evgga1b9SbkKFenesT0A7/TpT/WXazuNgavHNXr4h+zft4fw8HBaNq7LO7378vPsWcTHx9O3Vw9AezE6YvTYTMfio+GDObBf89WqST3e6dWXVm3aMXHsaDq+2hovb2/GjJ9k94ng0MH9/PXnH1SsWInX2r8CwAf9B1GrdtqHzvCw20xOJc5V2yrO9cWk0Vw4dwaloGjxR+g9aJTd+Bm5lp586mkaNGzCW6+3x9PTk8cqV6bdq/cGH+XxUvSrWQafXJ581LAca07fprx/XkoWzIMAYdEJLD6i3QmX88tL08f8sSQJPrk9iE5IYrSN+LVu295hnQDGjLhn17ppPXr26kvrNu1Zv3a1ruYWo79HV8mu/KyUughEABYgUUReUEr5AguBssBF4DURsf9o6Gj/bhDn+gBNLncyUBsoAiwF6gPlRKSzA/PkfbgsznUnxnVxLr/8D6c4V4QBcS6jgllGRorGJbh2bpPJ7e36A6Y7R4peDHFdnCvQoDhXgsX1GI5d6/q7pAd9pGhWiXOdvB7lco0rl/Bx6tea0F9I1WqBUmoqECoik5VSw4EiIjLMVf/gHi2XL5VSR4HeQCWrz4rAcmBCdvs3MTExcRU3v+R8Bahr/fwzsAl4MBM6gIhsQqtkGpRS3cgmLRcTExMToxhpE1dKvQukHrb6vYh8n66YAGuVUgLMtG4vJiLXrduDyYQkykMrzmViYmJiFCP359bknD6Bp6emiAQppYoC65RSp9LtQ6zJ3hA5RpzL1bZ+rwdciN+d+ORyvS0yLtFYu7YRkrL5PU5qctsbFeMAoz0Y/Nw5YYqBEBppD392xGrXHQFHpzwY/ct1k03pQ0SCrP/fVEotA6oCN5RSJUTkulKqBHDT6P5zrDiXiYmJSXaRHW3oSikfwENEIqyfGwPjgRVAF7SOI12AP4z6cEc/9L+A/CJyKd1yERvt6o4YN2YUjeq+zGvt7o0WvHMnnPff607bVk14/73u3L17J43NjeDr9O/Vjc6vtebt115h8fxfAZj9/de0a16f7h3b071je3Zu32LX75jRI6hbqzrtXmmpu67usgFNfa51iya0bNqIH2c5e+JLi8Vi4Y0ObenX5z2b2yeOHUWz+jXp+GrrDNt++2UO1Z6t4nDwDeg/rqzwlZ2xMOLrRvB1+r3XjU4dWtM51fX3w7df0uWNtnTr2J5Bfd7hVojjmzK9x2XkN6I37krB/L7VWDeiDmuH16FbnbTjOXrWK8fF/7akiE/ank5PPVqI/LkVXh7G6mc0Fpkhm/qhFwO2KaUOA3uAlSLyN1oib6SUOgs0tH43RI4S52r1Shu+/DbtCfxp9iyqVq3Osj/XULVqdX76cVaa7Z5eXrw/YAi/LlrBd3Pmsez3BVw8/y8AHd7szOx5S5g9b4nDftWvtGnHtzN/cKWqbrOxWCxM+mQ833z3A8tWrOTvVX/x77lzuu3nzf2FwMBydre3aNWWL77O+KO5EXydPbt2ULx4Cac+9B5XZn1ldyyM+PL08qLPwCHMXbyCmXPmsXTxAi6c/5c3O3fj5wXLmDNvCTVq1eGnWd9myXEZ+Y3ojrvAxOUnaPTpZtp+sY3ONctQoZgmd1CicB5qP+bP1dDoNPvwUDC8VWWSe1UaqZ/RWGSG7JByEZHzIvK0dXlCRD6xrr8tIg1EpKKINBSRUKP1zlHiXLbU+DZv3EDL1trAjpatX8mgvOZILVAvRlQQ3WWTGfW5G8HBbNu6mbYOBi8ZVdVLjd7jyqyv7I6FEV/pr7+yZctx6+aNNBo6MTExDo/NleMy8hvRG3cBjl/VRl1HxVn490Ykxa3yAB+1fYJPV5zM0JbftXYgqw9fT1ltpH5GY5EpTHGu+0No6G38rVoZfv4BhIbetls2tVogwLLF8+n6Zlsmjx9NhJPHvAeVzKjPTZs6if4DB+Ph4gvkzKrqZZcvd8bCiK/r14I4c/qewuX3X/+X9i0asG71SodCZ5lVGHTlN5KMs7iX8s1LlVKFOHQxnEZPFuPGnVhOXotIU6ZYoTw0eao4c7dfyrL6uUtt0RTnegBQyn5gU6sF+uTPT5v2rzN/2Wpm/6bpTXw9Y5qba3t/2bJ5I76+flR54knnhVORFap6D5ovo7FwhejoaEYPHUi/D4el3J2/26c/S1b+Q6NmLVi6aF62+U6No99IMs7ini+XJ992f57xS4+TmJREn0YVmL7qdIZyY9pWYfKKky6NEtVTP3eQU7Vc3KG2eEApNVop5VgZKKOdLrVFX1+/lBdKt0JuUsTXN0OZ9GqBAL5+/ilqdy3bvMrJ48dcqd4Dg1H1uUMHD7B54waaN6nP8CEfsnfPbkYNH+LULrOqeq7gqi93xsIVX4mJCYwemvb6S03jZi3Z/M/6LPFlCz2/kdQ4iruXh+K77s+zfF8Qa44EU8bfh1J++Vg9tDbbxtSneOE8/DWkNgEFcvPUo4X5sstzbBtTHy8PyO2tbGqpu1I/d6kt5tAWF7fcoRcBCgMblVJ7lFIDlVKPODPSq7ZYp259/lqh9fL5a8UfGZTXbKkFAtxKlRS2bvqHwPLGNCruN0bV5/oN+JA1/2xm1ZoNTJ72OS9WfYlPJjt/Ssmsqp4ruOrLnbHQ60tEmDx+DGUDy/FGp3vX35XL95ohtm7a4FABNLMKg85+I+lxFPcpbz7NuRuR/LhJmwP09PUIXhi9jprjN1Bz/AaCw2NpOW0LIRFx1LKuqzl+A4lJEJcg2Bre4Er93KW2mFMzujv6oYeJyGBgsFKqFvAmcEApdRKYb2NorF1GDrunxte8UV3e7d2XLt17MmLIIP5Y/jslSjzCp9O+SGNjTy3wnzWrOHvmNEpB8RIlGTzyY7t+jaggussmu9XnbKkS6lHVS43e48qsL3cp8bniK/X11816/b37fn9W/rGUy5cuojwUxUs8wuARY7LkuIz8RvTG3dMD2lctxclrd1k1RJs5aurK02w6oX8cjJH6GY1FZngQmn2M4A61xQMi8ly6dZ5oeuivi0g3HfuQuzGuqeQZmS/RiFJgTsCIcqLRkaJ5DYxKNaKAaNSXkVi4+tI4mbsGFD8L5jV2DSYYOF+JBmLhzpGi3gZG9WaV2uKl23EuB6eMX+77/lfAHXfoZ9KvEBEL8Ld1MTExMXmgeFBecrqKOwYWvWFvm1Vt0cTExOSBIoc2oWd/k4tD50pdFpFHdZRzeYILI4L/Rh7hcwJGxK+i44w1g+TP4/pDnzubXBItrsfCy9PYz/XoFdfHNjxZyrWBZcnEJrgew4sh0c4LpaOcwQk4zgRHOC+Ujv+Udj0WWdXkcjXM9SaXUkX+HzS5ZJXaoomJiYn7uO+52RCm2qKJiYlJOnJqG7o7Enqy2uKh9BuUUpuM7vTihfOMGDoo5XvQ1Sv0er8fHTt3SVNu4thRbN+ymSK+vsz7fUXK+kXz57Jk0Xw8PDyoUasOHwwYbNfXmNEj2LJ5E76+fiz94y/dddy+dQtTJn9CkiWJtu070OOddx8Ym7i4OHp06UR8fDwWi4WGjRrTu2+/DOUmjRvN9q1a/OYu0voKnz1zimmTxhMTHU2JRx7h44lT02iTGK2jrXM167uvWLH0dwoXKQJA774DqFGrTgbbzMRC77WUHj3XxbUrl/jq05Ep328GX+PVzu8ScfcOB3ZuQXkoChb25b0Px1DEz3b/+uDr1xk9ciiht2+DUrR/9TXeslM3e9c7aMqJX34xjb83bE+JZzJRkRHMnD6Bqxf/BaXo9eEYVi2bz/UrWn/5qKgIfHwKsHipdg1M+HgU27ZsooivLwuW/AnA/6ZPY+uWjXh7e1OyVGnGjJtEgYIFszQWYOwcu0oOzefawIcHfQEkIjbJ7hIelSDVq9eQM+evpKwLjUqU0KhE+WfLLtmx74g0bdY8Zd26TdulY6e3JTgsWkKjEuXclRsSGpUoMQlic9m2c48cOHxMmjVvYbdM+iUyNlHqN2ggZ89flrtRcdKyZSs5dvLsfbGJik/KsETGWSQkPEKi4pMkPCpO2rV/VXbuPZCyPSQiQUIiEmTd5p2ybc9hadKsecq61m3aytpNOyQkIkHmzF0on0z5PGWbkTo6OldTPp8hX377fcr31IuRWDi6juxdS0aviz3nw9Msu87elhdfqiardp6UTUevpqyfMH2m9BowTPacD5foeMmwXAq6IfsPHZPoeJGQsAhp2KixHD15Nk0ZRzEMjUqUk/9ekc5duknt2nXk/NUQCY1KlAMX76YsPd8fKJ99+4scuHhX9py9LVuPBaXZPnDEOBk18XMJj7ZIeLRFNmzdJbv2a36S1/29fovcuhsn4dEWmTBpikyYNCVlm5FYGLmWtJSW+ZxzLTxOXF3ud54UkYdDy2XP7p2UKl2aEo+UzLDNlpLc0sULeLtbT3Ll0maU8fX1c7h/d6kgussGNM2MfPm0F1yJiYkkJiaibDxnPvNcxvhduXSJZ57TBvC++FJ1Nm9YlyV1tKf6p5esUOJzdC2lx9Xr4vihvRQtUQr/YiXI53PviSYuNsZm7JMJCChK5SpPAODjk59y5cpx044glRHFyuioSE4ePUi9pprioZe3Nz75C6RsFxF2bl5PjXpNUtbZUk2sVuNlvLy0h/4nn3rabh3BeCzcpbZoinPdR9b+vYomzVroLn/50kUOH9xP986v07vH25w4fjTL62REFc5dNslYLBZeb9+GBrVfplr1Gvznqad12QWWr8DWTRsA2Lh+DTduBDssn1mFvMUL5vHWa22YOHaUw8kPskKJz9VryRV2bl5H9bqNU74v+ukb+nVqyY6Nf9O+s75JNYKCrnLq5End5wqcKyfeDA6iYOHCfPvZOIb37sjM6ROIjYlJ2X7q6EEKF/GlREmnHdJS+HP5UmrUrGV3u9FYuEttMaf2W3SHONcLSqmNSqm5SqnSSql1Sqk7Sqm9SqlnHdjpEudKSIhn86YNNGzcVHedLBYLd+7c4cdfFtB34GBGDR3k8pylDwOenp4sXLKcNf9s4tjRI5w7m2EMmE1GjpnA0sUL6P5WB6Kjo/H2zr4Rtu06vMGSP9fw64Kl+PkH8L/pU7PNl5FrSS+JCQkc2LWFl2o1SFn3Wtf3+d/cv6hRrynr/lzsdB/R0VEMHtiPIcNGkt/JO4tk9ChWWiwWLpw9TaOWrzL523nkzpOXPxb+lLJ9+6Y1ae7OnTF71nd4enrStHkrm9uzIhbZTQ7N5265Q/8GmAqsROvVMlNECgHDrdtsoleca/u2rTxeuQp+fv66K1S0WHHqNWiEUoonnnwKDw8Pp1ObuYoRVTh32aSnQMGCvFD1JXZs26qrfJnAcsz4Zhazf1tMwybNKVmqdLbV0S+VKuYr7Tpw4pj9p6nMxsLItaSXw/t2ULbC4xQqkrF5r0b9puzdtsGhfUJCAh8O6EfzFq1o0Kixw7Kp0aNY6edfFN+AolSsrMkHv1SrARfPaZPRWyyJ7N22kep1MqpE2uKvP5axbesmJkyaZrfpJDOxcJvaoimfaxdvEVktIvPRXlj8jvbhHyBPZne+ZvVKmrr4iFy7bn32790DaM0vCQkJGd76ZxYjqnDusgEIDQ0l4q42+0xsbCy7d+6grM7p18KsExAkJSXx848zadP+9WypI8CtkHuJZ/OG9ZQrb1+IKbNKfEauJb3s3LQ2TRNDcNDllM8Hdm6mROmydm1FhHFjRhFYrhydu7g2uFqPYmVhX3/8Aopx7cpFAI4d3EPJR7Vr4eiBPTxSuix+Ac6T5s7tW/n15x/5fMY35Mmb1365TMTCXWqLObUN3R3dFmOVUo2BQoAopdqIyHKlVB3A2BBBKzHR0ezeuZ2RH42zW8aWklyrNu2YOHY0HV9tjZe3N2PGT3L4IsZdKojusgEtUY4ZNZwki4UkERo1aUrtuvUylPt45GAO7ttLeHg4bZrVp8d7fYiJjmbp4vkA1KnXkBat22ZJHW2dqwP793D29ClQihIlSjJ89NgsjwXou5bSo/e6iI2N4diB3XTvNyJl3cLZX3P96iWU8sC/WHG6fTDcrp9DB/fz159/ULFiJV5rr724/KD/IGrVzth906hiZbc+Q/hq8kckJiZQtHhJeg3W1Ed3bFpLjXoZnwhGD7+nmtiycV3e6d2Xn2fPIj4+nr69egDai9ER6c5XZmPhNkXNByM/u4w71BafRmtySQIGAr2BLkAQ8I6IOB1cZA79zxzm0P97mEP/72EO/bfPrchEly8U//xe9/3PgDvEuQ6LSBMRaSYip0Skv4gUFpEngMey27+JiYmJq5ht6MbQ/3xrYmJi4ibMNnQ7ZJU4l6tNKEYe4x/WJhcjzSeeBid1MMLD6qt4oUy/89fNwcvhLtv8x0DzjrfBVoUnShZ0Xigd97Mn8YNyx+0qpjiXiYmJyUNCjhLnMiI8FB8XR/9eXVNEqOrUb0S3d/tw/dpVxo8eyt074VR6vAojx34K5LLp92ER5zIitJUV4mZ66zh+zD3Bp4VLNcGn9Wv/5vtvv+LihfP89NsiqjzxZJbEIjWuiF+56is+Lo6BvbuRkKBdf7XrNaTLO32YOmE0Rw7uSxliP2T0BCpUsj2S05X6bfhzIdvWrgCBlxu3pkHr14mKuMsP0z7i9s3r+BUtQc+hE/DJf++O+UbwdSaOGaF1R1WK1m078FrHzmxYt4bZ33/NpQvnmfXLAh6vYjv2eoXebNG8SX188vng4emJp6cn8xYucVje6Ln6f8P9FpPRK87lqvBQUFicBIXFydXQWDkXFCZBYXFyKSRSWrdtL+u27JF3eveVXxcul6CwOPlw2Cj55odfHlpxLiNCW0bEzewJnDmr450Yi9yJscjGbbtk9wHNV/K6Q8fPyOGT5+SNjm/Jzn2HU9bfibEYioUR8Sujcb98O1Yu3YqR01dC5fLtWDl/I0Jat2knf2/eLX0HDJa5i1fI5duxaRaj4lz/nLwlv/y9W+o0bCKrD12VtceCpdWrHWX+hkPSZ9g4GTphuvxz8pYMnTBd+g4fJ/+cvCU3IxLkZkSCnDh/TbbuOSw3IxLkYnC41G/YSHYfPil7jpySfUfPyGtvviVbdh+UmxEJhoTeouKTJCrO9lKnbl25Gnzb5jYjsSCLxLnCohPF1eV+58kcJ85lRHhIKUXefPkATYTKkpgISnFw3x7q1NdGvzVp0Zptm+2PTntYxLmMCG1lhbiZ3jraEnwKLFeesmUDHe7fVT/pcUX8ylVf6a8/eyJoWVG/4KuXCKz0BLly58HT04tKTz7LoZ2bOLx7K9Xqa5M0V6vfnEO70o4I9g8I4LHKVQDI5+ND2cBy3Lp5k7KB5XlUR+z1Cr1lBUbOlRFy6kvRHJXQbeFMeAg0rYqenV6lbdM6PF+1GiVLlSZ/gQJ4WpXhAooW51bIzSytV04Q5wLXhbbAdXEzdwkqZYUfveJXrviyWCy893YHXm1el+erVqfyE08BMHvml7zTqT3fzJhKfHx8puv3yKPlOHfiMJF37xAfF8ux/TsIu3WTiDuhFPLV5AwKFvEj4k6o3f1fvxbEmVMnqfLkU7rqk/oYjQi9KaV4/70edHytHUsWL3TJpxGhMr2Y3RbvA3qEh0ATofph7u8s/nM9p44f4/LFC26q4YOPEaGth1XczIj4lR48PT2Z+ctiFvyxjlMnjnHh37P06N2fOQtW8PXs+UTcvcPCX2dnun4lSpelcbtO/G/sAL4cO5BSgZVQHml/4tqds+3sEx0dxaghA+g/eLjTCUtsHaMRobc5P89j/qKlfPXtLBYumMf+fXt12WXXuUrGFOeyg1Iqv1JqvFLquFVlMUQptUsp1dWJnVO1RT3CQ6nJX6Agzzz/IsePHiYyIkJrfgFCbgbjH1A0E0eZkZwizuWq0Jbm0zVxM3cJKmXGj6viV0Z85S9QkGeee5G9u7bj5x+AUopcuXLRpGUbTp04liX1e7lRK0ZOn8OHn35LvvwFKPZIaQoU8uVO6C0A7oTeokCgurLeAAAPJ0lEQVShjLpFiQkJjB4ygMbNWqQ0RRrBVaG3otaY+fr5Ub9BQ44fs9fL+R5GhcpcIodmdHfcof8GnEfrujgO+B/QGainlJpkz0iP2qIe4aHwsFAiIzQRqrjYWPbv2UWZwHI8+/yLKe3Fa1au4OXaGXVMMsODLs6VjKtCW+C6uJm7BJWM+jEifqXXV4brb+9OHi0TmHLTISLs2LyBsuUrZEn97oZrzSmhIcEc2rmJF2s35qmqNdm1YRUAuzas4umX0uqUiwifThhDmcByvNGpq67jT41RobeY6GiioiJTPu/csZ3yFSo5tMmMUJkr5NQ2dHdouRwWkadTfd8rIi8qpTyAEyJiv/H7no2ERiWmER7y9fXLIDzUpnlDfvptMYWLFEkZWPTv2dNMHj+apCQLSUlC3QaN6dKzN9eCrjBh9FDu3r1DxUqPM3LcZIr72n50Sy3C5Ovnp0ucC2Drls1MnTwpRUTonfd63xebyFjtSSS10Javn59Noa1eHwxEKZUyAMdWzJu1bMXEsaM5e/oUXt7e9Bs4hBeqVgPsD85yVMf4RG3Q2Khh9wSf/Hz9eLd3XwoWKsRnkz8hLCyUAgUKUumxx/nyux8AyOWV8X7EWSxsXe4HD+yj29tvUbHivSaK1OJX9tpHnfkKuRvH+XNnmGK9/kSSqFO/CZ179GJw3x7WpxqhfMXHGTD0I/Lmy4d/gdwu1w9g57/aH+bPRvQm6u4dPL28eLV7Px5/+gUi797hh2mjCQ25gW9Acd4ZOhGfAgVTBhYdPrifPj3fpnyFSijreX+vzwDi4+OZMW0S4WGh5C9QkIqVHmPmDxmbhs6cPp1B6O293n3SFrIR96tXrjBoQF9Aa8Zr1rwlPd/tlbLd1otVZ7HIlytrtFyi4l1PjD657n9LujsS+g5gqIhsU0q1BvqISBPrttMi4lTPJTmhu4KRkaK++W33Q8/pJCd0VzA6otLIaNvkhO4qthK6M4xc7kZ/piF341y2sZXQ9ZCc0F3ByEhRn9wGR1Mbirvrgc+qhB5tIKHn05HQlVJNgf8CnsAPIjLZQPXs4o6BRb2AH5RSFYHjQHcApVQA8LUb/JuYmJi4RjbcayulPNFyXiPgKrBXKbVCRE5klY9sT+gicgSoamN9iFLKdU1NExMTk2wmm9rEqwLnROQ8gFJqAfAKkHMSuhPGAXP0FPT1ud9VNTEx+f9CNrWGlwSupPp+FXgpKx24o9viETvLUXSqLYqIsrcA7znanlU27vT1oNfPjIUZi/vty5FNVuStPF4oV5fUXa2ti3MhoaxGsl+H5QbwDFAm3VIWuJYF+9/nDht3+nrQ62fGwozF/fZltH73cwGqA2tSfR8BjMhKHzlKbdHExMQkB7MXqKiUCkSbgvMNoGNWOnDHS9EeDrZl6cGYmJiYPKiISKJSqi+wBq3b4mwROZ6VPh6GN43fu8nGnb4e9Pq509eDXj93+nrQ6+dOX0brd18RkVXAquzav7K25ZiYmJiY5HBytNqiiYmJick9cmxCV0o1VUqdVkqdU0oN12kzWyl1UynlWNourU1ppdRGpdQJq2Jkf512eZRSe5RSh61241zw6amUOqiU0jXfnVLqolLqqFLqkCN1Sht2hZVSvyulTimlTiqlqjsp/5jVR/JyVyk1QKevgdY4HFNKzVdKOZ1BWSnV31r+uCM/ts6rUspXKbVOKXXW+n8RHTYdrL6SlFIZROHs2Eyzxu+IUmqZUqqwTrsJVptDSqm1SqlHnNmk2vahUkqUUv46fY1VSgWlOm/N9fhSSn1gPbbjSqmpOvwsTOXjolLKVkcIW3bPKE2B9ZC1u19VHTZPK6V2Wq/7P5VSrs9C/TByv7vyGOz+4wn8C5RDmwj0MFBFh11t4DngmAu+SgDPWT8XAM7o9KXQevcAeAO7gWo6fQ4C5gF/6Sx/EfA3EMefgZ7Wz7mAwi6eg2CgjI6yJYELQF7r90VAVyc2TwLHgHxo73rWAxX0nldgKjDc+nk4MEWHTWXgMWAT8IJOP40BL+vnKen9OLArmOpzP+A7PdcqUBrtpdolW+fcjq+xwGBXfhdAPWvMc1u/F9VTv1TbPwfG6PS1Fmhm/dwc2KTDZi9Qx/q5OzDB1ev/YVxy6h16yhBaEYkHkofQOkREtgD2p2uxbXNdRA5YP0cAJ9ESlDM7EZFI61dv6+L0hYVSqhTQAvjBlXq6ilKqENoP5UcAEYkXkXAXdtEA+FdELuks7wXkVUp5oSXpa07KVwZ2i0i0iCQCm4F2tgraOa+voP3Bwvp/G2c2InJSRE7bq5Adm7XW+gHsAkrptLub6qsP6a4NB9fqF8DQ9OV12NnFjk1vYLKIxFnL3NRhA4BSSgGvAfN1+hIg+Q67EOmuDTs2lYAt1s/rgPaY5NiEbmsIrdMkm1mUUmWBZ9HutvWU97Q+dt4E1omIHrsZaD9YVyQIBVirlNqv9I9OCwRCgDnW5p0flFI+Lvh8Axs/WJuVEwkCPgMuA9eBOyKy1onZMaCWUspPKZUP7c7N+ewb9ygmItetn4PROSo5k3QHVustrJT6RCl1BXgLGKOj/CtAkIgcNlC3vtYmntnpm5/sUAkt/ruVUpuVUi+64KsWcENEzuosPwCYZo3FZ2gDbpxxnHs3cR1w7dp4aMmpCd3tKKXyA0uAAenuruwiIhYReQbtrq2qUupJJz5aAjdFZL+L1aspIs8BzYA+SqnaOmy80B5jvxWRZ4EotKYJpyilcgGtgcU6yxdB+/EFAo8APkqpTo5sROQkWhPGWuBv4BDguiYy1mngDQm46kcpNQpIRJvQRRciMkpESltt+jrZfz5gJDoSvw2+Bcqjjdi+jtYc4gwvwBeoBgwBFlnvvPXwJjr/2FvpDQy0xmIg1qdGJ3QH3ldK7UdrCtU3KetDTk5N6EGk/YtcyrouW1BKeaMl899EZKmr9tamjI1AUydFXwZaK6UuojUj1VdKzdWx/yDr/zeBZdhQt7TBVeBqqqeG39ESvB6aAQdERO8MzA2BCyISIiIJwFKghjMjEflRRJ4XkdpAGNr7C73cUEqVALD+n7WzgKdCadMptgTesv7xcJXfcN5kUB7tD+Jh6/VRCjiglCru0AoQkRvWm4skYBb6r4+l1qbDPWhPjBlewqbH2qTWDnBlxucuaNcEaDcJTusnIqdEpLGIPI/2x+NfF/w9tOTUhJ4yhNZ6t/gGsCI7HFnvSn4ETorIdBfsApJ7PCil8qJpIJ9yZCMiI0SklIiURTumDSLi8E5WKeWjlCqQ/BntJZ3TXjwiEgxcUUolTzDSAP0ynq7egV0Gqiml8lnj2QDtXYRDlFJFrf8/ipYk5rngcwVaosD6/x8u2OpGaRMWDAVai0i0C3YVU319BefXxlERKSoiZa3Xx1W0l/XBjuysvkqk+toWHdcHsBztxShKqUpoL81v6bBrCJwSkas6yiZzDUiefqk+4LSpJtW14QGMBr5zwd/Dy/1+K2t0QWtTPYP2l3mUTpv5aI+cCWg/iB46bGqiPa4fQXvsPwQ012H3FHDQancMG2/8ndjXRUcvF7SePoety3G9sbDaPgPss9ZxOVBEh40PcBso5OLxjENLWseAX7H2nnBisxXtj8xhoIEr5xXwA/5BSw7rAV8dNm2tn+PQROXW6LA5h/Y+J/na+E5n/ZZYY3EE+BMo6cq1ip2eTXZ8/QoctfpaAZTQYZMLmGut4wGgvp76AT8BvVw8VzWB/dbzvBt4XodNf7Tf/xlgMtZBkv/fF3OkqImJiclDQk5tcjExMTExSYeZ0E1MTEweEsyEbmJiYvKQYCZ0ExMTk4cEM6GbmJiYPCSYCd3ELSilflJKTbR+rqWUsquZksV+RSlVwc62TUqpnjr3c1Ep1dBgHQzbmpi4gpnQTVKwJp4YpVSkUuqGNQnnz2o/IrJVRB5zVk4p1VUptS2r/ZuYPKyYCd0kPa1EJD+aDMALaKPw0mAd3m1iYvKAYSZ0E5uIpg+zGk2XPLnpoo9S6izWodlKqZbWSQnClVI7lFJPJdsrpZ5VSh1QSkUopRYCeVJtq6uUuprqe2ml1FKlVIhS6rZS6iulVGW04dzVrU8M4dayuZVSnymlLlufIr6zSisk72uIUuq6UuqaUqq73uNVSpVXSm2w+r+llPpNZZys4kWlTXQSppSao1JN0uEoFiYm7sJM6CY2UUqVRpNXOJhqdRvgJaCKUupZYDbwHtow+5nACmvCzYUmJfArmmLfYuyITymlPIG/0CZsKIsmg7xANLXFXsBOEckvIsnJdTKatOszQAVr+THWfTUFBqPp5lRE0xXRfcjAp2hqkJXRxN/GpivzFtAETSirEtanF0excMG/iUmmMRO6SXqWW++Gt6FNKjEp1bZPRSRURGKAd4GZIrJbNCW/n9E0UKpZF29ghogkiMjvaIJqtqiKlkSHiEiUiMSKiM12c6uw17toUquhok04MglNyAy0SRXmiMgxEYkiY0K2i4icE5F1IhInIiHAdO4JRiXzlYhcEZFQ4BM0kTKcxMLExG2YbaEm6WkjIuvtbEs9qUgZoItS6oNU63KhJWdBm4ghtVCQvZmNSgOX5N6sP44IQJvtaH8qaW6FNh0eVt+pteT1zqaEUqoY8F+0yRkKoN3shKUrlvr4L1n9geNYmJi4DfMO3cQVUifoK8AnIlI41ZJPRJKV8UqmmxDhUTv7vAI8audFa3rluFtADPBEKp+FrC9xsfpNrZNvz6ctJln9/UdECgKd0P5YpCb9vpOnSnMUCxMTt2EmdBOjzAJ6KaVeUho+SqkWVm32nWiz9/RTSnkrpdphf9KCPWiJeLJ1H3mUUi9bt90ASlnb5JF7EzR8kUoPu6RSqom1/CKgq1KqitJm+PnYheMpAEQCd5RSJdFm6UlPH6VUKaWULzCKe5M4OIqFiYnbMBO6iSFEZB/wDvAVWtPEOaCrdVs82oQUXdEm932dezPSpN+PBWiF9oLzMpre9evWzRvQNN6DlVLJkysMs/rapZS6i6Z1/ph1X6vR5mTdYC2zwYVDGofWVfMOsNJOfeehTYl3Hk2Hf6KzWJiYuBNTD93ExMTkIcG8QzcxMTF5SDATuomJiclDgpnQTUxMTB4SzIRuYmJi8pBgJnQTExOThwQzoZuYmJg8JJgJ3cTExOQhwUzoJiYmJg8JZkI3MTExeUj4P1TB193XSjrvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dehyO8FntICE"
      },
      "source": [
        "#BERT 512 Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCBufmMhs49f",
        "outputId": "c83e4b9e-d0e3-44a8-ece9-2abc0e2624d3"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYnMfkfos49f",
        "outputId": "db227804-87ff-4648-f462-5a13aa42d809"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train.data[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: tensor([  101,  1045,  2001,  6603,  2065,  3087,  2041,  2045,  2071,  4372,\n",
            "         7138,  2368,  2033,  2006,  2023,  2482,  1045,  2387,  1996,  2060,\n",
            "         2154,  1012,  2009,  2001,  1037,  1016,  1011,  2341,  2998,  2482,\n",
            "         1010,  2246,  2000,  2022,  2013,  1996,  2397, 20341,  1013,  2220,\n",
            "        17549,  1012,  2009,  2001,  2170,  1037,  5318,  4115,  1012,  1996,\n",
            "         4303,  2020,  2428,  2235,  1012,  1999,  2804,  1010,  1996,  2392,\n",
            "        21519,  2001,  3584,  2013,  1996,  2717,  1997,  1996,  2303,  1012,\n",
            "         2023,  2003,  2035,  1045,  2113,  1012,  2065,  3087,  2064,  2425,\n",
            "         4168,  1037,  2944,  2171,  1010,  3194, 28699,  2015,  1010,  2086,\n",
            "         1997,  2537,  1010,  2073,  2023,  2482,  2003,  2081,  1010,  2381,\n",
            "         1010,  2030,  3649, 18558,  2017,  2031,  2006,  2023, 24151,  2559,\n",
            "         2482,  1010,  3531,  1041,  1011,  5653,  1012,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_qCkryNs49f",
        "outputId": "4715a559-44f8-4d15-a5d7-1a6af152bac9"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test.data:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True, #Truncate the sentences\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test.target)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test.data[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "Token IDs: tensor([  101,  1045,  2572,  1037,  2210,  5457,  2006,  2035,  1997,  1996,\n",
            "         4275,  1997,  1996,  6070,  1011,  6486, 19349, 21187,  2015,  1012,\n",
            "         1045,  2031,  2657,  1997,  1996,  3393,  7367,  1048,  3366,  7020,\n",
            "         2063,  7020,  7416,  1012,  2071,  2619,  2425,  2033,  1996,  5966,\n",
            "         2024,  2521,  2004,  2838,  2030,  2836,  1012,  1045,  2572,  2036,\n",
            "         8025,  2000,  2113,  2054,  1996,  2338,  3643,  2003,  2005,  9544,\n",
            "         5243,  6321,  1996,  6486,  2944,  1012,  1998,  2129,  2172,  2625,\n",
            "         2084,  2338,  3643,  2064,  2017,  2788,  2131,  2068,  2005,  1012,\n",
            "         1999,  2060,  2616,  2129,  2172,  2024,  2027,  1999,  5157,  2023,\n",
            "         2051,  1997,  2095,  1012,  1045,  2031,  2657,  2008,  1996,  3054,\n",
            "         1011,  3500,  2220,  2621,  2003,  1996,  2190,  2051,  2000,  4965,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPDrXpOgs49f",
        "outputId": "6c11ba3e-94ce-4d0f-8c80-8b108da239bb"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} test samples'.format(len(test_dataset)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10,182 training samples\n",
            "1,132 validation samples\n",
            "7,532 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKuwhYOxs49f"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(test_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9mTs74Ws49f"
      },
      "source": [
        "from transformers import  BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxDuwYUds49f",
        "outputId": "74555f27-bf17-43c3-be6d-3a47f80fb67b"
      },
      "source": [
        "bert_model"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbyjWpAps49g"
      },
      "source": [
        "# Define the model\n",
        "class linear(nn.Module):\n",
        "\n",
        "  def __init__(self, bert_model, n_outputs, dropout_rate):\n",
        "  \n",
        "    super(linear, self).__init__()\n",
        "\n",
        "    self.D = bert_model.config.to_dict()['hidden_size']\n",
        "    self.bert_model = bert_model\n",
        "    self.K = n_outputs    \n",
        "    self.dropout_rate=dropout_rate\n",
        "    \n",
        "    # embedding layer\n",
        "    #self.embed = nn.Embedding(self.V, self.D)\n",
        "    \n",
        "   \n",
        "    # dense layer\n",
        "    self.fc = nn.Linear(self.D , self.K)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout= nn.Dropout(self.dropout_rate)\n",
        "  \n",
        "  def forward(self, X):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = self.bert_model(X)[0][:,0,:]\n",
        "    \n",
        "    #embedding= self.dropout(embedding) \n",
        "\n",
        "    output = self.fc(embedding)\n",
        "    output= self.dropout(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VECRhFEqs49g"
      },
      "source": [
        "n_outputs = 20\n",
        "dropout_rate = 0.5"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmGrkdCis49g",
        "outputId": "13e55d27-fbca-4cac-8b92-70e321be738c"
      },
      "source": [
        "#model = RNN(n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
        "model = linear(bert_model, n_outputs, dropout_rate)\n",
        "model.to(device)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "linear(\n",
              "  (bert_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKQriPvts49g",
        "outputId": "71d82016-06f8-4da4-c338-0ecea7d0c024"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear(\n",
            "  (bert_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=768, out_features=20, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HVsqarSs49g",
        "outputId": "d40bf0c6-27d0-40c4-9567-bbb0be6104b8"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_model.embeddings.word_embeddings.weight torch.Size([30522, 768])\n",
            "bert_model.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
            "bert_model.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
            "bert_model.embeddings.LayerNorm.weight torch.Size([768])\n",
            "bert_model.embeddings.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "bert_model.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "bert_model.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "bert_model.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "bert_model.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "bert_model.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "bert_model.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "bert_model.pooler.dense.weight torch.Size([768, 768])\n",
            "bert_model.pooler.dense.bias torch.Size([768])\n",
            "fc.weight torch.Size([20, 768])\n",
            "fc.bias torch.Size([20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqwLRaN7s49g",
        "outputId": "00b6f32d-4d48-4ed9-e36a-7879ea36bf53"
      },
      "source": [
        "import random\n",
        "\n",
        "seed = 123\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs=10\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "#model.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model.train()\n",
        "  for batch in train_dataloader:\n",
        "   \n",
        "    # forward pass\n",
        "    output= model(batch[0].to(device))\n",
        "    loss=criterion(output,batch[2].to(device))\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_dataloader:\n",
        " \n",
        "      # forward pass\n",
        "      output= model(batch[0].to(device))\n",
        "      loss=criterion(output,batch[2].to(device))\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 3.0419    Valid Loss: 2.7815, Duration: 0:03:39.286841\n",
            "Epoch 2/10, Train Loss: 2.9293    Valid Loss: 2.7077, Duration: 0:03:39.195885\n",
            "Epoch 3/10, Train Loss: 2.8992    Valid Loss: 2.6527, Duration: 0:03:39.192333\n",
            "Epoch 4/10, Train Loss: 2.8657    Valid Loss: 2.6342, Duration: 0:03:39.245665\n",
            "Epoch 5/10, Train Loss: 2.8500    Valid Loss: 2.5605, Duration: 0:03:39.192875\n",
            "Epoch 6/10, Train Loss: 2.8464    Valid Loss: 2.5700, Duration: 0:03:39.200640\n",
            "Epoch 7/10, Train Loss: 2.8387    Valid Loss: 2.5003, Duration: 0:03:39.328104\n",
            "Epoch 8/10, Train Loss: 2.8185    Valid Loss: 2.4943, Duration: 0:03:39.246588\n",
            "Epoch 9/10, Train Loss: 2.8241    Valid Loss: 2.5048, Duration: 0:03:39.224581\n",
            "Epoch 10/10, Train Loss: 2.8186    Valid Loss: 2.4282, Duration: 0:03:39.227243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ5KPp7js49g"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      output=model(batch[0].to(device))\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct+= (batch[2].to(device)==indices).sum().item()\n",
        "      total += batch[2].shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt5YDI8Ps49g",
        "outputId": "95abafb1-5d45-46cb-b1df-a5ec0902e13f"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model)\n",
        "valid_acc = get_accuracy(validation_dataloader, model)\n",
        "test_acc = get_accuracy(test_dataloader ,model)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.3407,\t Valid acc: 0.3145,\t Test acc: 0.2872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9XbR02as49g"
      },
      "source": [
        "# Write a function to get predictions\n",
        "\n",
        "def get_predictions(test_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in test_iter:\n",
        "      \n",
        "      output=model(batch[0].to(device))\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,batch[2].numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwxVexgDs49g"
      },
      "source": [
        "y_test, predictions=get_predictions(test_dataloader, model)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n1tmUPQs49g",
        "outputId": "f6347b75-518d-4385-e353-b731ef3b23a9"
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  9,   6,   0,   0,   0,   0,  19,  22,   0,  33,   0,   3,   0,\n",
              "         55,   0,  69,   9,   8,  75,  11],\n",
              "       [  0, 111,  26,  17,   0,   5,  69,  36,   0,  32,   1,   2,   2,\n",
              "         53,   2,   1,   0,   1,  31,   0],\n",
              "       [  0,  59,  54,  41,   0,  12,  65,  33,   0,  41,   0,   1,   2,\n",
              "         48,   0,   1,   0,   0,  37,   0],\n",
              "       [  0,  42,  28,  85,   0,   2,  59,  61,   0,  34,   0,   2,   8,\n",
              "         41,   1,   0,   0,   1,  28,   0],\n",
              "       [  0,  51,  10,  48,   3,   0,  68,  59,   0,  41,   0,   0,   4,\n",
              "         64,   0,   1,   0,   0,  36,   0],\n",
              "       [  0,  68,  33,  39,   0,  49,  74,  27,   0,  28,   0,   2,   2,\n",
              "         52,   0,   1,   0,   0,  20,   0],\n",
              "       [  0,   8,   2,  13,   0,   0, 283,  28,   0,  29,   2,   0,   0,\n",
              "         17,   0,   0,   0,   0,   8,   0],\n",
              "       [  0,   9,   0,   2,   0,   0,  51, 205,   0,  55,   1,   1,   1,\n",
              "         40,   0,   0,   1,   0,  30,   0],\n",
              "       [  0,  25,   1,   1,   0,   0,  56, 148,  10,  62,   0,   1,   1,\n",
              "         39,   0,   1,   4,   1,  48,   0],\n",
              "       [  0,  12,   1,   0,   0,   0,  34,  26,   0, 231,   8,   0,   0,\n",
              "         35,   0,   4,   0,   4,  42,   0],\n",
              "       [  0,   7,   0,   1,   0,   0,  24,  40,   0,  85, 139,   0,   1,\n",
              "         43,   0,   3,   0,   3,  53,   0],\n",
              "       [  0,  15,  14,   9,   0,   1,  32,  26,   0,  48,   0,  55,   6,\n",
              "         68,   0,   8,  15,   6,  93,   0],\n",
              "       [  0,  22,  10,  18,   0,   3,  64,  79,   2,  36,   0,   4,  32,\n",
              "         78,   0,   7,   3,   4,  31,   0],\n",
              "       [  0,  10,   0,   0,   0,   0,  28,  33,   0,  43,   0,   0,   0,\n",
              "        231,   0,   7,   0,   2,  42,   0],\n",
              "       [  0,   8,   5,   2,   0,   1,  30,  64,   0,  37,   0,   0,   2,\n",
              "         82,  76,   7,   4,   2,  74,   0],\n",
              "       [  1,   8,   2,   1,   0,   0,  18,   8,   0,  21,   0,   0,   0,\n",
              "         47,   0, 225,   1,   5,  54,   7],\n",
              "       [  0,  10,   1,   1,   0,   0,  26,  36,   0,  33,   0,   2,   0,\n",
              "         74,   0,   9,  68,   6,  97,   1],\n",
              "       [  0,   7,   0,   1,   0,   0,  15,  14,   0,  36,   1,   1,   0,\n",
              "         33,   0,  26,   4, 175,  61,   2],\n",
              "       [  2,   3,   3,   1,   0,   0,   5,  19,   0,  27,   0,   1,   0,\n",
              "         73,   0,  13,  34,   9, 120,   0],\n",
              "       [  3,   1,   0,   0,   0,   0,  18,  25,   0,  35,   0,   0,   0,\n",
              "         38,   1,  70,   3,   7,  48,   2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVKiP-3Ns49g"
      },
      "source": [
        "# Write a function to print confusion matrix\n",
        "# plot confusion matrix\n",
        "# need to import confusion_matrix from sklearn for this function to work\n",
        "# need to import seaborn as sns\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_pred,normalize=None):\n",
        "  cm=confusion_matrix(y_true,y_pred,normalize=normalize)\n",
        "  fig, ax = plt.subplots(figsize=(6,5))\n",
        "  if normalize == None:\n",
        "    fmt='d'\n",
        "    fig.suptitle('Confusion matrix without Normalization', fontsize=12)\n",
        "        \n",
        "  else :\n",
        "    fmt='0.2f'\n",
        "    fig.suptitle('Normalized confusion matrix', fontsize=12)\n",
        "    \n",
        "  ax=sns.heatmap(cm,cmap=plt.cm.Blues,annot=True,fmt=fmt)\n",
        "  ax.axhline(y=0, color='k',linewidth=1)\n",
        "  ax.axhline(y=cm.shape[1], color='k',linewidth=2)\n",
        "  ax.axvline(x=0, color='k',linewidth=1)\n",
        "  ax.axvline(x=cm.shape[0], color='k',linewidth=2)\n",
        " \n",
        "  ax.set_xlabel('Predicted label', fontsize=12)\n",
        "  ax.set_ylabel('True label', fontsize=12)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "tz_JHbBRs49g",
        "outputId": "017dd003-46e4-44dc-c77f-d98a693b6d97"
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFSeZ2kQuXAu"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}